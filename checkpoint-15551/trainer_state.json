{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 15551,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006430454633142563,
      "grad_norm": 3.082956075668335,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 0.2824,
      "step": 10
    },
    {
      "epoch": 0.0012860909266285126,
      "grad_norm": 2.8381004333496094,
      "learning_rate": 5.399999999999999e-05,
      "loss": 0.1659,
      "step": 20
    },
    {
      "epoch": 0.001929136389942769,
      "grad_norm": 0.4284157454967499,
      "learning_rate": 8.1e-05,
      "loss": 0.0378,
      "step": 30
    },
    {
      "epoch": 0.002572181853257025,
      "grad_norm": 0.30510181188583374,
      "learning_rate": 0.00011099999999999999,
      "loss": 0.0169,
      "step": 40
    },
    {
      "epoch": 0.0032152273165712815,
      "grad_norm": 0.015173889696598053,
      "learning_rate": 0.00014099999999999998,
      "loss": 0.0171,
      "step": 50
    },
    {
      "epoch": 0.003858272779885538,
      "grad_norm": 9.088796615600586,
      "learning_rate": 0.00017099999999999998,
      "loss": 0.004,
      "step": 60
    },
    {
      "epoch": 0.004501318243199794,
      "grad_norm": 11.194215774536133,
      "learning_rate": 0.000201,
      "loss": 0.0145,
      "step": 70
    },
    {
      "epoch": 0.00514436370651405,
      "grad_norm": 0.16156944632530212,
      "learning_rate": 0.00023099999999999998,
      "loss": 0.0015,
      "step": 80
    },
    {
      "epoch": 0.005787409169828307,
      "grad_norm": 0.011441264301538467,
      "learning_rate": 0.000261,
      "loss": 0.0018,
      "step": 90
    },
    {
      "epoch": 0.006430454633142563,
      "grad_norm": 0.044937487691640854,
      "learning_rate": 0.00029099999999999997,
      "loss": 0.0008,
      "step": 100
    },
    {
      "epoch": 0.00707350009645682,
      "grad_norm": NaN,
      "learning_rate": 0.00029986408646689533,
      "loss": 0.019,
      "step": 110
    },
    {
      "epoch": 0.007716545559771076,
      "grad_norm": 0.03215140849351883,
      "learning_rate": 0.0002996893404957608,
      "loss": 0.0009,
      "step": 120
    },
    {
      "epoch": 0.008359591023085332,
      "grad_norm": 0.011234784498810768,
      "learning_rate": 0.00029949517830561126,
      "loss": 0.0005,
      "step": 130
    },
    {
      "epoch": 0.009002636486399589,
      "grad_norm": 0.0277872271835804,
      "learning_rate": 0.00029930101611546175,
      "loss": 0.0055,
      "step": 140
    },
    {
      "epoch": 0.009645681949713845,
      "grad_norm": 0.0621894896030426,
      "learning_rate": 0.00029910685392531223,
      "loss": 0.0017,
      "step": 150
    },
    {
      "epoch": 0.0102887274130281,
      "grad_norm": 0.03249938040971756,
      "learning_rate": 0.0002989126917351628,
      "loss": 0.0006,
      "step": 160
    },
    {
      "epoch": 0.010931772876342357,
      "grad_norm": 0.020698564127087593,
      "learning_rate": 0.00029871852954501326,
      "loss": 0.0015,
      "step": 170
    },
    {
      "epoch": 0.011574818339656614,
      "grad_norm": 0.006801704876124859,
      "learning_rate": 0.00029852436735486375,
      "loss": 0.0003,
      "step": 180
    },
    {
      "epoch": 0.01221786380297087,
      "grad_norm": 0.005510313902050257,
      "learning_rate": 0.00029833020516471424,
      "loss": 0.0001,
      "step": 190
    },
    {
      "epoch": 0.012860909266285126,
      "grad_norm": 0.1301761120557785,
      "learning_rate": 0.0002981360429745647,
      "loss": 0.0002,
      "step": 200
    },
    {
      "epoch": 0.013503954729599383,
      "grad_norm": 9.388954162597656,
      "learning_rate": 0.00029796129700343017,
      "loss": 0.0364,
      "step": 210
    },
    {
      "epoch": 0.01414700019291364,
      "grad_norm": 0.001272945897653699,
      "learning_rate": 0.00029776713481328065,
      "loss": 0.0031,
      "step": 220
    },
    {
      "epoch": 0.014790045656227895,
      "grad_norm": 0.006469451356679201,
      "learning_rate": 0.00029757297262313114,
      "loss": 0.0002,
      "step": 230
    },
    {
      "epoch": 0.015433091119542152,
      "grad_norm": 0.005173171404749155,
      "learning_rate": 0.0002973788104329817,
      "loss": 0.0008,
      "step": 240
    },
    {
      "epoch": 0.016076136582856407,
      "grad_norm": 0.031375300139188766,
      "learning_rate": 0.00029718464824283217,
      "loss": 0.0002,
      "step": 250
    },
    {
      "epoch": 0.016719182046170664,
      "grad_norm": 0.003152528777718544,
      "learning_rate": 0.00029699048605268265,
      "loss": 0.0002,
      "step": 260
    },
    {
      "epoch": 0.01736222750948492,
      "grad_norm": 0.05240177363157272,
      "learning_rate": 0.00029679632386253314,
      "loss": 0.0002,
      "step": 270
    },
    {
      "epoch": 0.018005272972799177,
      "grad_norm": 0.006423151586204767,
      "learning_rate": 0.00029660216167238363,
      "loss": 0.0002,
      "step": 280
    },
    {
      "epoch": 0.018648318436113434,
      "grad_norm": 0.0012830063933506608,
      "learning_rate": 0.0002964079994822341,
      "loss": 0.0001,
      "step": 290
    },
    {
      "epoch": 0.01929136389942769,
      "grad_norm": 0.012810802087187767,
      "learning_rate": 0.00029621383729208466,
      "loss": 0.0002,
      "step": 300
    },
    {
      "epoch": 0.019934409362741944,
      "grad_norm": 0.016793400049209595,
      "learning_rate": 0.00029601967510193514,
      "loss": 0.0001,
      "step": 310
    },
    {
      "epoch": 0.0205774548260562,
      "grad_norm": 0.005208138842135668,
      "learning_rate": 0.00029582551291178563,
      "loss": 0.0003,
      "step": 320
    },
    {
      "epoch": 0.021220500289370458,
      "grad_norm": 0.006270959507673979,
      "learning_rate": 0.0002956313507216361,
      "loss": 0.0378,
      "step": 330
    },
    {
      "epoch": 0.021863545752684715,
      "grad_norm": 4.194936275482178,
      "learning_rate": 0.0002954371885314866,
      "loss": 0.0006,
      "step": 340
    },
    {
      "epoch": 0.02250659121599897,
      "grad_norm": 0.0018735924968495965,
      "learning_rate": 0.0002952430263413371,
      "loss": 0.0012,
      "step": 350
    },
    {
      "epoch": 0.02314963667931323,
      "grad_norm": 0.02992415986955166,
      "learning_rate": 0.00029504886415118763,
      "loss": 0.0004,
      "step": 360
    },
    {
      "epoch": 0.023792682142627485,
      "grad_norm": 0.0037754690274596214,
      "learning_rate": 0.0002948547019610381,
      "loss": 0.0093,
      "step": 370
    },
    {
      "epoch": 0.02443572760594174,
      "grad_norm": 0.011186433024704456,
      "learning_rate": 0.0002946605397708886,
      "loss": 0.0002,
      "step": 380
    },
    {
      "epoch": 0.025078773069255995,
      "grad_norm": 0.029746998101472855,
      "learning_rate": 0.0002944663775807391,
      "loss": 0.0107,
      "step": 390
    },
    {
      "epoch": 0.025721818532570252,
      "grad_norm": 0.003352358704432845,
      "learning_rate": 0.0002942722153905896,
      "loss": 0.0038,
      "step": 400
    },
    {
      "epoch": 0.02636486399588451,
      "grad_norm": 0.23775792121887207,
      "learning_rate": 0.00029407805320044006,
      "loss": 0.0006,
      "step": 410
    },
    {
      "epoch": 0.027007909459198766,
      "grad_norm": 0.012079250998795033,
      "learning_rate": 0.0002938838910102906,
      "loss": 0.0056,
      "step": 420
    },
    {
      "epoch": 0.027650954922513023,
      "grad_norm": 0.002813945757225156,
      "learning_rate": 0.0002936897288201411,
      "loss": 0.0006,
      "step": 430
    },
    {
      "epoch": 0.02829400038582728,
      "grad_norm": 0.08025374263525009,
      "learning_rate": 0.0002934955666299916,
      "loss": 0.0003,
      "step": 440
    },
    {
      "epoch": 0.028937045849141533,
      "grad_norm": 0.0019060386111959815,
      "learning_rate": 0.00029330140443984207,
      "loss": 0.0002,
      "step": 450
    },
    {
      "epoch": 0.02958009131245579,
      "grad_norm": 0.0032094570342451334,
      "learning_rate": 0.00029310724224969255,
      "loss": 0.0002,
      "step": 460
    },
    {
      "epoch": 0.030223136775770047,
      "grad_norm": 0.005044864024966955,
      "learning_rate": 0.00029291308005954304,
      "loss": 0.0002,
      "step": 470
    },
    {
      "epoch": 0.030866182239084303,
      "grad_norm": 0.004528976511210203,
      "learning_rate": 0.0002927189178693936,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 0.03150922770239856,
      "grad_norm": 0.0026366300880908966,
      "learning_rate": 0.000292524755679244,
      "loss": 0.0001,
      "step": 490
    },
    {
      "epoch": 0.032152273165712814,
      "grad_norm": 0.0012726749991998076,
      "learning_rate": 0.0002923305934890945,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 0.03279531862902707,
      "grad_norm": 0.04093683138489723,
      "learning_rate": 0.00029213643129894504,
      "loss": 0.0002,
      "step": 510
    },
    {
      "epoch": 0.03343836409234133,
      "grad_norm": 0.007075518369674683,
      "learning_rate": 0.00029194226910879553,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 0.034081409555655584,
      "grad_norm": 0.00805511511862278,
      "learning_rate": 0.000291748106918646,
      "loss": 0.002,
      "step": 530
    },
    {
      "epoch": 0.03472445501896984,
      "grad_norm": 9.287599563598633,
      "learning_rate": 0.0002915539447284965,
      "loss": 0.0061,
      "step": 540
    },
    {
      "epoch": 0.0353675004822841,
      "grad_norm": 0.0036395625211298466,
      "learning_rate": 0.000291359782538347,
      "loss": 0.0003,
      "step": 550
    },
    {
      "epoch": 0.036010545945598355,
      "grad_norm": 0.22234897315502167,
      "learning_rate": 0.0002911656203481975,
      "loss": 0.0017,
      "step": 560
    },
    {
      "epoch": 0.03665359140891261,
      "grad_norm": 0.0037991453427821398,
      "learning_rate": 0.000290971458158048,
      "loss": 0.0003,
      "step": 570
    },
    {
      "epoch": 0.03729663687222687,
      "grad_norm": 0.006269481498748064,
      "learning_rate": 0.0002907772959678985,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 0.037939682335541125,
      "grad_norm": 0.003924953285604715,
      "learning_rate": 0.000290583133777749,
      "loss": 0.0002,
      "step": 590
    },
    {
      "epoch": 0.03858272779885538,
      "grad_norm": 0.0017209189245477319,
      "learning_rate": 0.0002903889715875995,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 0.03922577326216964,
      "grad_norm": 0.0502810962498188,
      "learning_rate": 0.00029019480939744996,
      "loss": 0.0002,
      "step": 610
    },
    {
      "epoch": 0.03986881872548389,
      "grad_norm": 0.0024341994430869818,
      "learning_rate": 0.00029000064720730045,
      "loss": 0.0004,
      "step": 620
    },
    {
      "epoch": 0.040511864188798145,
      "grad_norm": 0.0013116110349074006,
      "learning_rate": 0.000289806485017151,
      "loss": 0.0002,
      "step": 630
    },
    {
      "epoch": 0.0411549096521124,
      "grad_norm": 0.005118091590702534,
      "learning_rate": 0.0002896123228270015,
      "loss": 0.0024,
      "step": 640
    },
    {
      "epoch": 0.04179795511542666,
      "grad_norm": 0.24159209430217743,
      "learning_rate": 0.00028941816063685196,
      "loss": 0.0002,
      "step": 650
    },
    {
      "epoch": 0.042441000578740916,
      "grad_norm": 0.0074364785104990005,
      "learning_rate": 0.00028922399844670245,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 0.04308404604205517,
      "grad_norm": 0.0051528410986065865,
      "learning_rate": 0.00028902983625655294,
      "loss": 0.0001,
      "step": 670
    },
    {
      "epoch": 0.04372709150536943,
      "grad_norm": 0.005788784008473158,
      "learning_rate": 0.0002888356740664034,
      "loss": 0.0002,
      "step": 680
    },
    {
      "epoch": 0.044370136968683686,
      "grad_norm": 0.0043295081704854965,
      "learning_rate": 0.00028864151187625397,
      "loss": 0.0001,
      "step": 690
    },
    {
      "epoch": 0.04501318243199794,
      "grad_norm": 0.006153011694550514,
      "learning_rate": 0.00028844734968610445,
      "loss": 0.0001,
      "step": 700
    },
    {
      "epoch": 0.0456562278953122,
      "grad_norm": 0.0015911835944280028,
      "learning_rate": 0.00028825318749595494,
      "loss": 0.0094,
      "step": 710
    },
    {
      "epoch": 0.04629927335862646,
      "grad_norm": 0.008311445824801922,
      "learning_rate": 0.0002880590253058054,
      "loss": 0.0005,
      "step": 720
    },
    {
      "epoch": 0.046942318821940714,
      "grad_norm": 0.004049984738230705,
      "learning_rate": 0.0002878648631156559,
      "loss": 0.0005,
      "step": 730
    },
    {
      "epoch": 0.04758536428525497,
      "grad_norm": 0.0017906214343383908,
      "learning_rate": 0.0002876707009255064,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.04822840974856923,
      "grad_norm": 0.006499862298369408,
      "learning_rate": 0.00028747653873535694,
      "loss": 0.0045,
      "step": 750
    },
    {
      "epoch": 0.04887145521188348,
      "grad_norm": 0.01862650364637375,
      "learning_rate": 0.00028728237654520743,
      "loss": 0.0015,
      "step": 760
    },
    {
      "epoch": 0.049514500675197734,
      "grad_norm": 0.018520699813961983,
      "learning_rate": 0.0002870882143550579,
      "loss": 0.0009,
      "step": 770
    },
    {
      "epoch": 0.05015754613851199,
      "grad_norm": 0.0026677504647523165,
      "learning_rate": 0.0002868940521649084,
      "loss": 0.0116,
      "step": 780
    },
    {
      "epoch": 0.05080059160182625,
      "grad_norm": 16.270404815673828,
      "learning_rate": 0.0002866998899747589,
      "loss": 0.0447,
      "step": 790
    },
    {
      "epoch": 0.051443637065140504,
      "grad_norm": 0.007973204366862774,
      "learning_rate": 0.0002865057277846094,
      "loss": 0.0034,
      "step": 800
    },
    {
      "epoch": 0.05208668252845476,
      "grad_norm": 0.010610627010464668,
      "learning_rate": 0.0002863115655944599,
      "loss": 0.0006,
      "step": 810
    },
    {
      "epoch": 0.05272972799176902,
      "grad_norm": 0.011871593073010445,
      "learning_rate": 0.00028611740340431035,
      "loss": 0.0007,
      "step": 820
    },
    {
      "epoch": 0.053372773455083275,
      "grad_norm": 0.1069258451461792,
      "learning_rate": 0.00028592324121416083,
      "loss": 0.0007,
      "step": 830
    },
    {
      "epoch": 0.05401581891839753,
      "grad_norm": 0.08255577832460403,
      "learning_rate": 0.0002857290790240114,
      "loss": 0.0442,
      "step": 840
    },
    {
      "epoch": 0.05465886438171179,
      "grad_norm": 1.3891594409942627,
      "learning_rate": 0.00028553491683386186,
      "loss": 0.0061,
      "step": 850
    },
    {
      "epoch": 0.055301909845026045,
      "grad_norm": 25.04448890686035,
      "learning_rate": 0.00028534075464371235,
      "loss": 0.0392,
      "step": 860
    },
    {
      "epoch": 0.0559449553083403,
      "grad_norm": 0.007316415663808584,
      "learning_rate": 0.00028514659245356284,
      "loss": 0.0005,
      "step": 870
    },
    {
      "epoch": 0.05658800077165456,
      "grad_norm": 0.07940110564231873,
      "learning_rate": 0.0002849524302634133,
      "loss": 0.0004,
      "step": 880
    },
    {
      "epoch": 0.05723104623496881,
      "grad_norm": 0.0020378369372338057,
      "learning_rate": 0.0002847582680732638,
      "loss": 0.0003,
      "step": 890
    },
    {
      "epoch": 0.057874091698283066,
      "grad_norm": 0.016911623999476433,
      "learning_rate": 0.00028456410588311435,
      "loss": 0.0002,
      "step": 900
    },
    {
      "epoch": 0.05851713716159732,
      "grad_norm": 0.014805045910179615,
      "learning_rate": 0.00028436994369296484,
      "loss": 0.0004,
      "step": 910
    },
    {
      "epoch": 0.05916018262491158,
      "grad_norm": 0.07077830284833908,
      "learning_rate": 0.0002841757815028153,
      "loss": 0.0008,
      "step": 920
    },
    {
      "epoch": 0.059803228088225836,
      "grad_norm": 0.09810267388820648,
      "learning_rate": 0.0002839816193126658,
      "loss": 0.0088,
      "step": 930
    },
    {
      "epoch": 0.06044627355154009,
      "grad_norm": 0.0033646535594016314,
      "learning_rate": 0.0002837874571225163,
      "loss": 0.0028,
      "step": 940
    },
    {
      "epoch": 0.06108931901485435,
      "grad_norm": 0.504551112651825,
      "learning_rate": 0.0002835932949323668,
      "loss": 0.0005,
      "step": 950
    },
    {
      "epoch": 0.06173236447816861,
      "grad_norm": 0.004404716659337282,
      "learning_rate": 0.0002833991327422173,
      "loss": 0.0002,
      "step": 960
    },
    {
      "epoch": 0.062375409941482864,
      "grad_norm": 0.007822226732969284,
      "learning_rate": 0.0002832049705520678,
      "loss": 0.0001,
      "step": 970
    },
    {
      "epoch": 0.06301845540479711,
      "grad_norm": 0.03470062464475632,
      "learning_rate": 0.0002830108083619183,
      "loss": 0.0002,
      "step": 980
    },
    {
      "epoch": 0.06366150086811137,
      "grad_norm": 0.04779701679944992,
      "learning_rate": 0.0002828166461717688,
      "loss": 0.0002,
      "step": 990
    },
    {
      "epoch": 0.06430454633142563,
      "grad_norm": 0.008149433881044388,
      "learning_rate": 0.00028262248398161927,
      "loss": 0.0001,
      "step": 1000
    },
    {
      "epoch": 0.06494759179473988,
      "grad_norm": 13.60133171081543,
      "learning_rate": 0.00028242832179146976,
      "loss": 0.0351,
      "step": 1010
    },
    {
      "epoch": 0.06559063725805414,
      "grad_norm": 0.01585574634373188,
      "learning_rate": 0.0002822341596013203,
      "loss": 0.0038,
      "step": 1020
    },
    {
      "epoch": 0.0662336827213684,
      "grad_norm": 0.08149644732475281,
      "learning_rate": 0.0002820399974111708,
      "loss": 0.0004,
      "step": 1030
    },
    {
      "epoch": 0.06687672818468265,
      "grad_norm": 0.007382568437606096,
      "learning_rate": 0.0002818458352210213,
      "loss": 0.0025,
      "step": 1040
    },
    {
      "epoch": 0.06751977364799691,
      "grad_norm": 0.0029208576306700706,
      "learning_rate": 0.00028165167303087176,
      "loss": 0.0002,
      "step": 1050
    },
    {
      "epoch": 0.06816281911131117,
      "grad_norm": 0.054018303751945496,
      "learning_rate": 0.00028145751084072225,
      "loss": 0.0002,
      "step": 1060
    },
    {
      "epoch": 0.06880586457462542,
      "grad_norm": 0.014584409072995186,
      "learning_rate": 0.00028126334865057273,
      "loss": 0.0002,
      "step": 1070
    },
    {
      "epoch": 0.06944891003793968,
      "grad_norm": 0.010768949054181576,
      "learning_rate": 0.0002810691864604233,
      "loss": 0.0034,
      "step": 1080
    },
    {
      "epoch": 0.07009195550125394,
      "grad_norm": 0.0049514262937009335,
      "learning_rate": 0.00028087502427027376,
      "loss": 0.0003,
      "step": 1090
    },
    {
      "epoch": 0.0707350009645682,
      "grad_norm": 0.009885115548968315,
      "learning_rate": 0.00028068086208012425,
      "loss": 0.0003,
      "step": 1100
    },
    {
      "epoch": 0.07137804642788245,
      "grad_norm": 0.0013223444111645222,
      "learning_rate": 0.00028048669988997474,
      "loss": 0.0001,
      "step": 1110
    },
    {
      "epoch": 0.07202109189119671,
      "grad_norm": 0.0027523438911885023,
      "learning_rate": 0.0002802925376998252,
      "loss": 0.0001,
      "step": 1120
    },
    {
      "epoch": 0.07266413735451097,
      "grad_norm": 0.0024839267134666443,
      "learning_rate": 0.0002800983755096757,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 0.07330718281782522,
      "grad_norm": 0.005889390595257282,
      "learning_rate": 0.00027990421331952625,
      "loss": 0.0002,
      "step": 1140
    },
    {
      "epoch": 0.07395022828113948,
      "grad_norm": 0.003618705552071333,
      "learning_rate": 0.00027971005112937674,
      "loss": 0.0001,
      "step": 1150
    },
    {
      "epoch": 0.07459327374445374,
      "grad_norm": 0.02230084501206875,
      "learning_rate": 0.00027951588893922717,
      "loss": 0.0001,
      "step": 1160
    },
    {
      "epoch": 0.075236319207768,
      "grad_norm": 0.0032510024029761553,
      "learning_rate": 0.0002793217267490777,
      "loss": 0.0001,
      "step": 1170
    },
    {
      "epoch": 0.07587936467108225,
      "grad_norm": 0.0020653053652495146,
      "learning_rate": 0.0002791275645589282,
      "loss": 0.0001,
      "step": 1180
    },
    {
      "epoch": 0.0765224101343965,
      "grad_norm": 0.001693928032182157,
      "learning_rate": 0.0002789334023687787,
      "loss": 0.0003,
      "step": 1190
    },
    {
      "epoch": 0.07716545559771076,
      "grad_norm": 0.003929548896849155,
      "learning_rate": 0.00027873924017862917,
      "loss": 0.0001,
      "step": 1200
    },
    {
      "epoch": 0.07780850106102502,
      "grad_norm": 0.002742464654147625,
      "learning_rate": 0.00027854507798847966,
      "loss": 0.0001,
      "step": 1210
    },
    {
      "epoch": 0.07845154652433928,
      "grad_norm": 0.002569250063970685,
      "learning_rate": 0.00027835091579833014,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 0.07909459198765352,
      "grad_norm": 0.00414744857698679,
      "learning_rate": 0.0002781567536081807,
      "loss": 0.0001,
      "step": 1230
    },
    {
      "epoch": 0.07973763745096778,
      "grad_norm": 0.0013987907441332936,
      "learning_rate": 0.00027796259141803117,
      "loss": 0.0001,
      "step": 1240
    },
    {
      "epoch": 0.08038068291428203,
      "grad_norm": 0.00269597047008574,
      "learning_rate": 0.00027776842922788166,
      "loss": 0.0001,
      "step": 1250
    },
    {
      "epoch": 0.08102372837759629,
      "grad_norm": 0.0011159213026985526,
      "learning_rate": 0.00027757426703773215,
      "loss": 0.0001,
      "step": 1260
    },
    {
      "epoch": 0.08166677384091055,
      "grad_norm": 0.008467872627079487,
      "learning_rate": 0.00027738010484758263,
      "loss": 0.0002,
      "step": 1270
    },
    {
      "epoch": 0.0823098193042248,
      "grad_norm": 0.004972531925886869,
      "learning_rate": 0.0002771859426574331,
      "loss": 0.0001,
      "step": 1280
    },
    {
      "epoch": 0.08295286476753906,
      "grad_norm": 0.0031965638045221567,
      "learning_rate": 0.00027699178046728366,
      "loss": 0.0001,
      "step": 1290
    },
    {
      "epoch": 0.08359591023085332,
      "grad_norm": 0.0012875394895672798,
      "learning_rate": 0.00027679761827713415,
      "loss": 0.0001,
      "step": 1300
    },
    {
      "epoch": 0.08423895569416757,
      "grad_norm": 0.0005580168799497187,
      "learning_rate": 0.00027660345608698463,
      "loss": 0.0,
      "step": 1310
    },
    {
      "epoch": 0.08488200115748183,
      "grad_norm": 0.004077531397342682,
      "learning_rate": 0.0002764092938968351,
      "loss": 0.0001,
      "step": 1320
    },
    {
      "epoch": 0.08552504662079609,
      "grad_norm": 0.0023254055995494127,
      "learning_rate": 0.0002762151317066856,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 0.08616809208411035,
      "grad_norm": 0.0012702274834737182,
      "learning_rate": 0.0002760209695165361,
      "loss": 0.0001,
      "step": 1340
    },
    {
      "epoch": 0.0868111375474246,
      "grad_norm": 0.0008282812195830047,
      "learning_rate": 0.00027582680732638664,
      "loss": 0.0073,
      "step": 1350
    },
    {
      "epoch": 0.08745418301073886,
      "grad_norm": 0.00199107825756073,
      "learning_rate": 0.0002756326451362371,
      "loss": 0.0001,
      "step": 1360
    },
    {
      "epoch": 0.08809722847405312,
      "grad_norm": 0.07606184482574463,
      "learning_rate": 0.0002754384829460876,
      "loss": 0.0184,
      "step": 1370
    },
    {
      "epoch": 0.08874027393736737,
      "grad_norm": 0.0033141120802611113,
      "learning_rate": 0.0002752443207559381,
      "loss": 0.0002,
      "step": 1380
    },
    {
      "epoch": 0.08938331940068163,
      "grad_norm": 0.0018103538313880563,
      "learning_rate": 0.0002750501585657886,
      "loss": 0.0003,
      "step": 1390
    },
    {
      "epoch": 0.09002636486399589,
      "grad_norm": 0.0008557455730624497,
      "learning_rate": 0.0002748559963756391,
      "loss": 0.0014,
      "step": 1400
    },
    {
      "epoch": 0.09066941032731014,
      "grad_norm": 0.011382213793694973,
      "learning_rate": 0.0002746618341854896,
      "loss": 0.0007,
      "step": 1410
    },
    {
      "epoch": 0.0913124557906244,
      "grad_norm": 0.007175760343670845,
      "learning_rate": 0.0002744676719953401,
      "loss": 0.0002,
      "step": 1420
    },
    {
      "epoch": 0.09195550125393866,
      "grad_norm": 0.009577354416251183,
      "learning_rate": 0.0002742735098051906,
      "loss": 0.0001,
      "step": 1430
    },
    {
      "epoch": 0.09259854671725291,
      "grad_norm": 0.0029162915889173746,
      "learning_rate": 0.00027407934761504107,
      "loss": 0.0001,
      "step": 1440
    },
    {
      "epoch": 0.09324159218056717,
      "grad_norm": 0.0021553568076342344,
      "learning_rate": 0.00027388518542489156,
      "loss": 0.0002,
      "step": 1450
    },
    {
      "epoch": 0.09388463764388143,
      "grad_norm": 0.0055338493548333645,
      "learning_rate": 0.0002736910232347421,
      "loss": 0.0001,
      "step": 1460
    },
    {
      "epoch": 0.09452768310719568,
      "grad_norm": 0.003968007862567902,
      "learning_rate": 0.0002734968610445926,
      "loss": 0.0001,
      "step": 1470
    },
    {
      "epoch": 0.09517072857050994,
      "grad_norm": 0.009197288192808628,
      "learning_rate": 0.00027330269885444307,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 0.0958137740338242,
      "grad_norm": 0.026844412088394165,
      "learning_rate": 0.00027310853666429356,
      "loss": 0.0001,
      "step": 1490
    },
    {
      "epoch": 0.09645681949713845,
      "grad_norm": 0.0035166190937161446,
      "learning_rate": 0.00027291437447414405,
      "loss": 0.0001,
      "step": 1500
    },
    {
      "epoch": 0.0970998649604527,
      "grad_norm": 0.0012212825240567327,
      "learning_rate": 0.00027272021228399453,
      "loss": 0.0001,
      "step": 1510
    },
    {
      "epoch": 0.09774291042376695,
      "grad_norm": 0.0005281951744109392,
      "learning_rate": 0.0002725260500938451,
      "loss": 0.0001,
      "step": 1520
    },
    {
      "epoch": 0.09838595588708121,
      "grad_norm": 0.04011517018079758,
      "learning_rate": 0.00027233188790369556,
      "loss": 0.0001,
      "step": 1530
    },
    {
      "epoch": 0.09902900135039547,
      "grad_norm": 0.0011010597227141261,
      "learning_rate": 0.000272137725713546,
      "loss": 0.0001,
      "step": 1540
    },
    {
      "epoch": 0.09967204681370972,
      "grad_norm": 0.0016450814437121153,
      "learning_rate": 0.00027194356352339653,
      "loss": 0.0001,
      "step": 1550
    },
    {
      "epoch": 0.10031509227702398,
      "grad_norm": 0.0007667277823202312,
      "learning_rate": 0.000271749401333247,
      "loss": 0.0001,
      "step": 1560
    },
    {
      "epoch": 0.10095813774033824,
      "grad_norm": 0.004130581393837929,
      "learning_rate": 0.0002715552391430975,
      "loss": 0.0001,
      "step": 1570
    },
    {
      "epoch": 0.1016011832036525,
      "grad_norm": 0.011813650839030743,
      "learning_rate": 0.000271361076952948,
      "loss": 0.0002,
      "step": 1580
    },
    {
      "epoch": 0.10224422866696675,
      "grad_norm": 0.0024055354297161102,
      "learning_rate": 0.0002711669147627985,
      "loss": 0.0001,
      "step": 1590
    },
    {
      "epoch": 0.10288727413028101,
      "grad_norm": 0.0029236157424747944,
      "learning_rate": 0.00027097275257264897,
      "loss": 0.0003,
      "step": 1600
    },
    {
      "epoch": 0.10353031959359527,
      "grad_norm": 1.7799047231674194,
      "learning_rate": 0.0002708368390395443,
      "loss": 0.6926,
      "step": 1610
    },
    {
      "epoch": 0.10417336505690952,
      "grad_norm": 0.008325375616550446,
      "learning_rate": 0.0002706426768493948,
      "loss": 0.0001,
      "step": 1620
    },
    {
      "epoch": 0.10481641052022378,
      "grad_norm": 1.5080102682113647,
      "learning_rate": 0.00027044851465924535,
      "loss": 0.0003,
      "step": 1630
    },
    {
      "epoch": 0.10545945598353804,
      "grad_norm": 0.03290943801403046,
      "learning_rate": 0.00027025435246909584,
      "loss": 0.0002,
      "step": 1640
    },
    {
      "epoch": 0.1061025014468523,
      "grad_norm": 0.004991691559553146,
      "learning_rate": 0.0002700601902789463,
      "loss": 0.0001,
      "step": 1650
    },
    {
      "epoch": 0.10674554691016655,
      "grad_norm": 0.01496544387191534,
      "learning_rate": 0.0002698660280887968,
      "loss": 0.0009,
      "step": 1660
    },
    {
      "epoch": 0.1073885923734808,
      "grad_norm": 0.007848798297345638,
      "learning_rate": 0.0002696718658986473,
      "loss": 0.0002,
      "step": 1670
    },
    {
      "epoch": 0.10803163783679506,
      "grad_norm": 0.9389325380325317,
      "learning_rate": 0.0002694777037084978,
      "loss": 0.0014,
      "step": 1680
    },
    {
      "epoch": 0.10867468330010932,
      "grad_norm": 0.007951568812131882,
      "learning_rate": 0.00026928354151834833,
      "loss": 0.0008,
      "step": 1690
    },
    {
      "epoch": 0.10931772876342358,
      "grad_norm": 0.004451705142855644,
      "learning_rate": 0.0002690893793281988,
      "loss": 0.0004,
      "step": 1700
    },
    {
      "epoch": 0.10996077422673783,
      "grad_norm": 0.004383180756121874,
      "learning_rate": 0.0002688952171380493,
      "loss": 0.0005,
      "step": 1710
    },
    {
      "epoch": 0.11060381969005209,
      "grad_norm": 0.0036027494352310896,
      "learning_rate": 0.0002687010549478998,
      "loss": 0.0003,
      "step": 1720
    },
    {
      "epoch": 0.11124686515336635,
      "grad_norm": 0.01892070844769478,
      "learning_rate": 0.0002685068927577503,
      "loss": 0.0003,
      "step": 1730
    },
    {
      "epoch": 0.1118899106166806,
      "grad_norm": 0.007973968051373959,
      "learning_rate": 0.00026831273056760076,
      "loss": 0.0002,
      "step": 1740
    },
    {
      "epoch": 0.11253295607999486,
      "grad_norm": 0.015800945460796356,
      "learning_rate": 0.0002681185683774513,
      "loss": 0.0002,
      "step": 1750
    },
    {
      "epoch": 0.11317600154330912,
      "grad_norm": 0.0025247628800570965,
      "learning_rate": 0.0002679244061873018,
      "loss": 0.006,
      "step": 1760
    },
    {
      "epoch": 0.11381904700662338,
      "grad_norm": 0.0009378696558997035,
      "learning_rate": 0.0002677302439971523,
      "loss": 0.0002,
      "step": 1770
    },
    {
      "epoch": 0.11446209246993762,
      "grad_norm": 0.00299034733325243,
      "learning_rate": 0.00026753608180700276,
      "loss": 0.0018,
      "step": 1780
    },
    {
      "epoch": 0.11510513793325187,
      "grad_norm": 0.11493714153766632,
      "learning_rate": 0.00026734191961685325,
      "loss": 0.003,
      "step": 1790
    },
    {
      "epoch": 0.11574818339656613,
      "grad_norm": 0.0044693658128380775,
      "learning_rate": 0.00026714775742670374,
      "loss": 0.0008,
      "step": 1800
    },
    {
      "epoch": 0.11639122885988039,
      "grad_norm": 0.002069166162982583,
      "learning_rate": 0.0002669535952365543,
      "loss": 0.0001,
      "step": 1810
    },
    {
      "epoch": 0.11703427432319465,
      "grad_norm": 0.0035002618096768856,
      "learning_rate": 0.0002667594330464047,
      "loss": 0.0005,
      "step": 1820
    },
    {
      "epoch": 0.1176773197865089,
      "grad_norm": 0.19143877923488617,
      "learning_rate": 0.0002665652708562552,
      "loss": 0.0003,
      "step": 1830
    },
    {
      "epoch": 0.11832036524982316,
      "grad_norm": 0.03421441838145256,
      "learning_rate": 0.00026637110866610574,
      "loss": 0.0003,
      "step": 1840
    },
    {
      "epoch": 0.11896341071313742,
      "grad_norm": 0.005144072696566582,
      "learning_rate": 0.0002661769464759562,
      "loss": 0.0001,
      "step": 1850
    },
    {
      "epoch": 0.11960645617645167,
      "grad_norm": 0.000617676938418299,
      "learning_rate": 0.0002659827842858067,
      "loss": 0.0001,
      "step": 1860
    },
    {
      "epoch": 0.12024950163976593,
      "grad_norm": 0.006389283575117588,
      "learning_rate": 0.0002657886220956572,
      "loss": 0.0021,
      "step": 1870
    },
    {
      "epoch": 0.12089254710308019,
      "grad_norm": 0.030939538031816483,
      "learning_rate": 0.0002655944599055077,
      "loss": 0.0009,
      "step": 1880
    },
    {
      "epoch": 0.12153559256639444,
      "grad_norm": 16.497676849365234,
      "learning_rate": 0.00026540029771535817,
      "loss": 0.0028,
      "step": 1890
    },
    {
      "epoch": 0.1221786380297087,
      "grad_norm": 0.0011582202278077602,
      "learning_rate": 0.0002652061355252087,
      "loss": 0.0053,
      "step": 1900
    },
    {
      "epoch": 0.12282168349302296,
      "grad_norm": 0.0027575986459851265,
      "learning_rate": 0.0002650119733350592,
      "loss": 0.0001,
      "step": 1910
    },
    {
      "epoch": 0.12346472895633721,
      "grad_norm": 0.0031327102333307266,
      "learning_rate": 0.0002648178111449097,
      "loss": 0.0062,
      "step": 1920
    },
    {
      "epoch": 0.12410777441965147,
      "grad_norm": 0.00471592228859663,
      "learning_rate": 0.00026462364895476017,
      "loss": 0.0005,
      "step": 1930
    },
    {
      "epoch": 0.12475081988296573,
      "grad_norm": 2.4805333614349365,
      "learning_rate": 0.00026442948676461066,
      "loss": 0.0018,
      "step": 1940
    },
    {
      "epoch": 0.12539386534627997,
      "grad_norm": 0.004392293747514486,
      "learning_rate": 0.00026423532457446115,
      "loss": 0.0002,
      "step": 1950
    },
    {
      "epoch": 0.12603691080959423,
      "grad_norm": 0.00620949175208807,
      "learning_rate": 0.0002640411623843117,
      "loss": 0.0004,
      "step": 1960
    },
    {
      "epoch": 0.12667995627290848,
      "grad_norm": 0.013864264823496342,
      "learning_rate": 0.0002638470001941622,
      "loss": 0.0002,
      "step": 1970
    },
    {
      "epoch": 0.12732300173622274,
      "grad_norm": 0.0028646686114370823,
      "learning_rate": 0.00026365283800401266,
      "loss": 0.0005,
      "step": 1980
    },
    {
      "epoch": 0.127966047199537,
      "grad_norm": 0.01688055507838726,
      "learning_rate": 0.00026345867581386315,
      "loss": 0.0001,
      "step": 1990
    },
    {
      "epoch": 0.12860909266285125,
      "grad_norm": 0.004852600395679474,
      "learning_rate": 0.00026326451362371363,
      "loss": 0.0149,
      "step": 2000
    },
    {
      "epoch": 0.1292521381261655,
      "grad_norm": 0.02161761187016964,
      "learning_rate": 0.0002630703514335642,
      "loss": 0.0002,
      "step": 2010
    },
    {
      "epoch": 0.12989518358947977,
      "grad_norm": 0.00827043503522873,
      "learning_rate": 0.00026287618924341466,
      "loss": 0.0002,
      "step": 2020
    },
    {
      "epoch": 0.13053822905279402,
      "grad_norm": 0.0028795485850423574,
      "learning_rate": 0.00026268202705326515,
      "loss": 0.0002,
      "step": 2030
    },
    {
      "epoch": 0.13118127451610828,
      "grad_norm": 0.007492228876799345,
      "learning_rate": 0.00026248786486311564,
      "loss": 0.0001,
      "step": 2040
    },
    {
      "epoch": 0.13182431997942254,
      "grad_norm": 0.006215324625372887,
      "learning_rate": 0.0002622937026729661,
      "loss": 0.0001,
      "step": 2050
    },
    {
      "epoch": 0.1324673654427368,
      "grad_norm": 0.0010250447085127234,
      "learning_rate": 0.0002620995404828166,
      "loss": 0.0001,
      "step": 2060
    },
    {
      "epoch": 0.13311041090605105,
      "grad_norm": 0.007822278887033463,
      "learning_rate": 0.00026190537829266715,
      "loss": 0.0006,
      "step": 2070
    },
    {
      "epoch": 0.1337534563693653,
      "grad_norm": 0.0673484280705452,
      "learning_rate": 0.00026171121610251764,
      "loss": 0.0002,
      "step": 2080
    },
    {
      "epoch": 0.13439650183267957,
      "grad_norm": 0.646003246307373,
      "learning_rate": 0.0002615170539123681,
      "loss": 0.0004,
      "step": 2090
    },
    {
      "epoch": 0.13503954729599382,
      "grad_norm": 8.070077896118164,
      "learning_rate": 0.0002613228917222186,
      "loss": 0.0182,
      "step": 2100
    },
    {
      "epoch": 0.13568259275930808,
      "grad_norm": 0.1474233865737915,
      "learning_rate": 0.0002611287295320691,
      "loss": 0.0008,
      "step": 2110
    },
    {
      "epoch": 0.13632563822262234,
      "grad_norm": 0.009767885319888592,
      "learning_rate": 0.0002609345673419196,
      "loss": 0.0002,
      "step": 2120
    },
    {
      "epoch": 0.1369686836859366,
      "grad_norm": 0.0070116170682013035,
      "learning_rate": 0.0002607404051517701,
      "loss": 0.0013,
      "step": 2130
    },
    {
      "epoch": 0.13761172914925085,
      "grad_norm": 0.27659544348716736,
      "learning_rate": 0.0002605462429616206,
      "loss": 0.0147,
      "step": 2140
    },
    {
      "epoch": 0.1382547746125651,
      "grad_norm": 0.004004859831184149,
      "learning_rate": 0.0002603520807714711,
      "loss": 0.0005,
      "step": 2150
    },
    {
      "epoch": 0.13889782007587936,
      "grad_norm": 0.0060078841634094715,
      "learning_rate": 0.0002601579185813216,
      "loss": 0.0002,
      "step": 2160
    },
    {
      "epoch": 0.13954086553919362,
      "grad_norm": 0.002108905930072069,
      "learning_rate": 0.00025996375639117207,
      "loss": 0.0001,
      "step": 2170
    },
    {
      "epoch": 0.14018391100250788,
      "grad_norm": 0.09159491211175919,
      "learning_rate": 0.00025976959420102256,
      "loss": 0.0002,
      "step": 2180
    },
    {
      "epoch": 0.14082695646582213,
      "grad_norm": 0.003725531278178096,
      "learning_rate": 0.0002595754320108731,
      "loss": 0.0001,
      "step": 2190
    },
    {
      "epoch": 0.1414700019291364,
      "grad_norm": 0.10627997666597366,
      "learning_rate": 0.00025938126982072353,
      "loss": 0.0004,
      "step": 2200
    },
    {
      "epoch": 0.14211304739245065,
      "grad_norm": 0.0016980747459456325,
      "learning_rate": 0.000259187107630574,
      "loss": 0.0008,
      "step": 2210
    },
    {
      "epoch": 0.1427560928557649,
      "grad_norm": 0.006418861914426088,
      "learning_rate": 0.00025899294544042456,
      "loss": 0.0002,
      "step": 2220
    },
    {
      "epoch": 0.14339913831907916,
      "grad_norm": 0.01762063056230545,
      "learning_rate": 0.00025879878325027505,
      "loss": 0.0027,
      "step": 2230
    },
    {
      "epoch": 0.14404218378239342,
      "grad_norm": 0.002267261268571019,
      "learning_rate": 0.00025860462106012553,
      "loss": 0.0105,
      "step": 2240
    },
    {
      "epoch": 0.14468522924570767,
      "grad_norm": 0.014084878377616405,
      "learning_rate": 0.000258410458869976,
      "loss": 0.0003,
      "step": 2250
    },
    {
      "epoch": 0.14532827470902193,
      "grad_norm": 0.003333577886223793,
      "learning_rate": 0.0002582162966798265,
      "loss": 0.006,
      "step": 2260
    },
    {
      "epoch": 0.1459713201723362,
      "grad_norm": 0.05515008047223091,
      "learning_rate": 0.000258022134489677,
      "loss": 0.0004,
      "step": 2270
    },
    {
      "epoch": 0.14661436563565045,
      "grad_norm": 0.0059719388373196125,
      "learning_rate": 0.00025782797229952754,
      "loss": 0.0001,
      "step": 2280
    },
    {
      "epoch": 0.1472574110989647,
      "grad_norm": 0.012211314402520657,
      "learning_rate": 0.000257633810109378,
      "loss": 0.0001,
      "step": 2290
    },
    {
      "epoch": 0.14790045656227896,
      "grad_norm": 0.0035669077187776566,
      "learning_rate": 0.0002574396479192285,
      "loss": 0.0014,
      "step": 2300
    },
    {
      "epoch": 0.14854350202559322,
      "grad_norm": 0.04933662712574005,
      "learning_rate": 0.000257245485729079,
      "loss": 0.0004,
      "step": 2310
    },
    {
      "epoch": 0.14918654748890747,
      "grad_norm": 0.004903999622911215,
      "learning_rate": 0.0002570513235389295,
      "loss": 0.0147,
      "step": 2320
    },
    {
      "epoch": 0.14982959295222173,
      "grad_norm": 0.023824697360396385,
      "learning_rate": 0.00025685716134877997,
      "loss": 0.0073,
      "step": 2330
    },
    {
      "epoch": 0.150472638415536,
      "grad_norm": 0.0016845623031258583,
      "learning_rate": 0.0002566629991586305,
      "loss": 0.0004,
      "step": 2340
    },
    {
      "epoch": 0.15111568387885024,
      "grad_norm": 0.0009980786126106977,
      "learning_rate": 0.000256468836968481,
      "loss": 0.0001,
      "step": 2350
    },
    {
      "epoch": 0.1517587293421645,
      "grad_norm": 0.016589155420660973,
      "learning_rate": 0.0002562746747783315,
      "loss": 0.0001,
      "step": 2360
    },
    {
      "epoch": 0.15240177480547876,
      "grad_norm": 0.002498666290193796,
      "learning_rate": 0.00025608051258818197,
      "loss": 0.0001,
      "step": 2370
    },
    {
      "epoch": 0.153044820268793,
      "grad_norm": 0.013179491274058819,
      "learning_rate": 0.00025588635039803246,
      "loss": 0.0001,
      "step": 2380
    },
    {
      "epoch": 0.15368786573210727,
      "grad_norm": 0.006743419915437698,
      "learning_rate": 0.00025569218820788294,
      "loss": 0.0002,
      "step": 2390
    },
    {
      "epoch": 0.15433091119542153,
      "grad_norm": 0.005220800172537565,
      "learning_rate": 0.0002554980260177335,
      "loss": 0.0002,
      "step": 2400
    },
    {
      "epoch": 0.15497395665873578,
      "grad_norm": 2.5458271503448486,
      "learning_rate": 0.00025530386382758397,
      "loss": 0.0024,
      "step": 2410
    },
    {
      "epoch": 0.15561700212205004,
      "grad_norm": 0.007832231000065804,
      "learning_rate": 0.00025510970163743446,
      "loss": 0.0001,
      "step": 2420
    },
    {
      "epoch": 0.1562600475853643,
      "grad_norm": 0.008841807022690773,
      "learning_rate": 0.00025491553944728495,
      "loss": 0.0003,
      "step": 2430
    },
    {
      "epoch": 0.15690309304867855,
      "grad_norm": 0.00458518834784627,
      "learning_rate": 0.00025472137725713543,
      "loss": 0.0037,
      "step": 2440
    },
    {
      "epoch": 0.1575461385119928,
      "grad_norm": 0.027611246332526207,
      "learning_rate": 0.0002545272150669859,
      "loss": 0.0004,
      "step": 2450
    },
    {
      "epoch": 0.15818918397530704,
      "grad_norm": 0.005565909668803215,
      "learning_rate": 0.00025433305287683646,
      "loss": 0.0028,
      "step": 2460
    },
    {
      "epoch": 0.1588322294386213,
      "grad_norm": 0.0027518230490386486,
      "learning_rate": 0.00025413889068668695,
      "loss": 0.0005,
      "step": 2470
    },
    {
      "epoch": 0.15947527490193555,
      "grad_norm": 0.03381475433707237,
      "learning_rate": 0.00025394472849653743,
      "loss": 0.0004,
      "step": 2480
    },
    {
      "epoch": 0.1601183203652498,
      "grad_norm": 0.0011026720749214292,
      "learning_rate": 0.0002537505663063879,
      "loss": 0.0002,
      "step": 2490
    },
    {
      "epoch": 0.16076136582856407,
      "grad_norm": 0.001358479494228959,
      "learning_rate": 0.0002535564041162384,
      "loss": 0.0002,
      "step": 2500
    },
    {
      "epoch": 0.16140441129187832,
      "grad_norm": 0.00536693911999464,
      "learning_rate": 0.0002533622419260889,
      "loss": 0.0002,
      "step": 2510
    },
    {
      "epoch": 0.16204745675519258,
      "grad_norm": 0.0037661453243345022,
      "learning_rate": 0.00025316807973593944,
      "loss": 0.0002,
      "step": 2520
    },
    {
      "epoch": 0.16269050221850684,
      "grad_norm": 0.006853419356048107,
      "learning_rate": 0.00025297391754578987,
      "loss": 0.0001,
      "step": 2530
    },
    {
      "epoch": 0.1633335476818211,
      "grad_norm": 0.0007505735266022384,
      "learning_rate": 0.00025277975535564035,
      "loss": 0.0001,
      "step": 2540
    },
    {
      "epoch": 0.16397659314513535,
      "grad_norm": 0.0041548279114067554,
      "learning_rate": 0.0002525855931654909,
      "loss": 0.0001,
      "step": 2550
    },
    {
      "epoch": 0.1646196386084496,
      "grad_norm": 0.002442867960780859,
      "learning_rate": 0.0002523914309753414,
      "loss": 0.0001,
      "step": 2560
    },
    {
      "epoch": 0.16526268407176387,
      "grad_norm": 0.017122268676757812,
      "learning_rate": 0.00025219726878519187,
      "loss": 0.0001,
      "step": 2570
    },
    {
      "epoch": 0.16590572953507812,
      "grad_norm": 0.00404988881200552,
      "learning_rate": 0.00025200310659504236,
      "loss": 0.0001,
      "step": 2580
    },
    {
      "epoch": 0.16654877499839238,
      "grad_norm": 0.0010793603723868728,
      "learning_rate": 0.00025180894440489284,
      "loss": 0.0002,
      "step": 2590
    },
    {
      "epoch": 0.16719182046170664,
      "grad_norm": 0.004376713652163744,
      "learning_rate": 0.00025161478221474333,
      "loss": 0.0001,
      "step": 2600
    },
    {
      "epoch": 0.1678348659250209,
      "grad_norm": 0.017478493973612785,
      "learning_rate": 0.00025142062002459387,
      "loss": 0.0001,
      "step": 2610
    },
    {
      "epoch": 0.16847791138833515,
      "grad_norm": 0.005506112240254879,
      "learning_rate": 0.00025122645783444436,
      "loss": 0.0001,
      "step": 2620
    },
    {
      "epoch": 0.1691209568516494,
      "grad_norm": 0.0018271703738719225,
      "learning_rate": 0.00025103229564429484,
      "loss": 0.0001,
      "step": 2630
    },
    {
      "epoch": 0.16976400231496366,
      "grad_norm": 0.0009266684646718204,
      "learning_rate": 0.00025083813345414533,
      "loss": 0.0001,
      "step": 2640
    },
    {
      "epoch": 0.17040704777827792,
      "grad_norm": 0.7151983976364136,
      "learning_rate": 0.0002506439712639958,
      "loss": 0.0003,
      "step": 2650
    },
    {
      "epoch": 0.17105009324159218,
      "grad_norm": 0.0010134264593943954,
      "learning_rate": 0.0002504498090738463,
      "loss": 0.0001,
      "step": 2660
    },
    {
      "epoch": 0.17169313870490643,
      "grad_norm": 0.0018768520094454288,
      "learning_rate": 0.00025025564688369685,
      "loss": 0.0001,
      "step": 2670
    },
    {
      "epoch": 0.1723361841682207,
      "grad_norm": 0.000919938029255718,
      "learning_rate": 0.00025006148469354733,
      "loss": 0.0001,
      "step": 2680
    },
    {
      "epoch": 0.17297922963153495,
      "grad_norm": 0.008233933709561825,
      "learning_rate": 0.0002498673225033978,
      "loss": 0.0001,
      "step": 2690
    },
    {
      "epoch": 0.1736222750948492,
      "grad_norm": 0.0010037625906988978,
      "learning_rate": 0.0002496731603132483,
      "loss": 0.0001,
      "step": 2700
    },
    {
      "epoch": 0.17426532055816346,
      "grad_norm": 0.0009160226327367127,
      "learning_rate": 0.0002494789981230988,
      "loss": 0.0,
      "step": 2710
    },
    {
      "epoch": 0.17490836602147772,
      "grad_norm": 0.0009649403509683907,
      "learning_rate": 0.0002492848359329493,
      "loss": 0.0027,
      "step": 2720
    },
    {
      "epoch": 0.17555141148479197,
      "grad_norm": 0.0008224497432820499,
      "learning_rate": 0.0002490906737427998,
      "loss": 0.0003,
      "step": 2730
    },
    {
      "epoch": 0.17619445694810623,
      "grad_norm": 0.0032581225968897343,
      "learning_rate": 0.0002488965115526503,
      "loss": 0.0002,
      "step": 2740
    },
    {
      "epoch": 0.1768375024114205,
      "grad_norm": 0.0020258526783436537,
      "learning_rate": 0.0002487023493625008,
      "loss": 0.0015,
      "step": 2750
    },
    {
      "epoch": 0.17748054787473475,
      "grad_norm": 0.0014307360397651792,
      "learning_rate": 0.0002485081871723513,
      "loss": 0.0001,
      "step": 2760
    },
    {
      "epoch": 0.178123593338049,
      "grad_norm": 0.015721360221505165,
      "learning_rate": 0.00024831402498220177,
      "loss": 0.0003,
      "step": 2770
    },
    {
      "epoch": 0.17876663880136326,
      "grad_norm": 0.0007676612003706396,
      "learning_rate": 0.00024811986279205225,
      "loss": 0.0056,
      "step": 2780
    },
    {
      "epoch": 0.17940968426467752,
      "grad_norm": 0.00130753917619586,
      "learning_rate": 0.0002479257006019028,
      "loss": 0.0003,
      "step": 2790
    },
    {
      "epoch": 0.18005272972799177,
      "grad_norm": 0.005891694221645594,
      "learning_rate": 0.0002477315384117533,
      "loss": 0.0002,
      "step": 2800
    },
    {
      "epoch": 0.18069577519130603,
      "grad_norm": 0.002976464806124568,
      "learning_rate": 0.00024753737622160377,
      "loss": 0.0001,
      "step": 2810
    },
    {
      "epoch": 0.1813388206546203,
      "grad_norm": 0.0029810124542564154,
      "learning_rate": 0.00024734321403145426,
      "loss": 0.0001,
      "step": 2820
    },
    {
      "epoch": 0.18198186611793454,
      "grad_norm": 0.00107732939068228,
      "learning_rate": 0.00024714905184130474,
      "loss": 0.0002,
      "step": 2830
    },
    {
      "epoch": 0.1826249115812488,
      "grad_norm": 0.004161810502409935,
      "learning_rate": 0.00024695488965115523,
      "loss": 0.0002,
      "step": 2840
    },
    {
      "epoch": 0.18326795704456306,
      "grad_norm": 0.2963269054889679,
      "learning_rate": 0.00024676072746100577,
      "loss": 0.0002,
      "step": 2850
    },
    {
      "epoch": 0.1839110025078773,
      "grad_norm": 0.0007135164923965931,
      "learning_rate": 0.00024656656527085626,
      "loss": 0.0004,
      "step": 2860
    },
    {
      "epoch": 0.18455404797119157,
      "grad_norm": 0.003025020705536008,
      "learning_rate": 0.0002463724030807067,
      "loss": 0.0001,
      "step": 2870
    },
    {
      "epoch": 0.18519709343450583,
      "grad_norm": 0.0030700003262609243,
      "learning_rate": 0.00024617824089055723,
      "loss": 0.0017,
      "step": 2880
    },
    {
      "epoch": 0.18584013889782008,
      "grad_norm": 0.0026337415911257267,
      "learning_rate": 0.0002459840787004077,
      "loss": 0.0002,
      "step": 2890
    },
    {
      "epoch": 0.18648318436113434,
      "grad_norm": 0.0012460995931178331,
      "learning_rate": 0.0002457899165102582,
      "loss": 0.0002,
      "step": 2900
    },
    {
      "epoch": 0.1871262298244486,
      "grad_norm": 0.0106038898229599,
      "learning_rate": 0.0002455957543201087,
      "loss": 0.0001,
      "step": 2910
    },
    {
      "epoch": 0.18776927528776285,
      "grad_norm": 0.004017654340714216,
      "learning_rate": 0.0002454015921299592,
      "loss": 0.0012,
      "step": 2920
    },
    {
      "epoch": 0.1884123207510771,
      "grad_norm": 0.019488677382469177,
      "learning_rate": 0.00024520742993980966,
      "loss": 0.0002,
      "step": 2930
    },
    {
      "epoch": 0.18905536621439137,
      "grad_norm": 0.005857615731656551,
      "learning_rate": 0.0002450132677496602,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 0.18969841167770563,
      "grad_norm": 0.0022299091797322035,
      "learning_rate": 0.0002448191055595107,
      "loss": 0.0001,
      "step": 2950
    },
    {
      "epoch": 0.19034145714101988,
      "grad_norm": 0.0043983012437820435,
      "learning_rate": 0.0002446249433693612,
      "loss": 0.0002,
      "step": 2960
    },
    {
      "epoch": 0.19098450260433414,
      "grad_norm": 0.0011693881824612617,
      "learning_rate": 0.00024443078117921167,
      "loss": 0.0001,
      "step": 2970
    },
    {
      "epoch": 0.1916275480676484,
      "grad_norm": 0.003746580332517624,
      "learning_rate": 0.00024423661898906215,
      "loss": 0.0005,
      "step": 2980
    },
    {
      "epoch": 0.19227059353096265,
      "grad_norm": 0.010575980879366398,
      "learning_rate": 0.00024404245679891267,
      "loss": 0.0002,
      "step": 2990
    },
    {
      "epoch": 0.1929136389942769,
      "grad_norm": 0.003816065611317754,
      "learning_rate": 0.00024384829460876318,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 0.19355668445759114,
      "grad_norm": 0.002192346379160881,
      "learning_rate": 0.00024365413241861367,
      "loss": 0.0001,
      "step": 3010
    },
    {
      "epoch": 0.1941997299209054,
      "grad_norm": 0.006412872113287449,
      "learning_rate": 0.00024345997022846415,
      "loss": 0.0002,
      "step": 3020
    },
    {
      "epoch": 0.19484277538421965,
      "grad_norm": 0.00756146339699626,
      "learning_rate": 0.00024326580803831467,
      "loss": 0.0001,
      "step": 3030
    },
    {
      "epoch": 0.1954858208475339,
      "grad_norm": 0.004506303463131189,
      "learning_rate": 0.00024307164584816515,
      "loss": 0.0002,
      "step": 3040
    },
    {
      "epoch": 0.19612886631084817,
      "grad_norm": 0.005403468385338783,
      "learning_rate": 0.00024287748365801561,
      "loss": 0.0001,
      "step": 3050
    },
    {
      "epoch": 0.19677191177416242,
      "grad_norm": 0.000728958344552666,
      "learning_rate": 0.00024268332146786616,
      "loss": 0.0001,
      "step": 3060
    },
    {
      "epoch": 0.19741495723747668,
      "grad_norm": 0.007860369049012661,
      "learning_rate": 0.00024248915927771661,
      "loss": 0.0001,
      "step": 3070
    },
    {
      "epoch": 0.19805800270079094,
      "grad_norm": 0.0011039968812838197,
      "learning_rate": 0.0002422949970875671,
      "loss": 0.0001,
      "step": 3080
    },
    {
      "epoch": 0.1987010481641052,
      "grad_norm": 0.002619662554934621,
      "learning_rate": 0.00024210083489741762,
      "loss": 0.0001,
      "step": 3090
    },
    {
      "epoch": 0.19934409362741945,
      "grad_norm": 0.0057267495431005955,
      "learning_rate": 0.0002419066727072681,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 0.1999871390907337,
      "grad_norm": 0.010363448411226273,
      "learning_rate": 0.0002417125105171186,
      "loss": 0.0001,
      "step": 3110
    },
    {
      "epoch": 0.20063018455404796,
      "grad_norm": 0.0008244778728112578,
      "learning_rate": 0.0002415183483269691,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 0.20127323001736222,
      "grad_norm": 0.0009085029596462846,
      "learning_rate": 0.0002413241861368196,
      "loss": 0.0001,
      "step": 3130
    },
    {
      "epoch": 0.20191627548067648,
      "grad_norm": 0.0034309481270611286,
      "learning_rate": 0.00024113002394667008,
      "loss": 0.0017,
      "step": 3140
    },
    {
      "epoch": 0.20255932094399073,
      "grad_norm": 0.0028160319197922945,
      "learning_rate": 0.0002409358617565206,
      "loss": 0.0001,
      "step": 3150
    },
    {
      "epoch": 0.203202366407305,
      "grad_norm": 0.07280543446540833,
      "learning_rate": 0.00024074169956637108,
      "loss": 0.0001,
      "step": 3160
    },
    {
      "epoch": 0.20384541187061925,
      "grad_norm": 0.03231974318623543,
      "learning_rate": 0.00024054753737622156,
      "loss": 0.0001,
      "step": 3170
    },
    {
      "epoch": 0.2044884573339335,
      "grad_norm": 0.000311483396217227,
      "learning_rate": 0.00024035337518607208,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 0.20513150279724776,
      "grad_norm": 0.0016832239925861359,
      "learning_rate": 0.00024015921299592256,
      "loss": 0.0001,
      "step": 3190
    },
    {
      "epoch": 0.20577454826056202,
      "grad_norm": 0.0022068757098168135,
      "learning_rate": 0.00023996505080577308,
      "loss": 0.0001,
      "step": 3200
    },
    {
      "epoch": 0.20641759372387627,
      "grad_norm": 0.0021225628443062305,
      "learning_rate": 0.00023977088861562357,
      "loss": 0.0001,
      "step": 3210
    },
    {
      "epoch": 0.20706063918719053,
      "grad_norm": 0.021268513053655624,
      "learning_rate": 0.00023957672642547405,
      "loss": 0.0001,
      "step": 3220
    },
    {
      "epoch": 0.2077036846505048,
      "grad_norm": 0.002188304206356406,
      "learning_rate": 0.00023938256423532457,
      "loss": 0.0001,
      "step": 3230
    },
    {
      "epoch": 0.20834673011381905,
      "grad_norm": 0.003238971810787916,
      "learning_rate": 0.00023918840204517505,
      "loss": 0.0001,
      "step": 3240
    },
    {
      "epoch": 0.2089897755771333,
      "grad_norm": 3.515038013458252,
      "learning_rate": 0.00023899423985502554,
      "loss": 0.0093,
      "step": 3250
    },
    {
      "epoch": 0.20963282104044756,
      "grad_norm": 0.00807645171880722,
      "learning_rate": 0.00023880007766487605,
      "loss": 0.0002,
      "step": 3260
    },
    {
      "epoch": 0.21027586650376182,
      "grad_norm": 0.004367792047560215,
      "learning_rate": 0.00023860591547472654,
      "loss": 0.0028,
      "step": 3270
    },
    {
      "epoch": 0.21091891196707607,
      "grad_norm": 0.000928363821003586,
      "learning_rate": 0.00023841175328457703,
      "loss": 0.0002,
      "step": 3280
    },
    {
      "epoch": 0.21156195743039033,
      "grad_norm": 0.008833194151520729,
      "learning_rate": 0.00023821759109442754,
      "loss": 0.0055,
      "step": 3290
    },
    {
      "epoch": 0.2122050028937046,
      "grad_norm": 0.012534103356301785,
      "learning_rate": 0.00023802342890427803,
      "loss": 0.0058,
      "step": 3300
    },
    {
      "epoch": 0.21284804835701884,
      "grad_norm": 0.13422299921512604,
      "learning_rate": 0.00023782926671412851,
      "loss": 0.0002,
      "step": 3310
    },
    {
      "epoch": 0.2134910938203331,
      "grad_norm": 0.000935845251660794,
      "learning_rate": 0.00023763510452397903,
      "loss": 0.01,
      "step": 3320
    },
    {
      "epoch": 0.21413413928364736,
      "grad_norm": 0.006762643810361624,
      "learning_rate": 0.00023744094233382952,
      "loss": 0.0003,
      "step": 3330
    },
    {
      "epoch": 0.2147771847469616,
      "grad_norm": 0.07439117878675461,
      "learning_rate": 0.00023724678014368,
      "loss": 0.0097,
      "step": 3340
    },
    {
      "epoch": 0.21542023021027587,
      "grad_norm": 0.0616474449634552,
      "learning_rate": 0.00023705261795353052,
      "loss": 0.0015,
      "step": 3350
    },
    {
      "epoch": 0.21606327567359013,
      "grad_norm": 0.015223588794469833,
      "learning_rate": 0.000236858455763381,
      "loss": 0.0069,
      "step": 3360
    },
    {
      "epoch": 0.21670632113690438,
      "grad_norm": 0.0056967115961015224,
      "learning_rate": 0.0002366642935732315,
      "loss": 0.0002,
      "step": 3370
    },
    {
      "epoch": 0.21734936660021864,
      "grad_norm": 0.1770365685224533,
      "learning_rate": 0.000236470131383082,
      "loss": 0.0001,
      "step": 3380
    },
    {
      "epoch": 0.2179924120635329,
      "grad_norm": 1.1026736497879028,
      "learning_rate": 0.0002362759691929325,
      "loss": 0.0005,
      "step": 3390
    },
    {
      "epoch": 0.21863545752684715,
      "grad_norm": 0.007723941467702389,
      "learning_rate": 0.00023608180700278298,
      "loss": 0.0006,
      "step": 3400
    },
    {
      "epoch": 0.2192785029901614,
      "grad_norm": 0.008242171257734299,
      "learning_rate": 0.0002358876448126335,
      "loss": 0.0233,
      "step": 3410
    },
    {
      "epoch": 0.21992154845347567,
      "grad_norm": 0.009965606965124607,
      "learning_rate": 0.00023569348262248398,
      "loss": 0.0011,
      "step": 3420
    },
    {
      "epoch": 0.22056459391678992,
      "grad_norm": 0.0014116954989731312,
      "learning_rate": 0.00023549932043233444,
      "loss": 0.0003,
      "step": 3430
    },
    {
      "epoch": 0.22120763938010418,
      "grad_norm": 0.004546190612018108,
      "learning_rate": 0.00023530515824218498,
      "loss": 0.0084,
      "step": 3440
    },
    {
      "epoch": 0.22185068484341844,
      "grad_norm": 0.10401153564453125,
      "learning_rate": 0.00023511099605203544,
      "loss": 0.0004,
      "step": 3450
    },
    {
      "epoch": 0.2224937303067327,
      "grad_norm": 0.005652827210724354,
      "learning_rate": 0.00023491683386188592,
      "loss": 0.0002,
      "step": 3460
    },
    {
      "epoch": 0.22313677577004695,
      "grad_norm": 0.5723432302474976,
      "learning_rate": 0.00023472267167173644,
      "loss": 0.0003,
      "step": 3470
    },
    {
      "epoch": 0.2237798212333612,
      "grad_norm": 0.1099439337849617,
      "learning_rate": 0.00023452850948158693,
      "loss": 0.0001,
      "step": 3480
    },
    {
      "epoch": 0.22442286669667547,
      "grad_norm": 0.0013927860418334603,
      "learning_rate": 0.0002343343472914374,
      "loss": 0.0001,
      "step": 3490
    },
    {
      "epoch": 0.22506591215998972,
      "grad_norm": 0.037120521068573,
      "learning_rate": 0.00023414018510128793,
      "loss": 0.0001,
      "step": 3500
    },
    {
      "epoch": 0.22570895762330398,
      "grad_norm": 0.0011176024563610554,
      "learning_rate": 0.0002339460229111384,
      "loss": 0.0001,
      "step": 3510
    },
    {
      "epoch": 0.22635200308661824,
      "grad_norm": 0.00805222149938345,
      "learning_rate": 0.0002337518607209889,
      "loss": 0.0001,
      "step": 3520
    },
    {
      "epoch": 0.2269950485499325,
      "grad_norm": 0.0010786259081214666,
      "learning_rate": 0.0002335576985308394,
      "loss": 0.0002,
      "step": 3530
    },
    {
      "epoch": 0.22763809401324675,
      "grad_norm": 0.004448257852345705,
      "learning_rate": 0.0002333635363406899,
      "loss": 0.0001,
      "step": 3540
    },
    {
      "epoch": 0.22828113947656098,
      "grad_norm": 0.002155427122488618,
      "learning_rate": 0.0002331693741505404,
      "loss": 0.0001,
      "step": 3550
    },
    {
      "epoch": 0.22892418493987524,
      "grad_norm": 0.0017095949733629823,
      "learning_rate": 0.0002329752119603909,
      "loss": 0.0023,
      "step": 3560
    },
    {
      "epoch": 0.2295672304031895,
      "grad_norm": 0.007910589687526226,
      "learning_rate": 0.0002327810497702414,
      "loss": 0.0003,
      "step": 3570
    },
    {
      "epoch": 0.23021027586650375,
      "grad_norm": 0.028281379491090775,
      "learning_rate": 0.00023258688758009187,
      "loss": 0.0002,
      "step": 3580
    },
    {
      "epoch": 0.230853321329818,
      "grad_norm": 0.035426463931798935,
      "learning_rate": 0.0002323927253899424,
      "loss": 0.0004,
      "step": 3590
    },
    {
      "epoch": 0.23149636679313226,
      "grad_norm": 0.001843053032644093,
      "learning_rate": 0.00023219856319979288,
      "loss": 0.0031,
      "step": 3600
    },
    {
      "epoch": 0.23213941225644652,
      "grad_norm": 0.0017411489970982075,
      "learning_rate": 0.00023200440100964336,
      "loss": 0.0001,
      "step": 3610
    },
    {
      "epoch": 0.23278245771976078,
      "grad_norm": 0.0025965566746890545,
      "learning_rate": 0.00023181023881949388,
      "loss": 0.0001,
      "step": 3620
    },
    {
      "epoch": 0.23342550318307503,
      "grad_norm": 0.0016594716580584645,
      "learning_rate": 0.00023161607662934436,
      "loss": 0.0002,
      "step": 3630
    },
    {
      "epoch": 0.2340685486463893,
      "grad_norm": 0.0012997793965041637,
      "learning_rate": 0.00023142191443919485,
      "loss": 0.0001,
      "step": 3640
    },
    {
      "epoch": 0.23471159410970355,
      "grad_norm": 0.0017880109371617436,
      "learning_rate": 0.00023122775224904536,
      "loss": 0.0001,
      "step": 3650
    },
    {
      "epoch": 0.2353546395730178,
      "grad_norm": 0.005552095361053944,
      "learning_rate": 0.00023103359005889585,
      "loss": 0.0001,
      "step": 3660
    },
    {
      "epoch": 0.23599768503633206,
      "grad_norm": 0.15482789278030396,
      "learning_rate": 0.00023083942786874634,
      "loss": 0.0006,
      "step": 3670
    },
    {
      "epoch": 0.23664073049964632,
      "grad_norm": 13.634414672851562,
      "learning_rate": 0.00023064526567859685,
      "loss": 0.0085,
      "step": 3680
    },
    {
      "epoch": 0.23728377596296057,
      "grad_norm": 0.002204810967668891,
      "learning_rate": 0.00023045110348844734,
      "loss": 0.0001,
      "step": 3690
    },
    {
      "epoch": 0.23792682142627483,
      "grad_norm": 0.020028002560138702,
      "learning_rate": 0.00023025694129829782,
      "loss": 0.0001,
      "step": 3700
    },
    {
      "epoch": 0.2385698668895891,
      "grad_norm": 0.010080301202833652,
      "learning_rate": 0.00023006277910814834,
      "loss": 0.0002,
      "step": 3710
    },
    {
      "epoch": 0.23921291235290335,
      "grad_norm": 0.010731145739555359,
      "learning_rate": 0.00022986861691799882,
      "loss": 0.0001,
      "step": 3720
    },
    {
      "epoch": 0.2398559578162176,
      "grad_norm": 0.1383245885372162,
      "learning_rate": 0.0002296744547278493,
      "loss": 0.0013,
      "step": 3730
    },
    {
      "epoch": 0.24049900327953186,
      "grad_norm": 0.0020970411133021116,
      "learning_rate": 0.00022948029253769983,
      "loss": 0.0001,
      "step": 3740
    },
    {
      "epoch": 0.24114204874284612,
      "grad_norm": 0.001612857566215098,
      "learning_rate": 0.0002292861303475503,
      "loss": 0.0001,
      "step": 3750
    },
    {
      "epoch": 0.24178509420616037,
      "grad_norm": 0.02579456940293312,
      "learning_rate": 0.00022909196815740077,
      "loss": 0.0001,
      "step": 3760
    },
    {
      "epoch": 0.24242813966947463,
      "grad_norm": 0.0031805073376744986,
      "learning_rate": 0.0002288978059672513,
      "loss": 0.0001,
      "step": 3770
    },
    {
      "epoch": 0.2430711851327889,
      "grad_norm": 0.0024960963055491447,
      "learning_rate": 0.00022870364377710177,
      "loss": 0.0001,
      "step": 3780
    },
    {
      "epoch": 0.24371423059610314,
      "grad_norm": 0.004820927511900663,
      "learning_rate": 0.00022850948158695226,
      "loss": 0.0002,
      "step": 3790
    },
    {
      "epoch": 0.2443572760594174,
      "grad_norm": 0.0011982161086052656,
      "learning_rate": 0.0002283153193968028,
      "loss": 0.0002,
      "step": 3800
    },
    {
      "epoch": 0.24500032152273166,
      "grad_norm": 0.002723531797528267,
      "learning_rate": 0.00022812115720665326,
      "loss": 0.0001,
      "step": 3810
    },
    {
      "epoch": 0.2456433669860459,
      "grad_norm": 0.04682909697294235,
      "learning_rate": 0.00022792699501650375,
      "loss": 0.0001,
      "step": 3820
    },
    {
      "epoch": 0.24628641244936017,
      "grad_norm": 0.0010340214939787984,
      "learning_rate": 0.00022773283282635426,
      "loss": 0.0002,
      "step": 3830
    },
    {
      "epoch": 0.24692945791267443,
      "grad_norm": 0.010337949730455875,
      "learning_rate": 0.00022753867063620475,
      "loss": 0.0001,
      "step": 3840
    },
    {
      "epoch": 0.24757250337598868,
      "grad_norm": 0.002691086148843169,
      "learning_rate": 0.00022734450844605523,
      "loss": 0.0001,
      "step": 3850
    },
    {
      "epoch": 0.24821554883930294,
      "grad_norm": 0.0014174818061292171,
      "learning_rate": 0.00022715034625590575,
      "loss": 0.0001,
      "step": 3860
    },
    {
      "epoch": 0.2488585943026172,
      "grad_norm": 0.013149037025868893,
      "learning_rate": 0.00022695618406575624,
      "loss": 0.0001,
      "step": 3870
    },
    {
      "epoch": 0.24950163976593145,
      "grad_norm": 0.001287082675844431,
      "learning_rate": 0.00022676202187560672,
      "loss": 0.0001,
      "step": 3880
    },
    {
      "epoch": 0.2501446852292457,
      "grad_norm": 0.0004143227415625006,
      "learning_rate": 0.00022656785968545724,
      "loss": 0.0,
      "step": 3890
    },
    {
      "epoch": 0.25078773069255994,
      "grad_norm": 0.0008281385526061058,
      "learning_rate": 0.00022637369749530772,
      "loss": 0.0001,
      "step": 3900
    },
    {
      "epoch": 0.2514307761558742,
      "grad_norm": 0.001513587310910225,
      "learning_rate": 0.0002261795353051582,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 0.25207382161918845,
      "grad_norm": 0.0011311895214021206,
      "learning_rate": 0.00022598537311500872,
      "loss": 0.0046,
      "step": 3920
    },
    {
      "epoch": 0.25271686708250274,
      "grad_norm": 1.9374933242797852,
      "learning_rate": 0.0002257912109248592,
      "loss": 0.0004,
      "step": 3930
    },
    {
      "epoch": 0.25335991254581697,
      "grad_norm": 0.0038821990601718426,
      "learning_rate": 0.0002255970487347097,
      "loss": 0.0001,
      "step": 3940
    },
    {
      "epoch": 0.25400295800913125,
      "grad_norm": 0.0010278376284986734,
      "learning_rate": 0.0002254028865445602,
      "loss": 0.0005,
      "step": 3950
    },
    {
      "epoch": 0.2546460034724455,
      "grad_norm": 0.1037815734744072,
      "learning_rate": 0.0002252087243544107,
      "loss": 0.0001,
      "step": 3960
    },
    {
      "epoch": 0.25528904893575977,
      "grad_norm": 0.06033795699477196,
      "learning_rate": 0.00022501456216426118,
      "loss": 0.0001,
      "step": 3970
    },
    {
      "epoch": 0.255932094399074,
      "grad_norm": 0.0098046213388443,
      "learning_rate": 0.0002248203999741117,
      "loss": 0.0001,
      "step": 3980
    },
    {
      "epoch": 0.2565751398623883,
      "grad_norm": 0.0007994355401024222,
      "learning_rate": 0.00022462623778396218,
      "loss": 0.0032,
      "step": 3990
    },
    {
      "epoch": 0.2572181853257025,
      "grad_norm": 0.0006214666645973921,
      "learning_rate": 0.00022443207559381267,
      "loss": 0.0002,
      "step": 4000
    },
    {
      "epoch": 0.2578612307890168,
      "grad_norm": 0.010954838246107101,
      "learning_rate": 0.00022423791340366319,
      "loss": 0.0001,
      "step": 4010
    },
    {
      "epoch": 0.258504276252331,
      "grad_norm": 0.0021952814422547817,
      "learning_rate": 0.00022404375121351367,
      "loss": 0.0013,
      "step": 4020
    },
    {
      "epoch": 0.2591473217156453,
      "grad_norm": 0.0026948191225528717,
      "learning_rate": 0.00022384958902336416,
      "loss": 0.0002,
      "step": 4030
    },
    {
      "epoch": 0.25979036717895954,
      "grad_norm": 0.0012609190307557583,
      "learning_rate": 0.00022365542683321467,
      "loss": 0.0001,
      "step": 4040
    },
    {
      "epoch": 0.2604334126422738,
      "grad_norm": 0.0036800955422222614,
      "learning_rate": 0.00022346126464306516,
      "loss": 0.0001,
      "step": 4050
    },
    {
      "epoch": 0.26107645810558805,
      "grad_norm": 0.005062917247414589,
      "learning_rate": 0.00022326710245291565,
      "loss": 0.0001,
      "step": 4060
    },
    {
      "epoch": 0.26171950356890233,
      "grad_norm": 0.0036747080739587545,
      "learning_rate": 0.00022307294026276616,
      "loss": 0.0001,
      "step": 4070
    },
    {
      "epoch": 0.26236254903221656,
      "grad_norm": 0.0005405957344919443,
      "learning_rate": 0.00022287877807261665,
      "loss": 0.0001,
      "step": 4080
    },
    {
      "epoch": 0.26300559449553085,
      "grad_norm": 0.004908591974526644,
      "learning_rate": 0.00022268461588246713,
      "loss": 0.0001,
      "step": 4090
    },
    {
      "epoch": 0.2636486399588451,
      "grad_norm": 0.0006082929903641343,
      "learning_rate": 0.00022249045369231765,
      "loss": 0.0001,
      "step": 4100
    },
    {
      "epoch": 0.26429168542215936,
      "grad_norm": 0.004091289825737476,
      "learning_rate": 0.00022229629150216813,
      "loss": 0.0001,
      "step": 4110
    },
    {
      "epoch": 0.2649347308854736,
      "grad_norm": 0.0014625383773818612,
      "learning_rate": 0.0002221021293120186,
      "loss": 0.0001,
      "step": 4120
    },
    {
      "epoch": 0.2655777763487879,
      "grad_norm": 0.0016609576996415854,
      "learning_rate": 0.00022190796712186914,
      "loss": 0.0039,
      "step": 4130
    },
    {
      "epoch": 0.2662208218121021,
      "grad_norm": 0.008704137988388538,
      "learning_rate": 0.0002217138049317196,
      "loss": 0.0,
      "step": 4140
    },
    {
      "epoch": 0.2668638672754164,
      "grad_norm": 0.0019209346501156688,
      "learning_rate": 0.00022151964274157008,
      "loss": 0.0001,
      "step": 4150
    },
    {
      "epoch": 0.2675069127387306,
      "grad_norm": 0.0013986140256747603,
      "learning_rate": 0.0002213254805514206,
      "loss": 0.0002,
      "step": 4160
    },
    {
      "epoch": 0.2681499582020449,
      "grad_norm": 0.0023111016489565372,
      "learning_rate": 0.00022113131836127108,
      "loss": 0.0001,
      "step": 4170
    },
    {
      "epoch": 0.26879300366535913,
      "grad_norm": 0.00036424919380806386,
      "learning_rate": 0.00022093715617112157,
      "loss": 0.0003,
      "step": 4180
    },
    {
      "epoch": 0.2694360491286734,
      "grad_norm": 0.0009493785910308361,
      "learning_rate": 0.00022074299398097208,
      "loss": 0.0,
      "step": 4190
    },
    {
      "epoch": 0.27007909459198765,
      "grad_norm": 0.0012706192210316658,
      "learning_rate": 0.00022054883179082257,
      "loss": 0.0001,
      "step": 4200
    },
    {
      "epoch": 0.27072214005530193,
      "grad_norm": 1.437903642654419,
      "learning_rate": 0.00022035466960067306,
      "loss": 0.0003,
      "step": 4210
    },
    {
      "epoch": 0.27136518551861616,
      "grad_norm": 0.0334041491150856,
      "learning_rate": 0.00022016050741052357,
      "loss": 0.0001,
      "step": 4220
    },
    {
      "epoch": 0.27200823098193044,
      "grad_norm": 0.07090022414922714,
      "learning_rate": 0.00021996634522037406,
      "loss": 0.0225,
      "step": 4230
    },
    {
      "epoch": 0.2726512764452447,
      "grad_norm": 0.00542101077735424,
      "learning_rate": 0.00021977218303022454,
      "loss": 0.0009,
      "step": 4240
    },
    {
      "epoch": 0.27329432190855896,
      "grad_norm": 0.061505064368247986,
      "learning_rate": 0.00021957802084007506,
      "loss": 0.0009,
      "step": 4250
    },
    {
      "epoch": 0.2739373673718732,
      "grad_norm": 0.0031127005349844694,
      "learning_rate": 0.00021938385864992554,
      "loss": 0.0005,
      "step": 4260
    },
    {
      "epoch": 0.27458041283518747,
      "grad_norm": 0.034456606954336166,
      "learning_rate": 0.00021918969645977603,
      "loss": 0.0017,
      "step": 4270
    },
    {
      "epoch": 0.2752234582985017,
      "grad_norm": 0.005301982630044222,
      "learning_rate": 0.00021899553426962655,
      "loss": 0.0009,
      "step": 4280
    },
    {
      "epoch": 0.275866503761816,
      "grad_norm": 0.03121107630431652,
      "learning_rate": 0.00021880137207947703,
      "loss": 0.0015,
      "step": 4290
    },
    {
      "epoch": 0.2765095492251302,
      "grad_norm": 0.023596331477165222,
      "learning_rate": 0.00021860720988932752,
      "loss": 0.0037,
      "step": 4300
    },
    {
      "epoch": 0.2771525946884445,
      "grad_norm": 0.002833855804055929,
      "learning_rate": 0.00021841304769917803,
      "loss": 0.0002,
      "step": 4310
    },
    {
      "epoch": 0.2777956401517587,
      "grad_norm": 0.004798303823918104,
      "learning_rate": 0.00021821888550902852,
      "loss": 0.0018,
      "step": 4320
    },
    {
      "epoch": 0.278438685615073,
      "grad_norm": 0.0036847093142569065,
      "learning_rate": 0.000218024723318879,
      "loss": 0.0003,
      "step": 4330
    },
    {
      "epoch": 0.27908173107838724,
      "grad_norm": 0.014566939324140549,
      "learning_rate": 0.00021783056112872952,
      "loss": 0.0041,
      "step": 4340
    },
    {
      "epoch": 0.2797247765417015,
      "grad_norm": 0.0054976255632936954,
      "learning_rate": 0.00021763639893858,
      "loss": 0.0002,
      "step": 4350
    },
    {
      "epoch": 0.28036782200501575,
      "grad_norm": 0.034246500581502914,
      "learning_rate": 0.0002174422367484305,
      "loss": 0.0002,
      "step": 4360
    },
    {
      "epoch": 0.28101086746833,
      "grad_norm": 0.0050557563081383705,
      "learning_rate": 0.000217248074558281,
      "loss": 0.0002,
      "step": 4370
    },
    {
      "epoch": 0.28165391293164427,
      "grad_norm": 0.004938544239848852,
      "learning_rate": 0.0002170539123681315,
      "loss": 0.0066,
      "step": 4380
    },
    {
      "epoch": 0.2822969583949585,
      "grad_norm": 0.00516043696552515,
      "learning_rate": 0.00021685975017798198,
      "loss": 0.0002,
      "step": 4390
    },
    {
      "epoch": 0.2829400038582728,
      "grad_norm": 0.08477336913347244,
      "learning_rate": 0.0002166655879878325,
      "loss": 0.0003,
      "step": 4400
    },
    {
      "epoch": 0.283583049321587,
      "grad_norm": 0.02259998954832554,
      "learning_rate": 0.00021647142579768298,
      "loss": 0.0002,
      "step": 4410
    },
    {
      "epoch": 0.2842260947849013,
      "grad_norm": 5.392057418823242,
      "learning_rate": 0.00021627726360753347,
      "loss": 0.0047,
      "step": 4420
    },
    {
      "epoch": 0.2848691402482155,
      "grad_norm": 0.003461760003119707,
      "learning_rate": 0.00021608310141738398,
      "loss": 0.0001,
      "step": 4430
    },
    {
      "epoch": 0.2855121857115298,
      "grad_norm": 0.0013166216667741537,
      "learning_rate": 0.00021588893922723447,
      "loss": 0.0001,
      "step": 4440
    },
    {
      "epoch": 0.28615523117484404,
      "grad_norm": 0.004805993288755417,
      "learning_rate": 0.00021569477703708498,
      "loss": 0.0001,
      "step": 4450
    },
    {
      "epoch": 0.2867982766381583,
      "grad_norm": 0.0025365862529724836,
      "learning_rate": 0.00021550061484693547,
      "loss": 0.0001,
      "step": 4460
    },
    {
      "epoch": 0.28744132210147255,
      "grad_norm": 0.4985528588294983,
      "learning_rate": 0.00021530645265678596,
      "loss": 0.0002,
      "step": 4470
    },
    {
      "epoch": 0.28808436756478684,
      "grad_norm": 0.006580046843737364,
      "learning_rate": 0.00021511229046663647,
      "loss": 0.001,
      "step": 4480
    },
    {
      "epoch": 0.28872741302810107,
      "grad_norm": 0.002615205943584442,
      "learning_rate": 0.00021491812827648696,
      "loss": 0.0001,
      "step": 4490
    },
    {
      "epoch": 0.28937045849141535,
      "grad_norm": 0.08293542265892029,
      "learning_rate": 0.00021472396608633742,
      "loss": 0.0001,
      "step": 4500
    },
    {
      "epoch": 0.2900135039547296,
      "grad_norm": 1.0063881874084473,
      "learning_rate": 0.00021452980389618796,
      "loss": 0.0002,
      "step": 4510
    },
    {
      "epoch": 0.29065654941804386,
      "grad_norm": 0.00454728864133358,
      "learning_rate": 0.00021433564170603842,
      "loss": 0.0096,
      "step": 4520
    },
    {
      "epoch": 0.2912995948813581,
      "grad_norm": 0.010537977330386639,
      "learning_rate": 0.0002141414795158889,
      "loss": 0.0074,
      "step": 4530
    },
    {
      "epoch": 0.2919426403446724,
      "grad_norm": 0.02997523359954357,
      "learning_rate": 0.00021394731732573942,
      "loss": 0.0003,
      "step": 4540
    },
    {
      "epoch": 0.2925856858079866,
      "grad_norm": 0.043629348278045654,
      "learning_rate": 0.0002137531551355899,
      "loss": 0.0002,
      "step": 4550
    },
    {
      "epoch": 0.2932287312713009,
      "grad_norm": 0.014157540164887905,
      "learning_rate": 0.0002135589929454404,
      "loss": 0.0001,
      "step": 4560
    },
    {
      "epoch": 0.2938717767346151,
      "grad_norm": 0.01038400363177061,
      "learning_rate": 0.0002133648307552909,
      "loss": 0.0002,
      "step": 4570
    },
    {
      "epoch": 0.2945148221979294,
      "grad_norm": 0.0032363932114094496,
      "learning_rate": 0.0002131706685651414,
      "loss": 0.0014,
      "step": 4580
    },
    {
      "epoch": 0.29515786766124363,
      "grad_norm": 0.0035897986963391304,
      "learning_rate": 0.00021297650637499188,
      "loss": 0.0001,
      "step": 4590
    },
    {
      "epoch": 0.2958009131245579,
      "grad_norm": 0.0010806118370965123,
      "learning_rate": 0.0002127823441848424,
      "loss": 0.0003,
      "step": 4600
    },
    {
      "epoch": 0.29644395858787215,
      "grad_norm": 0.00030678423354402184,
      "learning_rate": 0.00021258818199469288,
      "loss": 0.0001,
      "step": 4610
    },
    {
      "epoch": 0.29708700405118643,
      "grad_norm": 0.0048354752361774445,
      "learning_rate": 0.00021239401980454337,
      "loss": 0.0001,
      "step": 4620
    },
    {
      "epoch": 0.29773004951450066,
      "grad_norm": 0.0010556989582255483,
      "learning_rate": 0.00021219985761439388,
      "loss": 0.0002,
      "step": 4630
    },
    {
      "epoch": 0.29837309497781495,
      "grad_norm": 0.007903434336185455,
      "learning_rate": 0.00021200569542424437,
      "loss": 0.0001,
      "step": 4640
    },
    {
      "epoch": 0.2990161404411292,
      "grad_norm": 0.0030005834996700287,
      "learning_rate": 0.00021181153323409485,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 0.29965918590444346,
      "grad_norm": 0.013434093445539474,
      "learning_rate": 0.00021161737104394537,
      "loss": 0.0001,
      "step": 4660
    },
    {
      "epoch": 0.3003022313677577,
      "grad_norm": 0.011719143949449062,
      "learning_rate": 0.00021142320885379586,
      "loss": 0.0016,
      "step": 4670
    },
    {
      "epoch": 0.300945276831072,
      "grad_norm": 0.06532979756593704,
      "learning_rate": 0.00021122904666364634,
      "loss": 0.0001,
      "step": 4680
    },
    {
      "epoch": 0.3015883222943862,
      "grad_norm": 0.0038081342354416847,
      "learning_rate": 0.00021103488447349686,
      "loss": 0.0001,
      "step": 4690
    },
    {
      "epoch": 0.3022313677577005,
      "grad_norm": 0.0010328099597245455,
      "learning_rate": 0.00021084072228334734,
      "loss": 0.0001,
      "step": 4700
    },
    {
      "epoch": 0.3028744132210147,
      "grad_norm": 0.0009167915559373796,
      "learning_rate": 0.00021064656009319783,
      "loss": 0.0001,
      "step": 4710
    },
    {
      "epoch": 0.303517458684329,
      "grad_norm": 0.005539823789149523,
      "learning_rate": 0.00021045239790304834,
      "loss": 0.0002,
      "step": 4720
    },
    {
      "epoch": 0.30416050414764323,
      "grad_norm": 0.004099482670426369,
      "learning_rate": 0.00021025823571289883,
      "loss": 0.0001,
      "step": 4730
    },
    {
      "epoch": 0.3048035496109575,
      "grad_norm": 0.0004480456409510225,
      "learning_rate": 0.00021006407352274932,
      "loss": 0.0204,
      "step": 4740
    },
    {
      "epoch": 0.30544659507427174,
      "grad_norm": 0.0016756089171394706,
      "learning_rate": 0.00020986991133259983,
      "loss": 0.0001,
      "step": 4750
    },
    {
      "epoch": 0.306089640537586,
      "grad_norm": 0.001921917893923819,
      "learning_rate": 0.00020967574914245032,
      "loss": 0.0003,
      "step": 4760
    },
    {
      "epoch": 0.30673268600090026,
      "grad_norm": 0.016566837206482887,
      "learning_rate": 0.0002094815869523008,
      "loss": 0.0005,
      "step": 4770
    },
    {
      "epoch": 0.30737573146421454,
      "grad_norm": 0.0019698161631822586,
      "learning_rate": 0.00020928742476215132,
      "loss": 0.0001,
      "step": 4780
    },
    {
      "epoch": 0.30801877692752877,
      "grad_norm": 0.012309960089623928,
      "learning_rate": 0.0002090932625720018,
      "loss": 0.0002,
      "step": 4790
    },
    {
      "epoch": 0.30866182239084305,
      "grad_norm": 0.004223220515996218,
      "learning_rate": 0.0002088991003818523,
      "loss": 0.0003,
      "step": 4800
    },
    {
      "epoch": 0.3093048678541573,
      "grad_norm": 0.0028714979998767376,
      "learning_rate": 0.0002087049381917028,
      "loss": 0.0001,
      "step": 4810
    },
    {
      "epoch": 0.30994791331747157,
      "grad_norm": 0.0048024337738752365,
      "learning_rate": 0.0002085107760015533,
      "loss": 0.0001,
      "step": 4820
    },
    {
      "epoch": 0.3105909587807858,
      "grad_norm": 0.0013854127610102296,
      "learning_rate": 0.00020831661381140375,
      "loss": 0.0001,
      "step": 4830
    },
    {
      "epoch": 0.3112340042441001,
      "grad_norm": 0.0008692371775396168,
      "learning_rate": 0.0002081224516212543,
      "loss": 0.0001,
      "step": 4840
    },
    {
      "epoch": 0.3118770497074143,
      "grad_norm": 0.000668401422444731,
      "learning_rate": 0.00020792828943110475,
      "loss": 0.0001,
      "step": 4850
    },
    {
      "epoch": 0.3125200951707286,
      "grad_norm": 0.016971377655863762,
      "learning_rate": 0.00020773412724095524,
      "loss": 0.0003,
      "step": 4860
    },
    {
      "epoch": 0.3131631406340428,
      "grad_norm": 0.029836613684892654,
      "learning_rate": 0.00020753996505080578,
      "loss": 0.0001,
      "step": 4870
    },
    {
      "epoch": 0.3138061860973571,
      "grad_norm": 0.006859369110316038,
      "learning_rate": 0.00020734580286065624,
      "loss": 0.0002,
      "step": 4880
    },
    {
      "epoch": 0.31444923156067134,
      "grad_norm": 20.210296630859375,
      "learning_rate": 0.00020715164067050673,
      "loss": 0.0106,
      "step": 4890
    },
    {
      "epoch": 0.3150922770239856,
      "grad_norm": 0.005935616325587034,
      "learning_rate": 0.00020695747848035724,
      "loss": 0.0001,
      "step": 4900
    },
    {
      "epoch": 0.31573532248729985,
      "grad_norm": 0.0026404033415019512,
      "learning_rate": 0.00020676331629020773,
      "loss": 0.0002,
      "step": 4910
    },
    {
      "epoch": 0.3163783679506141,
      "grad_norm": 0.1833839863538742,
      "learning_rate": 0.00020656915410005821,
      "loss": 0.0002,
      "step": 4920
    },
    {
      "epoch": 0.31702141341392837,
      "grad_norm": 0.0013257110258564353,
      "learning_rate": 0.00020637499190990873,
      "loss": 0.0001,
      "step": 4930
    },
    {
      "epoch": 0.3176644588772426,
      "grad_norm": 0.003518626792356372,
      "learning_rate": 0.00020618082971975922,
      "loss": 0.0002,
      "step": 4940
    },
    {
      "epoch": 0.3183075043405569,
      "grad_norm": 0.0034765200689435005,
      "learning_rate": 0.0002059866675296097,
      "loss": 0.0003,
      "step": 4950
    },
    {
      "epoch": 0.3189505498038711,
      "grad_norm": 0.0018719836371019483,
      "learning_rate": 0.00020579250533946022,
      "loss": 0.0001,
      "step": 4960
    },
    {
      "epoch": 0.3195935952671854,
      "grad_norm": 0.0007138579967431724,
      "learning_rate": 0.0002055983431493107,
      "loss": 0.0001,
      "step": 4970
    },
    {
      "epoch": 0.3202366407304996,
      "grad_norm": 0.032497767359018326,
      "learning_rate": 0.0002054041809591612,
      "loss": 0.0021,
      "step": 4980
    },
    {
      "epoch": 0.3208796861938139,
      "grad_norm": 0.002566020004451275,
      "learning_rate": 0.0002052100187690117,
      "loss": 0.0001,
      "step": 4990
    },
    {
      "epoch": 0.32152273165712814,
      "grad_norm": 0.000561542168725282,
      "learning_rate": 0.0002050158565788622,
      "loss": 0.0001,
      "step": 5000
    },
    {
      "epoch": 0.3221657771204424,
      "grad_norm": 0.0016562276287004352,
      "learning_rate": 0.00020482169438871268,
      "loss": 0.0001,
      "step": 5010
    },
    {
      "epoch": 0.32280882258375665,
      "grad_norm": 0.003302366007119417,
      "learning_rate": 0.0002046275321985632,
      "loss": 0.0099,
      "step": 5020
    },
    {
      "epoch": 0.32345186804707093,
      "grad_norm": 0.0020678630098700523,
      "learning_rate": 0.00020443337000841368,
      "loss": 0.0005,
      "step": 5030
    },
    {
      "epoch": 0.32409491351038516,
      "grad_norm": 0.0017796186730265617,
      "learning_rate": 0.00020423920781826416,
      "loss": 0.0181,
      "step": 5040
    },
    {
      "epoch": 0.32473795897369945,
      "grad_norm": 0.0035685126204043627,
      "learning_rate": 0.00020404504562811468,
      "loss": 0.0002,
      "step": 5050
    },
    {
      "epoch": 0.3253810044370137,
      "grad_norm": 9.325828552246094,
      "learning_rate": 0.00020385088343796517,
      "loss": 0.0008,
      "step": 5060
    },
    {
      "epoch": 0.32602404990032796,
      "grad_norm": 0.026107989251613617,
      "learning_rate": 0.00020365672124781565,
      "loss": 0.0003,
      "step": 5070
    },
    {
      "epoch": 0.3266670953636422,
      "grad_norm": 0.023607295006513596,
      "learning_rate": 0.00020346255905766617,
      "loss": 0.0002,
      "step": 5080
    },
    {
      "epoch": 0.3273101408269565,
      "grad_norm": 0.0036239062901586294,
      "learning_rate": 0.00020326839686751665,
      "loss": 0.0001,
      "step": 5090
    },
    {
      "epoch": 0.3279531862902707,
      "grad_norm": 0.002622301923111081,
      "learning_rate": 0.00020307423467736714,
      "loss": 0.0073,
      "step": 5100
    },
    {
      "epoch": 0.328596231753585,
      "grad_norm": 0.012889828532934189,
      "learning_rate": 0.00020288007248721765,
      "loss": 0.0074,
      "step": 5110
    },
    {
      "epoch": 0.3292392772168992,
      "grad_norm": 0.014833415858447552,
      "learning_rate": 0.00020268591029706814,
      "loss": 0.0001,
      "step": 5120
    },
    {
      "epoch": 0.3298823226802135,
      "grad_norm": 0.08644358068704605,
      "learning_rate": 0.00020249174810691863,
      "loss": 0.0072,
      "step": 5130
    },
    {
      "epoch": 0.33052536814352773,
      "grad_norm": 0.0036115634720772505,
      "learning_rate": 0.00020229758591676914,
      "loss": 0.0003,
      "step": 5140
    },
    {
      "epoch": 0.331168413606842,
      "grad_norm": 0.005299827549606562,
      "learning_rate": 0.00020210342372661963,
      "loss": 0.0003,
      "step": 5150
    },
    {
      "epoch": 0.33181145907015624,
      "grad_norm": 0.007456258870661259,
      "learning_rate": 0.00020190926153647011,
      "loss": 0.0001,
      "step": 5160
    },
    {
      "epoch": 0.33245450453347053,
      "grad_norm": 0.013777051120996475,
      "learning_rate": 0.00020171509934632063,
      "loss": 0.0001,
      "step": 5170
    },
    {
      "epoch": 0.33309754999678476,
      "grad_norm": 0.042210690677165985,
      "learning_rate": 0.00020152093715617112,
      "loss": 0.0001,
      "step": 5180
    },
    {
      "epoch": 0.33374059546009904,
      "grad_norm": 0.0005020174430683255,
      "learning_rate": 0.00020132677496602157,
      "loss": 0.0001,
      "step": 5190
    },
    {
      "epoch": 0.3343836409234133,
      "grad_norm": 0.0009660233044996858,
      "learning_rate": 0.00020113261277587212,
      "loss": 0.0002,
      "step": 5200
    },
    {
      "epoch": 0.33502668638672756,
      "grad_norm": 0.002697199583053589,
      "learning_rate": 0.00020093845058572258,
      "loss": 0.0001,
      "step": 5210
    },
    {
      "epoch": 0.3356697318500418,
      "grad_norm": 0.0010388368973508477,
      "learning_rate": 0.00020074428839557306,
      "loss": 0.0001,
      "step": 5220
    },
    {
      "epoch": 0.33631277731335607,
      "grad_norm": 0.0010246256133541465,
      "learning_rate": 0.00020055012620542358,
      "loss": 0.0001,
      "step": 5230
    },
    {
      "epoch": 0.3369558227766703,
      "grad_norm": 0.002224060008302331,
      "learning_rate": 0.00020035596401527406,
      "loss": 0.0001,
      "step": 5240
    },
    {
      "epoch": 0.3375988682399846,
      "grad_norm": 0.0009461173904128373,
      "learning_rate": 0.00020016180182512455,
      "loss": 0.0001,
      "step": 5250
    },
    {
      "epoch": 0.3382419137032988,
      "grad_norm": 0.00215711398050189,
      "learning_rate": 0.00019996763963497506,
      "loss": 0.0001,
      "step": 5260
    },
    {
      "epoch": 0.3388849591666131,
      "grad_norm": 0.006435705814510584,
      "learning_rate": 0.00019977347744482555,
      "loss": 0.0002,
      "step": 5270
    },
    {
      "epoch": 0.3395280046299273,
      "grad_norm": 0.0016490633133798838,
      "learning_rate": 0.00019957931525467604,
      "loss": 0.0,
      "step": 5280
    },
    {
      "epoch": 0.3401710500932416,
      "grad_norm": 0.0010877236491069198,
      "learning_rate": 0.00019938515306452655,
      "loss": 0.0001,
      "step": 5290
    },
    {
      "epoch": 0.34081409555655584,
      "grad_norm": 0.0029182308353483677,
      "learning_rate": 0.00019919099087437704,
      "loss": 0.016,
      "step": 5300
    },
    {
      "epoch": 0.3414571410198701,
      "grad_norm": 0.000842285284306854,
      "learning_rate": 0.00019899682868422752,
      "loss": 0.0001,
      "step": 5310
    },
    {
      "epoch": 0.34210018648318435,
      "grad_norm": 0.3945971131324768,
      "learning_rate": 0.00019880266649407804,
      "loss": 0.0002,
      "step": 5320
    },
    {
      "epoch": 0.34274323194649864,
      "grad_norm": 0.009469493292272091,
      "learning_rate": 0.00019860850430392853,
      "loss": 0.0001,
      "step": 5330
    },
    {
      "epoch": 0.34338627740981287,
      "grad_norm": 0.0022488010581582785,
      "learning_rate": 0.000198414342113779,
      "loss": 0.0001,
      "step": 5340
    },
    {
      "epoch": 0.34402932287312715,
      "grad_norm": 0.0014770155539736152,
      "learning_rate": 0.00019822017992362953,
      "loss": 0.0001,
      "step": 5350
    },
    {
      "epoch": 0.3446723683364414,
      "grad_norm": 0.0015726228011772037,
      "learning_rate": 0.00019802601773348,
      "loss": 0.0001,
      "step": 5360
    },
    {
      "epoch": 0.34531541379975567,
      "grad_norm": 0.0013047344982624054,
      "learning_rate": 0.0001978318555433305,
      "loss": 0.0001,
      "step": 5370
    },
    {
      "epoch": 0.3459584592630699,
      "grad_norm": 0.00504881888628006,
      "learning_rate": 0.000197637693353181,
      "loss": 0.0001,
      "step": 5380
    },
    {
      "epoch": 0.3466015047263842,
      "grad_norm": 0.003770547453314066,
      "learning_rate": 0.0001974435311630315,
      "loss": 0.0,
      "step": 5390
    },
    {
      "epoch": 0.3472445501896984,
      "grad_norm": 0.0012459015706554055,
      "learning_rate": 0.000197249368972882,
      "loss": 0.0001,
      "step": 5400
    },
    {
      "epoch": 0.3478875956530127,
      "grad_norm": 0.0015902961604297161,
      "learning_rate": 0.0001970552067827325,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 0.3485306411163269,
      "grad_norm": 0.0020683519542217255,
      "learning_rate": 0.000196861044592583,
      "loss": 0.0001,
      "step": 5420
    },
    {
      "epoch": 0.3491736865796412,
      "grad_norm": 0.0005725260707549751,
      "learning_rate": 0.00019666688240243347,
      "loss": 0.0001,
      "step": 5430
    },
    {
      "epoch": 0.34981673204295544,
      "grad_norm": 0.002183082979172468,
      "learning_rate": 0.000196472720212284,
      "loss": 0.0,
      "step": 5440
    },
    {
      "epoch": 0.3504597775062697,
      "grad_norm": 0.004558494780212641,
      "learning_rate": 0.00019627855802213448,
      "loss": 0.0001,
      "step": 5450
    },
    {
      "epoch": 0.35110282296958395,
      "grad_norm": 0.0066748070530593395,
      "learning_rate": 0.00019608439583198496,
      "loss": 0.0001,
      "step": 5460
    },
    {
      "epoch": 0.3517458684328982,
      "grad_norm": 0.005938533693552017,
      "learning_rate": 0.00019589023364183548,
      "loss": 0.0001,
      "step": 5470
    },
    {
      "epoch": 0.35238891389621246,
      "grad_norm": 0.0010352043900638819,
      "learning_rate": 0.00019569607145168596,
      "loss": 0.0,
      "step": 5480
    },
    {
      "epoch": 0.3530319593595267,
      "grad_norm": 0.00315073155798018,
      "learning_rate": 0.00019550190926153645,
      "loss": 0.0,
      "step": 5490
    },
    {
      "epoch": 0.353675004822841,
      "grad_norm": 0.0008101737475953996,
      "learning_rate": 0.00019530774707138696,
      "loss": 0.0001,
      "step": 5500
    },
    {
      "epoch": 0.3543180502861552,
      "grad_norm": 0.0010750412475317717,
      "learning_rate": 0.00019511358488123745,
      "loss": 0.0,
      "step": 5510
    },
    {
      "epoch": 0.3549610957494695,
      "grad_norm": 0.0008441470563411713,
      "learning_rate": 0.0001949194226910879,
      "loss": 0.0,
      "step": 5520
    },
    {
      "epoch": 0.3556041412127837,
      "grad_norm": 0.0016872339183464646,
      "learning_rate": 0.00019472526050093845,
      "loss": 0.0001,
      "step": 5530
    },
    {
      "epoch": 0.356247186676098,
      "grad_norm": 0.0075125377625226974,
      "learning_rate": 0.00019453109831078894,
      "loss": 0.0,
      "step": 5540
    },
    {
      "epoch": 0.35689023213941223,
      "grad_norm": 0.0005545731401070952,
      "learning_rate": 0.0001943369361206394,
      "loss": 0.001,
      "step": 5550
    },
    {
      "epoch": 0.3575332776027265,
      "grad_norm": 0.0015452710213139653,
      "learning_rate": 0.00019414277393048994,
      "loss": 0.0001,
      "step": 5560
    },
    {
      "epoch": 0.35817632306604075,
      "grad_norm": 0.0006133040296845138,
      "learning_rate": 0.0001939486117403404,
      "loss": 0.0001,
      "step": 5570
    },
    {
      "epoch": 0.35881936852935503,
      "grad_norm": 0.004122256301343441,
      "learning_rate": 0.00019375444955019088,
      "loss": 0.0001,
      "step": 5580
    },
    {
      "epoch": 0.35946241399266926,
      "grad_norm": 0.002295074053108692,
      "learning_rate": 0.0001935602873600414,
      "loss": 0.0008,
      "step": 5590
    },
    {
      "epoch": 0.36010545945598355,
      "grad_norm": 0.002655946183949709,
      "learning_rate": 0.00019336612516989189,
      "loss": 0.0304,
      "step": 5600
    },
    {
      "epoch": 0.3607485049192978,
      "grad_norm": 0.03406115621328354,
      "learning_rate": 0.00019317196297974237,
      "loss": 0.0048,
      "step": 5610
    },
    {
      "epoch": 0.36139155038261206,
      "grad_norm": 0.021329719573259354,
      "learning_rate": 0.00019297780078959289,
      "loss": 0.0036,
      "step": 5620
    },
    {
      "epoch": 0.3620345958459263,
      "grad_norm": 0.028583137318491936,
      "learning_rate": 0.00019278363859944337,
      "loss": 0.0002,
      "step": 5630
    },
    {
      "epoch": 0.3626776413092406,
      "grad_norm": 0.03039558231830597,
      "learning_rate": 0.00019258947640929386,
      "loss": 0.0009,
      "step": 5640
    },
    {
      "epoch": 0.3633206867725548,
      "grad_norm": 0.0057157110422849655,
      "learning_rate": 0.00019239531421914437,
      "loss": 0.0006,
      "step": 5650
    },
    {
      "epoch": 0.3639637322358691,
      "grad_norm": 0.0058264657855033875,
      "learning_rate": 0.00019220115202899486,
      "loss": 0.0001,
      "step": 5660
    },
    {
      "epoch": 0.3646067776991833,
      "grad_norm": 0.005463923327624798,
      "learning_rate": 0.00019200698983884535,
      "loss": 0.0005,
      "step": 5670
    },
    {
      "epoch": 0.3652498231624976,
      "grad_norm": 0.004950022790580988,
      "learning_rate": 0.00019181282764869586,
      "loss": 0.0008,
      "step": 5680
    },
    {
      "epoch": 0.36589286862581183,
      "grad_norm": 0.004736654926091433,
      "learning_rate": 0.00019161866545854635,
      "loss": 0.0001,
      "step": 5690
    },
    {
      "epoch": 0.3665359140891261,
      "grad_norm": 0.0025505817029625177,
      "learning_rate": 0.00019142450326839686,
      "loss": 0.0006,
      "step": 5700
    },
    {
      "epoch": 0.36717895955244034,
      "grad_norm": 0.002771383384242654,
      "learning_rate": 0.00019123034107824735,
      "loss": 0.0001,
      "step": 5710
    },
    {
      "epoch": 0.3678220050157546,
      "grad_norm": 0.04781683161854744,
      "learning_rate": 0.00019103617888809784,
      "loss": 0.0004,
      "step": 5720
    },
    {
      "epoch": 0.36846505047906886,
      "grad_norm": 0.004718084819614887,
      "learning_rate": 0.00019084201669794835,
      "loss": 0.0022,
      "step": 5730
    },
    {
      "epoch": 0.36910809594238314,
      "grad_norm": 0.004321399610489607,
      "learning_rate": 0.00019064785450779884,
      "loss": 0.0001,
      "step": 5740
    },
    {
      "epoch": 0.36975114140569737,
      "grad_norm": 0.0011718375608325005,
      "learning_rate": 0.00019045369231764932,
      "loss": 0.0001,
      "step": 5750
    },
    {
      "epoch": 0.37039418686901165,
      "grad_norm": 0.113779716193676,
      "learning_rate": 0.00019025953012749984,
      "loss": 0.0002,
      "step": 5760
    },
    {
      "epoch": 0.3710372323323259,
      "grad_norm": 0.006680646911263466,
      "learning_rate": 0.00019006536793735032,
      "loss": 0.0001,
      "step": 5770
    },
    {
      "epoch": 0.37168027779564017,
      "grad_norm": 0.00157972052693367,
      "learning_rate": 0.0001898712057472008,
      "loss": 0.0001,
      "step": 5780
    },
    {
      "epoch": 0.3723233232589544,
      "grad_norm": 0.003161853877827525,
      "learning_rate": 0.00018967704355705132,
      "loss": 0.0001,
      "step": 5790
    },
    {
      "epoch": 0.3729663687222687,
      "grad_norm": 0.0020068343728780746,
      "learning_rate": 0.0001894828813669018,
      "loss": 0.0012,
      "step": 5800
    },
    {
      "epoch": 0.3736094141855829,
      "grad_norm": 0.0006436256808228791,
      "learning_rate": 0.0001892887191767523,
      "loss": 0.0001,
      "step": 5810
    },
    {
      "epoch": 0.3742524596488972,
      "grad_norm": 0.0017744266660884023,
      "learning_rate": 0.0001890945569866028,
      "loss": 0.0031,
      "step": 5820
    },
    {
      "epoch": 0.3748955051122114,
      "grad_norm": 0.010863104835152626,
      "learning_rate": 0.0001889003947964533,
      "loss": 0.0126,
      "step": 5830
    },
    {
      "epoch": 0.3755385505755257,
      "grad_norm": 0.0007266623433679342,
      "learning_rate": 0.00018870623260630378,
      "loss": 0.0001,
      "step": 5840
    },
    {
      "epoch": 0.37618159603883994,
      "grad_norm": 0.004319009371101856,
      "learning_rate": 0.0001885120704161543,
      "loss": 0.0014,
      "step": 5850
    },
    {
      "epoch": 0.3768246415021542,
      "grad_norm": 10.9022216796875,
      "learning_rate": 0.00018831790822600479,
      "loss": 0.0053,
      "step": 5860
    },
    {
      "epoch": 0.37746768696546845,
      "grad_norm": 0.004058252088725567,
      "learning_rate": 0.00018812374603585527,
      "loss": 0.0002,
      "step": 5870
    },
    {
      "epoch": 0.37811073242878274,
      "grad_norm": 0.005966344848275185,
      "learning_rate": 0.00018792958384570579,
      "loss": 0.0008,
      "step": 5880
    },
    {
      "epoch": 0.37875377789209697,
      "grad_norm": 0.0018945446936413646,
      "learning_rate": 0.00018773542165555627,
      "loss": 0.0022,
      "step": 5890
    },
    {
      "epoch": 0.37939682335541125,
      "grad_norm": 0.005766944028437138,
      "learning_rate": 0.00018754125946540673,
      "loss": 0.0002,
      "step": 5900
    },
    {
      "epoch": 0.3800398688187255,
      "grad_norm": 0.059940315783023834,
      "learning_rate": 0.00018734709727525727,
      "loss": 0.0003,
      "step": 5910
    },
    {
      "epoch": 0.38068291428203976,
      "grad_norm": 0.0026617480907589197,
      "learning_rate": 0.00018715293508510773,
      "loss": 0.0001,
      "step": 5920
    },
    {
      "epoch": 0.381325959745354,
      "grad_norm": 0.004262041766196489,
      "learning_rate": 0.00018695877289495822,
      "loss": 0.0191,
      "step": 5930
    },
    {
      "epoch": 0.3819690052086683,
      "grad_norm": 0.002744097961112857,
      "learning_rate": 0.00018676461070480876,
      "loss": 0.0001,
      "step": 5940
    },
    {
      "epoch": 0.3826120506719825,
      "grad_norm": 0.0009723000694066286,
      "learning_rate": 0.00018657044851465922,
      "loss": 0.0002,
      "step": 5950
    },
    {
      "epoch": 0.3832550961352968,
      "grad_norm": 0.0008960469858720899,
      "learning_rate": 0.0001863762863245097,
      "loss": 0.0001,
      "step": 5960
    },
    {
      "epoch": 0.383898141598611,
      "grad_norm": 0.0015052600065246224,
      "learning_rate": 0.00018618212413436022,
      "loss": 0.0008,
      "step": 5970
    },
    {
      "epoch": 0.3845411870619253,
      "grad_norm": 0.03120906464755535,
      "learning_rate": 0.0001859879619442107,
      "loss": 0.0001,
      "step": 5980
    },
    {
      "epoch": 0.38518423252523953,
      "grad_norm": 0.0024509415961802006,
      "learning_rate": 0.0001857937997540612,
      "loss": 0.0001,
      "step": 5990
    },
    {
      "epoch": 0.3858272779885538,
      "grad_norm": 0.0018607486272230744,
      "learning_rate": 0.0001855996375639117,
      "loss": 0.0001,
      "step": 6000
    },
    {
      "epoch": 0.38647032345186805,
      "grad_norm": 0.006398042198270559,
      "learning_rate": 0.0001854054753737622,
      "loss": 0.0003,
      "step": 6010
    },
    {
      "epoch": 0.3871133689151823,
      "grad_norm": 0.0036305750254541636,
      "learning_rate": 0.00018521131318361268,
      "loss": 0.0001,
      "step": 6020
    },
    {
      "epoch": 0.38775641437849656,
      "grad_norm": 0.0030811415053904057,
      "learning_rate": 0.0001850171509934632,
      "loss": 0.0004,
      "step": 6030
    },
    {
      "epoch": 0.3883994598418108,
      "grad_norm": 0.9973082542419434,
      "learning_rate": 0.00018482298880331368,
      "loss": 0.0002,
      "step": 6040
    },
    {
      "epoch": 0.3890425053051251,
      "grad_norm": 0.0007711373618803918,
      "learning_rate": 0.00018462882661316417,
      "loss": 0.0001,
      "step": 6050
    },
    {
      "epoch": 0.3896855507684393,
      "grad_norm": 0.0036724647507071495,
      "learning_rate": 0.00018443466442301468,
      "loss": 0.0098,
      "step": 6060
    },
    {
      "epoch": 0.3903285962317536,
      "grad_norm": 0.01768331229686737,
      "learning_rate": 0.00018424050223286517,
      "loss": 0.0001,
      "step": 6070
    },
    {
      "epoch": 0.3909716416950678,
      "grad_norm": 0.38353675603866577,
      "learning_rate": 0.00018404634004271566,
      "loss": 0.0002,
      "step": 6080
    },
    {
      "epoch": 0.3916146871583821,
      "grad_norm": 0.003956899978220463,
      "learning_rate": 0.00018385217785256617,
      "loss": 0.0001,
      "step": 6090
    },
    {
      "epoch": 0.39225773262169633,
      "grad_norm": 0.0021957119461148977,
      "learning_rate": 0.00018365801566241666,
      "loss": 0.0001,
      "step": 6100
    },
    {
      "epoch": 0.3929007780850106,
      "grad_norm": 0.008093828335404396,
      "learning_rate": 0.00018346385347226714,
      "loss": 0.0001,
      "step": 6110
    },
    {
      "epoch": 0.39354382354832484,
      "grad_norm": 0.0014821822987869382,
      "learning_rate": 0.00018326969128211766,
      "loss": 0.0002,
      "step": 6120
    },
    {
      "epoch": 0.39418686901163913,
      "grad_norm": 0.0027642531786113977,
      "learning_rate": 0.00018307552909196815,
      "loss": 0.0002,
      "step": 6130
    },
    {
      "epoch": 0.39482991447495336,
      "grad_norm": 0.0016164857661351562,
      "learning_rate": 0.00018288136690181863,
      "loss": 0.0001,
      "step": 6140
    },
    {
      "epoch": 0.39547295993826764,
      "grad_norm": 0.0017537773819640279,
      "learning_rate": 0.00018268720471166915,
      "loss": 0.0001,
      "step": 6150
    },
    {
      "epoch": 0.39611600540158187,
      "grad_norm": 0.0015637710457667708,
      "learning_rate": 0.00018249304252151963,
      "loss": 0.0,
      "step": 6160
    },
    {
      "epoch": 0.39675905086489616,
      "grad_norm": 0.002209337195381522,
      "learning_rate": 0.00018229888033137012,
      "loss": 0.0,
      "step": 6170
    },
    {
      "epoch": 0.3974020963282104,
      "grad_norm": 0.07985249906778336,
      "learning_rate": 0.00018210471814122063,
      "loss": 0.0059,
      "step": 6180
    },
    {
      "epoch": 0.39804514179152467,
      "grad_norm": 0.004893534816801548,
      "learning_rate": 0.00018191055595107112,
      "loss": 0.0001,
      "step": 6190
    },
    {
      "epoch": 0.3986881872548389,
      "grad_norm": 0.000839659187477082,
      "learning_rate": 0.0001817163937609216,
      "loss": 0.0002,
      "step": 6200
    },
    {
      "epoch": 0.3993312327181532,
      "grad_norm": 0.0009245625697076321,
      "learning_rate": 0.00018152223157077212,
      "loss": 0.0001,
      "step": 6210
    },
    {
      "epoch": 0.3999742781814674,
      "grad_norm": 0.012782717123627663,
      "learning_rate": 0.0001813280693806226,
      "loss": 0.0001,
      "step": 6220
    },
    {
      "epoch": 0.4006173236447817,
      "grad_norm": 0.0021831472404301167,
      "learning_rate": 0.0001811339071904731,
      "loss": 0.0158,
      "step": 6230
    },
    {
      "epoch": 0.4012603691080959,
      "grad_norm": 0.0031300680711865425,
      "learning_rate": 0.0001809397450003236,
      "loss": 0.0001,
      "step": 6240
    },
    {
      "epoch": 0.4019034145714102,
      "grad_norm": 0.0008810057770460844,
      "learning_rate": 0.0001807455828101741,
      "loss": 0.0001,
      "step": 6250
    },
    {
      "epoch": 0.40254646003472444,
      "grad_norm": 0.000664212042465806,
      "learning_rate": 0.00018055142062002456,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 0.4031895054980387,
      "grad_norm": 0.002166730584576726,
      "learning_rate": 0.0001803572584298751,
      "loss": 0.0001,
      "step": 6270
    },
    {
      "epoch": 0.40383255096135295,
      "grad_norm": 0.0013330851215869188,
      "learning_rate": 0.00018016309623972556,
      "loss": 0.0001,
      "step": 6280
    },
    {
      "epoch": 0.40447559642466724,
      "grad_norm": 1.343780755996704,
      "learning_rate": 0.00017996893404957604,
      "loss": 0.0004,
      "step": 6290
    },
    {
      "epoch": 0.40511864188798147,
      "grad_norm": 0.0015163940843194723,
      "learning_rate": 0.00017977477185942656,
      "loss": 0.0001,
      "step": 6300
    },
    {
      "epoch": 0.40576168735129575,
      "grad_norm": 0.0005552680231630802,
      "learning_rate": 0.00017958060966927704,
      "loss": 0.0001,
      "step": 6310
    },
    {
      "epoch": 0.40640473281461,
      "grad_norm": 0.0032523018307983875,
      "learning_rate": 0.00017938644747912753,
      "loss": 0.0001,
      "step": 6320
    },
    {
      "epoch": 0.40704777827792427,
      "grad_norm": 0.002560871187597513,
      "learning_rate": 0.00017919228528897804,
      "loss": 0.0001,
      "step": 6330
    },
    {
      "epoch": 0.4076908237412385,
      "grad_norm": 0.0009106422076001763,
      "learning_rate": 0.00017899812309882853,
      "loss": 0.0001,
      "step": 6340
    },
    {
      "epoch": 0.4083338692045528,
      "grad_norm": 0.0006887060008011758,
      "learning_rate": 0.00017880396090867902,
      "loss": 0.0001,
      "step": 6350
    },
    {
      "epoch": 0.408976914667867,
      "grad_norm": 0.001412733574397862,
      "learning_rate": 0.00017860979871852953,
      "loss": 0.0001,
      "step": 6360
    },
    {
      "epoch": 0.4096199601311813,
      "grad_norm": 0.0006630591815337539,
      "learning_rate": 0.00017841563652838002,
      "loss": 0.0002,
      "step": 6370
    },
    {
      "epoch": 0.4102630055944955,
      "grad_norm": 0.0019110775319859385,
      "learning_rate": 0.0001782214743382305,
      "loss": 0.0001,
      "step": 6380
    },
    {
      "epoch": 0.4109060510578098,
      "grad_norm": 0.0011413488537073135,
      "learning_rate": 0.00017802731214808102,
      "loss": 0.0001,
      "step": 6390
    },
    {
      "epoch": 0.41154909652112404,
      "grad_norm": 0.000954415590967983,
      "learning_rate": 0.0001778331499579315,
      "loss": 0.0001,
      "step": 6400
    },
    {
      "epoch": 0.4121921419844383,
      "grad_norm": 0.001453698379918933,
      "learning_rate": 0.000177638987767782,
      "loss": 0.0,
      "step": 6410
    },
    {
      "epoch": 0.41283518744775255,
      "grad_norm": 0.0017491269391030073,
      "learning_rate": 0.0001774448255776325,
      "loss": 0.0,
      "step": 6420
    },
    {
      "epoch": 0.41347823291106683,
      "grad_norm": 0.0003322840202599764,
      "learning_rate": 0.000177250663387483,
      "loss": 0.0,
      "step": 6430
    },
    {
      "epoch": 0.41412127837438106,
      "grad_norm": 0.0023742502089589834,
      "learning_rate": 0.00017705650119733348,
      "loss": 0.0,
      "step": 6440
    },
    {
      "epoch": 0.41476432383769535,
      "grad_norm": 0.0007907673134468496,
      "learning_rate": 0.000176862339007184,
      "loss": 0.0,
      "step": 6450
    },
    {
      "epoch": 0.4154073693010096,
      "grad_norm": 0.002900579944252968,
      "learning_rate": 0.00017666817681703448,
      "loss": 0.0001,
      "step": 6460
    },
    {
      "epoch": 0.41605041476432386,
      "grad_norm": 0.0008288777898997068,
      "learning_rate": 0.00017647401462688497,
      "loss": 0.0,
      "step": 6470
    },
    {
      "epoch": 0.4166934602276381,
      "grad_norm": 6.017904281616211,
      "learning_rate": 0.00017627985243673548,
      "loss": 0.0003,
      "step": 6480
    },
    {
      "epoch": 0.4173365056909524,
      "grad_norm": 0.0023220148868858814,
      "learning_rate": 0.00017608569024658597,
      "loss": 0.0004,
      "step": 6490
    },
    {
      "epoch": 0.4179795511542666,
      "grad_norm": 0.00031587487319484353,
      "learning_rate": 0.00017589152805643645,
      "loss": 0.0001,
      "step": 6500
    },
    {
      "epoch": 0.4186225966175809,
      "grad_norm": 0.002460579853504896,
      "learning_rate": 0.00017569736586628697,
      "loss": 0.0,
      "step": 6510
    },
    {
      "epoch": 0.4192656420808951,
      "grad_norm": 25.14678382873535,
      "learning_rate": 0.00017550320367613746,
      "loss": 0.0108,
      "step": 6520
    },
    {
      "epoch": 0.4199086875442094,
      "grad_norm": 0.002687507076188922,
      "learning_rate": 0.00017530904148598794,
      "loss": 0.0001,
      "step": 6530
    },
    {
      "epoch": 0.42055173300752363,
      "grad_norm": 0.001213231822475791,
      "learning_rate": 0.00017511487929583846,
      "loss": 0.0001,
      "step": 6540
    },
    {
      "epoch": 0.42119477847083786,
      "grad_norm": 0.0008234105771407485,
      "learning_rate": 0.00017492071710568894,
      "loss": 0.0001,
      "step": 6550
    },
    {
      "epoch": 0.42183782393415215,
      "grad_norm": 0.004637063946574926,
      "learning_rate": 0.00017472655491553943,
      "loss": 0.0615,
      "step": 6560
    },
    {
      "epoch": 0.4224808693974664,
      "grad_norm": 0.0034881778992712498,
      "learning_rate": 0.00017453239272538994,
      "loss": 0.0001,
      "step": 6570
    },
    {
      "epoch": 0.42312391486078066,
      "grad_norm": 0.0017566982423886657,
      "learning_rate": 0.00017433823053524043,
      "loss": 0.0005,
      "step": 6580
    },
    {
      "epoch": 0.4237669603240949,
      "grad_norm": 0.002435181988403201,
      "learning_rate": 0.0001741440683450909,
      "loss": 0.0001,
      "step": 6590
    },
    {
      "epoch": 0.4244100057874092,
      "grad_norm": 0.0033938204869627953,
      "learning_rate": 0.00017394990615494143,
      "loss": 0.0001,
      "step": 6600
    },
    {
      "epoch": 0.4250530512507234,
      "grad_norm": 0.003412725869566202,
      "learning_rate": 0.00017375574396479192,
      "loss": 0.0001,
      "step": 6610
    },
    {
      "epoch": 0.4256960967140377,
      "grad_norm": 0.001752758864313364,
      "learning_rate": 0.00017356158177464238,
      "loss": 0.0002,
      "step": 6620
    },
    {
      "epoch": 0.4263391421773519,
      "grad_norm": 0.9876331686973572,
      "learning_rate": 0.00017336741958449292,
      "loss": 0.0002,
      "step": 6630
    },
    {
      "epoch": 0.4269821876406662,
      "grad_norm": 0.0013593171024695039,
      "learning_rate": 0.00017317325739434338,
      "loss": 0.0002,
      "step": 6640
    },
    {
      "epoch": 0.42762523310398043,
      "grad_norm": 0.010617539286613464,
      "learning_rate": 0.00017297909520419386,
      "loss": 0.0001,
      "step": 6650
    },
    {
      "epoch": 0.4282682785672947,
      "grad_norm": 0.001124780043028295,
      "learning_rate": 0.00017278493301404438,
      "loss": 0.0001,
      "step": 6660
    },
    {
      "epoch": 0.42891132403060894,
      "grad_norm": 0.0012974448036402464,
      "learning_rate": 0.00017259077082389487,
      "loss": 0.0001,
      "step": 6670
    },
    {
      "epoch": 0.4295543694939232,
      "grad_norm": 0.0035821362398564816,
      "learning_rate": 0.00017239660863374535,
      "loss": 0.0001,
      "step": 6680
    },
    {
      "epoch": 0.43019741495723746,
      "grad_norm": 0.0016575841000303626,
      "learning_rate": 0.00017220244644359587,
      "loss": 0.0001,
      "step": 6690
    },
    {
      "epoch": 0.43084046042055174,
      "grad_norm": 0.0019523894879966974,
      "learning_rate": 0.00017200828425344635,
      "loss": 0.0001,
      "step": 6700
    },
    {
      "epoch": 0.43148350588386597,
      "grad_norm": 0.0021806287113577127,
      "learning_rate": 0.00017181412206329684,
      "loss": 0.0001,
      "step": 6710
    },
    {
      "epoch": 0.43212655134718025,
      "grad_norm": 0.0007193238707259297,
      "learning_rate": 0.00017161995987314735,
      "loss": 0.0001,
      "step": 6720
    },
    {
      "epoch": 0.4327695968104945,
      "grad_norm": 0.0014341319911181927,
      "learning_rate": 0.00017142579768299784,
      "loss": 0.0001,
      "step": 6730
    },
    {
      "epoch": 0.43341264227380877,
      "grad_norm": 0.00511549599468708,
      "learning_rate": 0.00017123163549284833,
      "loss": 0.0006,
      "step": 6740
    },
    {
      "epoch": 0.434055687737123,
      "grad_norm": 0.0027198162861168385,
      "learning_rate": 0.00017103747330269884,
      "loss": 0.0001,
      "step": 6750
    },
    {
      "epoch": 0.4346987332004373,
      "grad_norm": 0.00048182980390265584,
      "learning_rate": 0.00017084331111254933,
      "loss": 0.0001,
      "step": 6760
    },
    {
      "epoch": 0.4353417786637515,
      "grad_norm": 0.001114484155550599,
      "learning_rate": 0.00017064914892239981,
      "loss": 0.0053,
      "step": 6770
    },
    {
      "epoch": 0.4359848241270658,
      "grad_norm": 0.0058263265527784824,
      "learning_rate": 0.00017045498673225033,
      "loss": 0.0001,
      "step": 6780
    },
    {
      "epoch": 0.43662786959038,
      "grad_norm": 0.009553500451147556,
      "learning_rate": 0.00017026082454210082,
      "loss": 0.0001,
      "step": 6790
    },
    {
      "epoch": 0.4372709150536943,
      "grad_norm": 0.006398820783942938,
      "learning_rate": 0.0001700666623519513,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 0.43791396051700854,
      "grad_norm": 0.013022063300013542,
      "learning_rate": 0.00016987250016180182,
      "loss": 0.0001,
      "step": 6810
    },
    {
      "epoch": 0.4385570059803228,
      "grad_norm": 0.007332178298383951,
      "learning_rate": 0.0001696783379716523,
      "loss": 0.0001,
      "step": 6820
    },
    {
      "epoch": 0.43920005144363705,
      "grad_norm": 14.72004222869873,
      "learning_rate": 0.0001694841757815028,
      "loss": 0.0022,
      "step": 6830
    },
    {
      "epoch": 0.43984309690695134,
      "grad_norm": 0.0023224670439958572,
      "learning_rate": 0.0001692900135913533,
      "loss": 0.0001,
      "step": 6840
    },
    {
      "epoch": 0.44048614237026557,
      "grad_norm": 0.002749997191131115,
      "learning_rate": 0.0001690958514012038,
      "loss": 0.0003,
      "step": 6850
    },
    {
      "epoch": 0.44112918783357985,
      "grad_norm": 17.735820770263672,
      "learning_rate": 0.00016890168921105428,
      "loss": 0.0271,
      "step": 6860
    },
    {
      "epoch": 0.4417722332968941,
      "grad_norm": 0.0061786966398358345,
      "learning_rate": 0.0001687075270209048,
      "loss": 0.0001,
      "step": 6870
    },
    {
      "epoch": 0.44241527876020836,
      "grad_norm": 0.0010438539320603013,
      "learning_rate": 0.00016851336483075528,
      "loss": 0.0002,
      "step": 6880
    },
    {
      "epoch": 0.4430583242235226,
      "grad_norm": 0.0014964609872549772,
      "learning_rate": 0.00016831920264060576,
      "loss": 0.0002,
      "step": 6890
    },
    {
      "epoch": 0.4437013696868369,
      "grad_norm": 0.003527084831148386,
      "learning_rate": 0.00016812504045045628,
      "loss": 0.0001,
      "step": 6900
    },
    {
      "epoch": 0.4443444151501511,
      "grad_norm": 0.0028639815282076597,
      "learning_rate": 0.00016793087826030677,
      "loss": 0.0001,
      "step": 6910
    },
    {
      "epoch": 0.4449874606134654,
      "grad_norm": 0.009717519395053387,
      "learning_rate": 0.00016773671607015728,
      "loss": 0.0001,
      "step": 6920
    },
    {
      "epoch": 0.4456305060767796,
      "grad_norm": 0.0031342958100140095,
      "learning_rate": 0.00016754255388000777,
      "loss": 0.0001,
      "step": 6930
    },
    {
      "epoch": 0.4462735515400939,
      "grad_norm": 0.0021674667950719595,
      "learning_rate": 0.00016734839168985825,
      "loss": 0.0001,
      "step": 6940
    },
    {
      "epoch": 0.44691659700340813,
      "grad_norm": 14.037485122680664,
      "learning_rate": 0.00016715422949970877,
      "loss": 0.0046,
      "step": 6950
    },
    {
      "epoch": 0.4475596424667224,
      "grad_norm": 13.537151336669922,
      "learning_rate": 0.00016696006730955925,
      "loss": 0.0037,
      "step": 6960
    },
    {
      "epoch": 0.44820268793003665,
      "grad_norm": 0.0010533977765589952,
      "learning_rate": 0.0001667659051194097,
      "loss": 0.0001,
      "step": 6970
    },
    {
      "epoch": 0.44884573339335093,
      "grad_norm": 0.007663981057703495,
      "learning_rate": 0.00016657174292926025,
      "loss": 0.0001,
      "step": 6980
    },
    {
      "epoch": 0.44948877885666516,
      "grad_norm": 0.0013788992073386908,
      "learning_rate": 0.00016637758073911074,
      "loss": 0.0067,
      "step": 6990
    },
    {
      "epoch": 0.45013182431997945,
      "grad_norm": 0.002831491408869624,
      "learning_rate": 0.0001661834185489612,
      "loss": 0.0001,
      "step": 7000
    },
    {
      "epoch": 0.4507748697832937,
      "grad_norm": 0.0026435249019414186,
      "learning_rate": 0.00016598925635881174,
      "loss": 0.0001,
      "step": 7010
    },
    {
      "epoch": 0.45141791524660796,
      "grad_norm": 0.0026227415073662996,
      "learning_rate": 0.0001657950941686622,
      "loss": 0.0001,
      "step": 7020
    },
    {
      "epoch": 0.4520609607099222,
      "grad_norm": 0.001069183461368084,
      "learning_rate": 0.0001656009319785127,
      "loss": 0.0001,
      "step": 7030
    },
    {
      "epoch": 0.4527040061732365,
      "grad_norm": 0.0015214360319077969,
      "learning_rate": 0.0001654067697883632,
      "loss": 0.0001,
      "step": 7040
    },
    {
      "epoch": 0.4533470516365507,
      "grad_norm": 0.0012076791608706117,
      "learning_rate": 0.0001652126075982137,
      "loss": 0.0008,
      "step": 7050
    },
    {
      "epoch": 0.453990097099865,
      "grad_norm": 10.64516830444336,
      "learning_rate": 0.00016501844540806418,
      "loss": 0.0038,
      "step": 7060
    },
    {
      "epoch": 0.4546331425631792,
      "grad_norm": 0.01098586991429329,
      "learning_rate": 0.0001648242832179147,
      "loss": 0.0001,
      "step": 7070
    },
    {
      "epoch": 0.4552761880264935,
      "grad_norm": 0.0024596836883574724,
      "learning_rate": 0.00016463012102776518,
      "loss": 0.0001,
      "step": 7080
    },
    {
      "epoch": 0.45591923348980773,
      "grad_norm": 0.0059900847263634205,
      "learning_rate": 0.00016443595883761566,
      "loss": 0.0001,
      "step": 7090
    },
    {
      "epoch": 0.45656227895312196,
      "grad_norm": 0.04245994985103607,
      "learning_rate": 0.00016424179664746618,
      "loss": 0.0034,
      "step": 7100
    },
    {
      "epoch": 0.45720532441643624,
      "grad_norm": 0.003494906472042203,
      "learning_rate": 0.00016404763445731666,
      "loss": 0.0001,
      "step": 7110
    },
    {
      "epoch": 0.45784836987975047,
      "grad_norm": 0.001827145111747086,
      "learning_rate": 0.00016385347226716715,
      "loss": 0.0001,
      "step": 7120
    },
    {
      "epoch": 0.45849141534306476,
      "grad_norm": 0.0021306390408426523,
      "learning_rate": 0.00016365931007701766,
      "loss": 0.0004,
      "step": 7130
    },
    {
      "epoch": 0.459134460806379,
      "grad_norm": 0.10929706692695618,
      "learning_rate": 0.00016346514788686815,
      "loss": 0.0002,
      "step": 7140
    },
    {
      "epoch": 0.45977750626969327,
      "grad_norm": 0.0032926169224083424,
      "learning_rate": 0.00016327098569671864,
      "loss": 0.0021,
      "step": 7150
    },
    {
      "epoch": 0.4604205517330075,
      "grad_norm": 0.003031263593584299,
      "learning_rate": 0.00016307682350656915,
      "loss": 0.0001,
      "step": 7160
    },
    {
      "epoch": 0.4610635971963218,
      "grad_norm": 0.0009727829019539058,
      "learning_rate": 0.00016288266131641964,
      "loss": 0.0001,
      "step": 7170
    },
    {
      "epoch": 0.461706642659636,
      "grad_norm": 0.0018023391021415591,
      "learning_rate": 0.00016268849912627013,
      "loss": 0.0013,
      "step": 7180
    },
    {
      "epoch": 0.4623496881229503,
      "grad_norm": 0.004838672000914812,
      "learning_rate": 0.00016249433693612064,
      "loss": 0.0,
      "step": 7190
    },
    {
      "epoch": 0.4629927335862645,
      "grad_norm": 0.0029458184726536274,
      "learning_rate": 0.00016230017474597113,
      "loss": 0.0001,
      "step": 7200
    },
    {
      "epoch": 0.4636357790495788,
      "grad_norm": 0.0007900817436166108,
      "learning_rate": 0.0001621060125558216,
      "loss": 0.0001,
      "step": 7210
    },
    {
      "epoch": 0.46427882451289304,
      "grad_norm": 0.000927704619243741,
      "learning_rate": 0.00016191185036567213,
      "loss": 0.0,
      "step": 7220
    },
    {
      "epoch": 0.4649218699762073,
      "grad_norm": 0.002061528619378805,
      "learning_rate": 0.0001617176881755226,
      "loss": 0.0001,
      "step": 7230
    },
    {
      "epoch": 0.46556491543952155,
      "grad_norm": 0.024472132325172424,
      "learning_rate": 0.0001615235259853731,
      "loss": 0.0001,
      "step": 7240
    },
    {
      "epoch": 0.46620796090283584,
      "grad_norm": 0.0015925114275887609,
      "learning_rate": 0.00016132936379522361,
      "loss": 0.0001,
      "step": 7250
    },
    {
      "epoch": 0.46685100636615007,
      "grad_norm": 0.0006572240381501615,
      "learning_rate": 0.0001611352016050741,
      "loss": 0.0,
      "step": 7260
    },
    {
      "epoch": 0.46749405182946435,
      "grad_norm": 0.0025667883455753326,
      "learning_rate": 0.0001609410394149246,
      "loss": 0.0001,
      "step": 7270
    },
    {
      "epoch": 0.4681370972927786,
      "grad_norm": 0.0006540875765495002,
      "learning_rate": 0.0001607468772247751,
      "loss": 0.0001,
      "step": 7280
    },
    {
      "epoch": 0.46878014275609287,
      "grad_norm": 0.00060619245050475,
      "learning_rate": 0.0001605527150346256,
      "loss": 0.0001,
      "step": 7290
    },
    {
      "epoch": 0.4694231882194071,
      "grad_norm": 0.002661053091287613,
      "learning_rate": 0.00016035855284447608,
      "loss": 0.0008,
      "step": 7300
    },
    {
      "epoch": 0.4700662336827214,
      "grad_norm": 0.0018958167638629675,
      "learning_rate": 0.0001601643906543266,
      "loss": 0.0049,
      "step": 7310
    },
    {
      "epoch": 0.4707092791460356,
      "grad_norm": 0.001236300216987729,
      "learning_rate": 0.00015997022846417708,
      "loss": 0.0001,
      "step": 7320
    },
    {
      "epoch": 0.4713523246093499,
      "grad_norm": 0.011358371004462242,
      "learning_rate": 0.00015977606627402754,
      "loss": 0.0128,
      "step": 7330
    },
    {
      "epoch": 0.4719953700726641,
      "grad_norm": 0.001333800028078258,
      "learning_rate": 0.00015958190408387808,
      "loss": 0.0001,
      "step": 7340
    },
    {
      "epoch": 0.4726384155359784,
      "grad_norm": 0.02096083201467991,
      "learning_rate": 0.00015938774189372854,
      "loss": 0.0001,
      "step": 7350
    },
    {
      "epoch": 0.47328146099929264,
      "grad_norm": 0.03209133446216583,
      "learning_rate": 0.00015919357970357902,
      "loss": 0.0001,
      "step": 7360
    },
    {
      "epoch": 0.4739245064626069,
      "grad_norm": 0.011340572498738766,
      "learning_rate": 0.00015899941751342954,
      "loss": 0.0,
      "step": 7370
    },
    {
      "epoch": 0.47456755192592115,
      "grad_norm": 0.0021438756957650185,
      "learning_rate": 0.00015880525532328002,
      "loss": 0.0001,
      "step": 7380
    },
    {
      "epoch": 0.47521059738923543,
      "grad_norm": 0.0007421792251989245,
      "learning_rate": 0.0001586110931331305,
      "loss": 0.0001,
      "step": 7390
    },
    {
      "epoch": 0.47585364285254966,
      "grad_norm": 0.0013801276218146086,
      "learning_rate": 0.00015841693094298102,
      "loss": 0.002,
      "step": 7400
    },
    {
      "epoch": 0.47649668831586395,
      "grad_norm": 0.0019370467634871602,
      "learning_rate": 0.0001582227687528315,
      "loss": 0.0001,
      "step": 7410
    },
    {
      "epoch": 0.4771397337791782,
      "grad_norm": 0.002932261675596237,
      "learning_rate": 0.000158028606562682,
      "loss": 0.0001,
      "step": 7420
    },
    {
      "epoch": 0.47778277924249246,
      "grad_norm": 0.0017049020389094949,
      "learning_rate": 0.0001578344443725325,
      "loss": 0.0001,
      "step": 7430
    },
    {
      "epoch": 0.4784258247058067,
      "grad_norm": 0.0016853063134476542,
      "learning_rate": 0.000157640282182383,
      "loss": 0.0001,
      "step": 7440
    },
    {
      "epoch": 0.479068870169121,
      "grad_norm": 0.0009586101514287293,
      "learning_rate": 0.00015744611999223349,
      "loss": 0.0001,
      "step": 7450
    },
    {
      "epoch": 0.4797119156324352,
      "grad_norm": 0.0012174053117632866,
      "learning_rate": 0.000157251957802084,
      "loss": 0.0001,
      "step": 7460
    },
    {
      "epoch": 0.4803549610957495,
      "grad_norm": 0.001640572678297758,
      "learning_rate": 0.00015705779561193449,
      "loss": 0.0012,
      "step": 7470
    },
    {
      "epoch": 0.4809980065590637,
      "grad_norm": 0.0026300200261175632,
      "learning_rate": 0.00015686363342178497,
      "loss": 0.0001,
      "step": 7480
    },
    {
      "epoch": 0.481641052022378,
      "grad_norm": 0.0011454890482127666,
      "learning_rate": 0.0001566694712316355,
      "loss": 0.0001,
      "step": 7490
    },
    {
      "epoch": 0.48228409748569223,
      "grad_norm": 0.0026890854351222515,
      "learning_rate": 0.00015647530904148597,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 0.4829271429490065,
      "grad_norm": 0.0006284303381107748,
      "learning_rate": 0.00015628114685133646,
      "loss": 0.0001,
      "step": 7510
    },
    {
      "epoch": 0.48357018841232075,
      "grad_norm": 0.002675613621249795,
      "learning_rate": 0.00015608698466118697,
      "loss": 0.0,
      "step": 7520
    },
    {
      "epoch": 0.48421323387563503,
      "grad_norm": 0.001202043262310326,
      "learning_rate": 0.00015589282247103746,
      "loss": 0.0001,
      "step": 7530
    },
    {
      "epoch": 0.48485627933894926,
      "grad_norm": 0.0013111756416037679,
      "learning_rate": 0.00015569866028088795,
      "loss": 0.0001,
      "step": 7540
    },
    {
      "epoch": 0.48549932480226354,
      "grad_norm": 0.0019598931539803743,
      "learning_rate": 0.00015550449809073846,
      "loss": 0.0001,
      "step": 7550
    },
    {
      "epoch": 0.4861423702655778,
      "grad_norm": 0.0009506024653092027,
      "learning_rate": 0.00015531033590058895,
      "loss": 0.0,
      "step": 7560
    },
    {
      "epoch": 0.48678541572889206,
      "grad_norm": 0.002438274445012212,
      "learning_rate": 0.00015511617371043944,
      "loss": 0.0,
      "step": 7570
    },
    {
      "epoch": 0.4874284611922063,
      "grad_norm": 0.000851599033921957,
      "learning_rate": 0.00015492201152028995,
      "loss": 0.0,
      "step": 7580
    },
    {
      "epoch": 0.48807150665552057,
      "grad_norm": 0.0073771108873188496,
      "learning_rate": 0.00015472784933014044,
      "loss": 0.0,
      "step": 7590
    },
    {
      "epoch": 0.4887145521188348,
      "grad_norm": 0.003014577319845557,
      "learning_rate": 0.00015453368713999092,
      "loss": 0.0032,
      "step": 7600
    },
    {
      "epoch": 0.4893575975821491,
      "grad_norm": 0.003268080297857523,
      "learning_rate": 0.00015433952494984144,
      "loss": 0.0001,
      "step": 7610
    },
    {
      "epoch": 0.4900006430454633,
      "grad_norm": 0.02111576683819294,
      "learning_rate": 0.00015414536275969192,
      "loss": 0.0152,
      "step": 7620
    },
    {
      "epoch": 0.4906436885087776,
      "grad_norm": 0.05120973289012909,
      "learning_rate": 0.0001539512005695424,
      "loss": 0.0002,
      "step": 7630
    },
    {
      "epoch": 0.4912867339720918,
      "grad_norm": 0.21512699127197266,
      "learning_rate": 0.00015375703837939292,
      "loss": 0.0002,
      "step": 7640
    },
    {
      "epoch": 0.49192977943540606,
      "grad_norm": 0.0027215287555009127,
      "learning_rate": 0.0001535628761892434,
      "loss": 0.0001,
      "step": 7650
    },
    {
      "epoch": 0.49257282489872034,
      "grad_norm": 0.001622989191673696,
      "learning_rate": 0.0001533687139990939,
      "loss": 0.0003,
      "step": 7660
    },
    {
      "epoch": 0.49321587036203457,
      "grad_norm": 0.004593309946358204,
      "learning_rate": 0.0001531745518089444,
      "loss": 0.0001,
      "step": 7670
    },
    {
      "epoch": 0.49385891582534885,
      "grad_norm": 0.0009801180567592382,
      "learning_rate": 0.0001529803896187949,
      "loss": 0.0001,
      "step": 7680
    },
    {
      "epoch": 0.4945019612886631,
      "grad_norm": 0.0010925460373982787,
      "learning_rate": 0.00015278622742864536,
      "loss": 0.0001,
      "step": 7690
    },
    {
      "epoch": 0.49514500675197737,
      "grad_norm": 0.006907562725245953,
      "learning_rate": 0.0001525920652384959,
      "loss": 0.0001,
      "step": 7700
    },
    {
      "epoch": 0.4957880522152916,
      "grad_norm": 0.001553559210151434,
      "learning_rate": 0.00015239790304834636,
      "loss": 0.0002,
      "step": 7710
    },
    {
      "epoch": 0.4964310976786059,
      "grad_norm": 0.007207275368273258,
      "learning_rate": 0.00015220374085819685,
      "loss": 0.0001,
      "step": 7720
    },
    {
      "epoch": 0.4970741431419201,
      "grad_norm": 0.00042846909491345286,
      "learning_rate": 0.00015200957866804736,
      "loss": 0.0001,
      "step": 7730
    },
    {
      "epoch": 0.4977171886052344,
      "grad_norm": 0.00561892194673419,
      "learning_rate": 0.00015181541647789785,
      "loss": 0.0001,
      "step": 7740
    },
    {
      "epoch": 0.4983602340685486,
      "grad_norm": 0.0008210688247345388,
      "learning_rate": 0.00015162125428774833,
      "loss": 0.0,
      "step": 7750
    },
    {
      "epoch": 0.4990032795318629,
      "grad_norm": 0.0007102887611836195,
      "learning_rate": 0.00015142709209759885,
      "loss": 0.0001,
      "step": 7760
    },
    {
      "epoch": 0.49964632499517714,
      "grad_norm": 0.004106907173991203,
      "learning_rate": 0.00015123292990744933,
      "loss": 0.0001,
      "step": 7770
    },
    {
      "epoch": 0.5002893704584914,
      "grad_norm": 0.0011712478008121252,
      "learning_rate": 0.00015103876771729982,
      "loss": 0.0001,
      "step": 7780
    },
    {
      "epoch": 0.5009324159218057,
      "grad_norm": 0.002968397457152605,
      "learning_rate": 0.00015084460552715033,
      "loss": 0.0001,
      "step": 7790
    },
    {
      "epoch": 0.5015754613851199,
      "grad_norm": 0.0029815956950187683,
      "learning_rate": 0.00015065044333700082,
      "loss": 0.0001,
      "step": 7800
    },
    {
      "epoch": 0.5022185068484342,
      "grad_norm": 0.03966926038265228,
      "learning_rate": 0.0001504562811468513,
      "loss": 0.0001,
      "step": 7810
    },
    {
      "epoch": 0.5028615523117484,
      "grad_norm": 0.0012807458406314254,
      "learning_rate": 0.00015026211895670182,
      "loss": 0.0,
      "step": 7820
    },
    {
      "epoch": 0.5035045977750627,
      "grad_norm": 0.0006830858765169978,
      "learning_rate": 0.0001500679567665523,
      "loss": 0.0001,
      "step": 7830
    },
    {
      "epoch": 0.5041476432383769,
      "grad_norm": 0.0005957081448286772,
      "learning_rate": 0.00014987379457640282,
      "loss": 0.0002,
      "step": 7840
    },
    {
      "epoch": 0.5047906887016912,
      "grad_norm": 0.0006010026554577053,
      "learning_rate": 0.0001496796323862533,
      "loss": 0.0001,
      "step": 7850
    },
    {
      "epoch": 0.5054337341650055,
      "grad_norm": 0.00044956657802686095,
      "learning_rate": 0.0001494854701961038,
      "loss": 0.0,
      "step": 7860
    },
    {
      "epoch": 0.5060767796283198,
      "grad_norm": 0.000878096732776612,
      "learning_rate": 0.0001492913080059543,
      "loss": 0.0,
      "step": 7870
    },
    {
      "epoch": 0.5067198250916339,
      "grad_norm": 0.0009557919693179429,
      "learning_rate": 0.0001490971458158048,
      "loss": 0.0001,
      "step": 7880
    },
    {
      "epoch": 0.5073628705549482,
      "grad_norm": 0.00039099279092624784,
      "learning_rate": 0.00014890298362565528,
      "loss": 0.0,
      "step": 7890
    },
    {
      "epoch": 0.5080059160182625,
      "grad_norm": 0.00031431924435310066,
      "learning_rate": 0.00014870882143550577,
      "loss": 0.0001,
      "step": 7900
    },
    {
      "epoch": 0.5086489614815768,
      "grad_norm": 0.002112241694703698,
      "learning_rate": 0.00014851465924535628,
      "loss": 0.0001,
      "step": 7910
    },
    {
      "epoch": 0.509292006944891,
      "grad_norm": 0.001592376152984798,
      "learning_rate": 0.00014832049705520677,
      "loss": 0.0001,
      "step": 7920
    },
    {
      "epoch": 0.5099350524082052,
      "grad_norm": 0.0011675257701426744,
      "learning_rate": 0.00014812633486505726,
      "loss": 0.0,
      "step": 7930
    },
    {
      "epoch": 0.5105780978715195,
      "grad_norm": 0.000843422079924494,
      "learning_rate": 0.00014793217267490777,
      "loss": 0.0,
      "step": 7940
    },
    {
      "epoch": 0.5112211433348338,
      "grad_norm": 0.0005633013788610697,
      "learning_rate": 0.00014773801048475826,
      "loss": 0.0001,
      "step": 7950
    },
    {
      "epoch": 0.511864188798148,
      "grad_norm": 0.10203024744987488,
      "learning_rate": 0.00014754384829460874,
      "loss": 0.0001,
      "step": 7960
    },
    {
      "epoch": 0.5125072342614623,
      "grad_norm": 0.0025528136175125837,
      "learning_rate": 0.00014734968610445926,
      "loss": 0.0,
      "step": 7970
    },
    {
      "epoch": 0.5131502797247766,
      "grad_norm": 0.0032725678756833076,
      "learning_rate": 0.00014715552391430975,
      "loss": 0.0001,
      "step": 7980
    },
    {
      "epoch": 0.5137933251880908,
      "grad_norm": 0.0013287956826388836,
      "learning_rate": 0.00014696136172416023,
      "loss": 0.0,
      "step": 7990
    },
    {
      "epoch": 0.514436370651405,
      "grad_norm": 0.00034183284151367843,
      "learning_rate": 0.00014676719953401075,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 0.5150794161147193,
      "grad_norm": 0.0005062332493253052,
      "learning_rate": 0.00014657303734386123,
      "loss": 0.0001,
      "step": 8010
    },
    {
      "epoch": 0.5157224615780336,
      "grad_norm": 0.0012786512961611152,
      "learning_rate": 0.00014637887515371172,
      "loss": 0.0001,
      "step": 8020
    },
    {
      "epoch": 0.5163655070413479,
      "grad_norm": 0.0012981364270672202,
      "learning_rate": 0.00014618471296356223,
      "loss": 0.0001,
      "step": 8030
    },
    {
      "epoch": 0.517008552504662,
      "grad_norm": 0.0007844037027098238,
      "learning_rate": 0.0001459905507734127,
      "loss": 0.0001,
      "step": 8040
    },
    {
      "epoch": 0.5176515979679763,
      "grad_norm": 0.0025695026852190495,
      "learning_rate": 0.0001457963885832632,
      "loss": 0.0,
      "step": 8050
    },
    {
      "epoch": 0.5182946434312906,
      "grad_norm": 0.0009853511583060026,
      "learning_rate": 0.00014560222639311372,
      "loss": 0.0,
      "step": 8060
    },
    {
      "epoch": 0.5189376888946049,
      "grad_norm": 0.0030340056400746107,
      "learning_rate": 0.00014540806420296418,
      "loss": 0.0,
      "step": 8070
    },
    {
      "epoch": 0.5195807343579191,
      "grad_norm": 0.006613898556679487,
      "learning_rate": 0.0001452139020128147,
      "loss": 0.0001,
      "step": 8080
    },
    {
      "epoch": 0.5202237798212334,
      "grad_norm": 0.0014461377868428826,
      "learning_rate": 0.00014501973982266518,
      "loss": 0.0,
      "step": 8090
    },
    {
      "epoch": 0.5208668252845476,
      "grad_norm": 0.0009393503423780203,
      "learning_rate": 0.00014482557763251567,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 0.5215098707478619,
      "grad_norm": 0.00036534277023747563,
      "learning_rate": 0.00014463141544236618,
      "loss": 0.0,
      "step": 8110
    },
    {
      "epoch": 0.5221529162111761,
      "grad_norm": 0.0009663854725658894,
      "learning_rate": 0.00014443725325221667,
      "loss": 0.0,
      "step": 8120
    },
    {
      "epoch": 0.5227959616744904,
      "grad_norm": 0.0175444558262825,
      "learning_rate": 0.00014424309106206716,
      "loss": 0.0001,
      "step": 8130
    },
    {
      "epoch": 0.5234390071378047,
      "grad_norm": 0.0012476157862693071,
      "learning_rate": 0.00014404892887191767,
      "loss": 0.0001,
      "step": 8140
    },
    {
      "epoch": 0.524082052601119,
      "grad_norm": 0.028030522167682648,
      "learning_rate": 0.00014385476668176816,
      "loss": 0.0001,
      "step": 8150
    },
    {
      "epoch": 0.5247250980644331,
      "grad_norm": 0.005319231189787388,
      "learning_rate": 0.00014366060449161864,
      "loss": 0.0001,
      "step": 8160
    },
    {
      "epoch": 0.5253681435277474,
      "grad_norm": 0.0009682369418442249,
      "learning_rate": 0.00014346644230146916,
      "loss": 0.0001,
      "step": 8170
    },
    {
      "epoch": 0.5260111889910617,
      "grad_norm": 0.0006441896548494697,
      "learning_rate": 0.00014327228011131964,
      "loss": 0.0001,
      "step": 8180
    },
    {
      "epoch": 0.5266542344543759,
      "grad_norm": 0.0022986114490777254,
      "learning_rate": 0.00014307811792117013,
      "loss": 0.0,
      "step": 8190
    },
    {
      "epoch": 0.5272972799176902,
      "grad_norm": 0.0007275870884768665,
      "learning_rate": 0.00014288395573102064,
      "loss": 0.0,
      "step": 8200
    },
    {
      "epoch": 0.5279403253810044,
      "grad_norm": 0.001330581377260387,
      "learning_rate": 0.00014268979354087113,
      "loss": 0.0,
      "step": 8210
    },
    {
      "epoch": 0.5285833708443187,
      "grad_norm": 0.0003600346972234547,
      "learning_rate": 0.00014249563135072162,
      "loss": 0.0,
      "step": 8220
    },
    {
      "epoch": 0.5292264163076329,
      "grad_norm": 0.0007893973961472511,
      "learning_rate": 0.0001423014691605721,
      "loss": 0.0,
      "step": 8230
    },
    {
      "epoch": 0.5298694617709472,
      "grad_norm": 0.0015651185531169176,
      "learning_rate": 0.00014210730697042262,
      "loss": 0.0,
      "step": 8240
    },
    {
      "epoch": 0.5305125072342615,
      "grad_norm": 0.0005846665590070188,
      "learning_rate": 0.0001419131447802731,
      "loss": 0.0001,
      "step": 8250
    },
    {
      "epoch": 0.5311555526975758,
      "grad_norm": 0.001369394245557487,
      "learning_rate": 0.0001417189825901236,
      "loss": 0.0002,
      "step": 8260
    },
    {
      "epoch": 0.5317985981608899,
      "grad_norm": 0.021619629114866257,
      "learning_rate": 0.0001415248203999741,
      "loss": 0.0001,
      "step": 8270
    },
    {
      "epoch": 0.5324416436242042,
      "grad_norm": 0.00025066296802833676,
      "learning_rate": 0.0001413306582098246,
      "loss": 0.0,
      "step": 8280
    },
    {
      "epoch": 0.5330846890875185,
      "grad_norm": 0.011568732559680939,
      "learning_rate": 0.00014113649601967508,
      "loss": 0.0,
      "step": 8290
    },
    {
      "epoch": 0.5337277345508328,
      "grad_norm": 0.0003386793250683695,
      "learning_rate": 0.0001409423338295256,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 0.534370780014147,
      "grad_norm": 0.0015546281356364489,
      "learning_rate": 0.00014074817163937608,
      "loss": 0.0,
      "step": 8310
    },
    {
      "epoch": 0.5350138254774612,
      "grad_norm": 0.0009734351770021021,
      "learning_rate": 0.00014055400944922657,
      "loss": 0.0003,
      "step": 8320
    },
    {
      "epoch": 0.5356568709407755,
      "grad_norm": 0.011261092498898506,
      "learning_rate": 0.00014035984725907708,
      "loss": 0.0001,
      "step": 8330
    },
    {
      "epoch": 0.5362999164040898,
      "grad_norm": 0.0014333153376355767,
      "learning_rate": 0.00014016568506892757,
      "loss": 0.0001,
      "step": 8340
    },
    {
      "epoch": 0.536942961867404,
      "grad_norm": 0.0011510133044794202,
      "learning_rate": 0.00013997152287877805,
      "loss": 0.0001,
      "step": 8350
    },
    {
      "epoch": 0.5375860073307183,
      "grad_norm": 0.0009654673631303012,
      "learning_rate": 0.00013977736068862857,
      "loss": 0.0001,
      "step": 8360
    },
    {
      "epoch": 0.5382290527940325,
      "grad_norm": 0.0013159273657947779,
      "learning_rate": 0.00013958319849847906,
      "loss": 0.0001,
      "step": 8370
    },
    {
      "epoch": 0.5388720982573468,
      "grad_norm": 0.003499971702694893,
      "learning_rate": 0.00013938903630832954,
      "loss": 0.0001,
      "step": 8380
    },
    {
      "epoch": 0.539515143720661,
      "grad_norm": 0.002763750497251749,
      "learning_rate": 0.00013919487411818006,
      "loss": 0.0001,
      "step": 8390
    },
    {
      "epoch": 0.5401581891839753,
      "grad_norm": 0.0022850895766168833,
      "learning_rate": 0.00013900071192803052,
      "loss": 0.0001,
      "step": 8400
    },
    {
      "epoch": 0.5408012346472896,
      "grad_norm": 0.0035212752409279346,
      "learning_rate": 0.00013880654973788103,
      "loss": 0.0001,
      "step": 8410
    },
    {
      "epoch": 0.5414442801106039,
      "grad_norm": 0.0007115963380783796,
      "learning_rate": 0.00013861238754773152,
      "loss": 0.0001,
      "step": 8420
    },
    {
      "epoch": 0.542087325573918,
      "grad_norm": 0.0015581832267343998,
      "learning_rate": 0.000138418225357582,
      "loss": 0.0001,
      "step": 8430
    },
    {
      "epoch": 0.5427303710372323,
      "grad_norm": 0.003998820669949055,
      "learning_rate": 0.00013822406316743252,
      "loss": 0.0002,
      "step": 8440
    },
    {
      "epoch": 0.5433734165005466,
      "grad_norm": 0.0009967072401195765,
      "learning_rate": 0.000138029900977283,
      "loss": 0.0001,
      "step": 8450
    },
    {
      "epoch": 0.5440164619638609,
      "grad_norm": 0.0005379384965635836,
      "learning_rate": 0.00013783573878713352,
      "loss": 0.0001,
      "step": 8460
    },
    {
      "epoch": 0.5446595074271751,
      "grad_norm": 0.0014727734960615635,
      "learning_rate": 0.000137641576596984,
      "loss": 0.0001,
      "step": 8470
    },
    {
      "epoch": 0.5453025528904893,
      "grad_norm": 0.002852059667930007,
      "learning_rate": 0.0001374474144068345,
      "loss": 0.0001,
      "step": 8480
    },
    {
      "epoch": 0.5459455983538036,
      "grad_norm": 0.0041021984070539474,
      "learning_rate": 0.000137253252216685,
      "loss": 0.0,
      "step": 8490
    },
    {
      "epoch": 0.5465886438171179,
      "grad_norm": 0.00045873745693825185,
      "learning_rate": 0.0001370590900265355,
      "loss": 0.0001,
      "step": 8500
    },
    {
      "epoch": 0.5472316892804321,
      "grad_norm": 0.0056901718489825726,
      "learning_rate": 0.00013686492783638598,
      "loss": 0.0,
      "step": 8510
    },
    {
      "epoch": 0.5478747347437464,
      "grad_norm": 0.002368238056078553,
      "learning_rate": 0.0001366707656462365,
      "loss": 0.0,
      "step": 8520
    },
    {
      "epoch": 0.5485177802070607,
      "grad_norm": 0.0013411915861070156,
      "learning_rate": 0.00013647660345608698,
      "loss": 0.0,
      "step": 8530
    },
    {
      "epoch": 0.5491608256703749,
      "grad_norm": 0.000602277519647032,
      "learning_rate": 0.00013628244126593747,
      "loss": 0.0,
      "step": 8540
    },
    {
      "epoch": 0.5498038711336891,
      "grad_norm": 0.0004846336378250271,
      "learning_rate": 0.00013608827907578798,
      "loss": 0.0,
      "step": 8550
    },
    {
      "epoch": 0.5504469165970034,
      "grad_norm": 0.002503142226487398,
      "learning_rate": 0.00013589411688563847,
      "loss": 0.0,
      "step": 8560
    },
    {
      "epoch": 0.5510899620603177,
      "grad_norm": 0.0006016541155986488,
      "learning_rate": 0.00013569995469548895,
      "loss": 0.0,
      "step": 8570
    },
    {
      "epoch": 0.551733007523632,
      "grad_norm": 0.001561068231239915,
      "learning_rate": 0.00013550579250533947,
      "loss": 0.0,
      "step": 8580
    },
    {
      "epoch": 0.5523760529869461,
      "grad_norm": 0.0011247580405324697,
      "learning_rate": 0.00013531163031518993,
      "loss": 0.0,
      "step": 8590
    },
    {
      "epoch": 0.5530190984502604,
      "grad_norm": 0.0008518798276782036,
      "learning_rate": 0.00013511746812504044,
      "loss": 0.0,
      "step": 8600
    },
    {
      "epoch": 0.5536621439135747,
      "grad_norm": 0.0009580561309121549,
      "learning_rate": 0.00013492330593489093,
      "loss": 0.0,
      "step": 8610
    },
    {
      "epoch": 0.554305189376889,
      "grad_norm": 0.20250186324119568,
      "learning_rate": 0.00013472914374474141,
      "loss": 0.0002,
      "step": 8620
    },
    {
      "epoch": 0.5549482348402032,
      "grad_norm": 0.0011550479102879763,
      "learning_rate": 0.00013453498155459193,
      "loss": 0.0031,
      "step": 8630
    },
    {
      "epoch": 0.5555912803035175,
      "grad_norm": 0.0009827768662944436,
      "learning_rate": 0.00013434081936444242,
      "loss": 0.0035,
      "step": 8640
    },
    {
      "epoch": 0.5562343257668317,
      "grad_norm": 0.0019090728601440787,
      "learning_rate": 0.0001341466571742929,
      "loss": 0.0001,
      "step": 8650
    },
    {
      "epoch": 0.556877371230146,
      "grad_norm": 0.0027465990278869867,
      "learning_rate": 0.00013395249498414342,
      "loss": 0.0001,
      "step": 8660
    },
    {
      "epoch": 0.5575204166934602,
      "grad_norm": 0.006422881036996841,
      "learning_rate": 0.0001337583327939939,
      "loss": 0.0001,
      "step": 8670
    },
    {
      "epoch": 0.5581634621567745,
      "grad_norm": 0.01984882541000843,
      "learning_rate": 0.0001335641706038444,
      "loss": 0.0007,
      "step": 8680
    },
    {
      "epoch": 0.5588065076200888,
      "grad_norm": 0.004834554623812437,
      "learning_rate": 0.0001333700084136949,
      "loss": 0.0001,
      "step": 8690
    },
    {
      "epoch": 0.559449553083403,
      "grad_norm": 0.0007974468171596527,
      "learning_rate": 0.0001331758462235454,
      "loss": 0.0002,
      "step": 8700
    },
    {
      "epoch": 0.5600925985467172,
      "grad_norm": 0.0030424087308347225,
      "learning_rate": 0.00013298168403339588,
      "loss": 0.0001,
      "step": 8710
    },
    {
      "epoch": 0.5607356440100315,
      "grad_norm": 0.0011738440953195095,
      "learning_rate": 0.0001327875218432464,
      "loss": 0.0002,
      "step": 8720
    },
    {
      "epoch": 0.5613786894733458,
      "grad_norm": 0.0026466338895261288,
      "learning_rate": 0.00013259335965309688,
      "loss": 0.0001,
      "step": 8730
    },
    {
      "epoch": 0.56202173493666,
      "grad_norm": 0.0008066098089329898,
      "learning_rate": 0.00013239919746294736,
      "loss": 0.0001,
      "step": 8740
    },
    {
      "epoch": 0.5626647803999743,
      "grad_norm": 0.001314023626036942,
      "learning_rate": 0.00013220503527279788,
      "loss": 0.0,
      "step": 8750
    },
    {
      "epoch": 0.5633078258632885,
      "grad_norm": 0.016043370589613914,
      "learning_rate": 0.00013201087308264837,
      "loss": 0.0001,
      "step": 8760
    },
    {
      "epoch": 0.5639508713266028,
      "grad_norm": 0.0016176241915673018,
      "learning_rate": 0.00013181671089249885,
      "loss": 0.0001,
      "step": 8770
    },
    {
      "epoch": 0.564593916789917,
      "grad_norm": 0.0012959380401298404,
      "learning_rate": 0.00013162254870234934,
      "loss": 0.0,
      "step": 8780
    },
    {
      "epoch": 0.5652369622532313,
      "grad_norm": 0.001078000757843256,
      "learning_rate": 0.00013142838651219985,
      "loss": 0.0001,
      "step": 8790
    },
    {
      "epoch": 0.5658800077165456,
      "grad_norm": 0.0009227495174854994,
      "learning_rate": 0.00013123422432205034,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 0.5665230531798598,
      "grad_norm": 0.001139592146500945,
      "learning_rate": 0.00013104006213190083,
      "loss": 0.0,
      "step": 8810
    },
    {
      "epoch": 0.567166098643174,
      "grad_norm": 0.0004590022435877472,
      "learning_rate": 0.00013084589994175134,
      "loss": 0.0001,
      "step": 8820
    },
    {
      "epoch": 0.5678091441064883,
      "grad_norm": 0.0004295298713259399,
      "learning_rate": 0.00013065173775160183,
      "loss": 0.0001,
      "step": 8830
    },
    {
      "epoch": 0.5684521895698026,
      "grad_norm": 3.3034417629241943,
      "learning_rate": 0.00013045757556145231,
      "loss": 0.0002,
      "step": 8840
    },
    {
      "epoch": 0.5690952350331169,
      "grad_norm": 0.000912496994715184,
      "learning_rate": 0.00013026341337130283,
      "loss": 0.0,
      "step": 8850
    },
    {
      "epoch": 0.569738280496431,
      "grad_norm": 0.0010589096928015351,
      "learning_rate": 0.00013006925118115331,
      "loss": 0.0001,
      "step": 8860
    },
    {
      "epoch": 0.5703813259597453,
      "grad_norm": 0.0009460641886107624,
      "learning_rate": 0.0001298750889910038,
      "loss": 0.0,
      "step": 8870
    },
    {
      "epoch": 0.5710243714230596,
      "grad_norm": 0.0005036407383158803,
      "learning_rate": 0.00012968092680085432,
      "loss": 0.0,
      "step": 8880
    },
    {
      "epoch": 0.5716674168863739,
      "grad_norm": 0.0013242375571280718,
      "learning_rate": 0.0001294867646107048,
      "loss": 0.0001,
      "step": 8890
    },
    {
      "epoch": 0.5723104623496881,
      "grad_norm": 0.0024174214340746403,
      "learning_rate": 0.0001292926024205553,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 0.5729535078130024,
      "grad_norm": 0.03417178988456726,
      "learning_rate": 0.0001290984402304058,
      "loss": 0.0001,
      "step": 8910
    },
    {
      "epoch": 0.5735965532763166,
      "grad_norm": 0.003510728944092989,
      "learning_rate": 0.0001289042780402563,
      "loss": 0.0,
      "step": 8920
    },
    {
      "epoch": 0.5742395987396309,
      "grad_norm": 5.154608249664307,
      "learning_rate": 0.00012871011585010678,
      "loss": 0.0004,
      "step": 8930
    },
    {
      "epoch": 0.5748826442029451,
      "grad_norm": 0.008980832062661648,
      "learning_rate": 0.0001285159536599573,
      "loss": 0.0001,
      "step": 8940
    },
    {
      "epoch": 0.5755256896662594,
      "grad_norm": 0.0020786470267921686,
      "learning_rate": 0.00012832179146980775,
      "loss": 0.0001,
      "step": 8950
    },
    {
      "epoch": 0.5761687351295737,
      "grad_norm": 0.0008686000946909189,
      "learning_rate": 0.00012812762927965826,
      "loss": 0.0001,
      "step": 8960
    },
    {
      "epoch": 0.576811780592888,
      "grad_norm": 0.004736183676868677,
      "learning_rate": 0.00012793346708950875,
      "loss": 0.0002,
      "step": 8970
    },
    {
      "epoch": 0.5774548260562021,
      "grad_norm": 0.0004968122811987996,
      "learning_rate": 0.00012773930489935924,
      "loss": 0.0002,
      "step": 8980
    },
    {
      "epoch": 0.5780978715195164,
      "grad_norm": 0.0007352762622758746,
      "learning_rate": 0.00012754514270920975,
      "loss": 0.0007,
      "step": 8990
    },
    {
      "epoch": 0.5787409169828307,
      "grad_norm": 0.0009324248530901968,
      "learning_rate": 0.00012735098051906024,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 0.579383962446145,
      "grad_norm": 0.0041541424579918385,
      "learning_rate": 0.00012715681832891072,
      "loss": 0.0,
      "step": 9010
    },
    {
      "epoch": 0.5800270079094592,
      "grad_norm": 0.005107238423079252,
      "learning_rate": 0.00012696265613876124,
      "loss": 0.0,
      "step": 9020
    },
    {
      "epoch": 0.5806700533727734,
      "grad_norm": 0.025233078747987747,
      "learning_rate": 0.00012676849394861173,
      "loss": 0.0001,
      "step": 9030
    },
    {
      "epoch": 0.5813130988360877,
      "grad_norm": 0.0025473397690802813,
      "learning_rate": 0.0001265743317584622,
      "loss": 0.0,
      "step": 9040
    },
    {
      "epoch": 0.581956144299402,
      "grad_norm": 0.0014277581358328462,
      "learning_rate": 0.00012638016956831273,
      "loss": 0.0001,
      "step": 9050
    },
    {
      "epoch": 0.5825991897627162,
      "grad_norm": 0.003853968344628811,
      "learning_rate": 0.0001261860073781632,
      "loss": 0.0,
      "step": 9060
    },
    {
      "epoch": 0.5832422352260305,
      "grad_norm": 0.00029182370053604245,
      "learning_rate": 0.00012599184518801373,
      "loss": 0.0,
      "step": 9070
    },
    {
      "epoch": 0.5838852806893448,
      "grad_norm": 0.000583847111556679,
      "learning_rate": 0.0001257976829978642,
      "loss": 0.0001,
      "step": 9080
    },
    {
      "epoch": 0.584528326152659,
      "grad_norm": 0.0022436901926994324,
      "learning_rate": 0.0001256035208077147,
      "loss": 0.0,
      "step": 9090
    },
    {
      "epoch": 0.5851713716159732,
      "grad_norm": 0.010021990165114403,
      "learning_rate": 0.00012540935861756521,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 0.5858144170792875,
      "grad_norm": 0.0012459945864975452,
      "learning_rate": 0.00012521519642741567,
      "loss": 0.0001,
      "step": 9110
    },
    {
      "epoch": 0.5864574625426018,
      "grad_norm": 0.00936313159763813,
      "learning_rate": 0.0001250210342372662,
      "loss": 0.0001,
      "step": 9120
    },
    {
      "epoch": 0.5871005080059161,
      "grad_norm": 0.001350642298348248,
      "learning_rate": 0.0001248268720471167,
      "loss": 0.0,
      "step": 9130
    },
    {
      "epoch": 0.5877435534692302,
      "grad_norm": 0.004283128771930933,
      "learning_rate": 0.00012463270985696716,
      "loss": 0.0,
      "step": 9140
    },
    {
      "epoch": 0.5883865989325445,
      "grad_norm": 0.0002949445624835789,
      "learning_rate": 0.00012443854766681768,
      "loss": 0.0,
      "step": 9150
    },
    {
      "epoch": 0.5890296443958588,
      "grad_norm": 0.001021861215122044,
      "learning_rate": 0.00012424438547666816,
      "loss": 0.0,
      "step": 9160
    },
    {
      "epoch": 0.5896726898591731,
      "grad_norm": 0.001552138477563858,
      "learning_rate": 0.00012405022328651865,
      "loss": 0.0,
      "step": 9170
    },
    {
      "epoch": 0.5903157353224873,
      "grad_norm": 0.0007914268644526601,
      "learning_rate": 0.00012385606109636916,
      "loss": 0.0,
      "step": 9180
    },
    {
      "epoch": 0.5909587807858016,
      "grad_norm": 0.00015781378897372633,
      "learning_rate": 0.00012366189890621965,
      "loss": 0.0,
      "step": 9190
    },
    {
      "epoch": 0.5916018262491158,
      "grad_norm": 0.022576961666345596,
      "learning_rate": 0.00012346773671607014,
      "loss": 0.0001,
      "step": 9200
    },
    {
      "epoch": 0.5922448717124301,
      "grad_norm": 0.005820626858621836,
      "learning_rate": 0.00012327357452592065,
      "loss": 0.0001,
      "step": 9210
    },
    {
      "epoch": 0.5928879171757443,
      "grad_norm": 0.000742654490750283,
      "learning_rate": 0.00012307941233577114,
      "loss": 0.0,
      "step": 9220
    },
    {
      "epoch": 0.5935309626390586,
      "grad_norm": 0.002421658718958497,
      "learning_rate": 0.00012288525014562162,
      "loss": 0.0001,
      "step": 9230
    },
    {
      "epoch": 0.5941740081023729,
      "grad_norm": 0.0011232227552682161,
      "learning_rate": 0.00012269108795547214,
      "loss": 0.0,
      "step": 9240
    },
    {
      "epoch": 0.5948170535656871,
      "grad_norm": 0.0003203350934199989,
      "learning_rate": 0.00012249692576532262,
      "loss": 0.0001,
      "step": 9250
    },
    {
      "epoch": 0.5954600990290013,
      "grad_norm": 0.0006354125216603279,
      "learning_rate": 0.0001223027635751731,
      "loss": 0.0,
      "step": 9260
    },
    {
      "epoch": 0.5961031444923156,
      "grad_norm": 0.0009951884858310223,
      "learning_rate": 0.00012210860138502362,
      "loss": 0.0,
      "step": 9270
    },
    {
      "epoch": 0.5967461899556299,
      "grad_norm": 0.00023261677415575832,
      "learning_rate": 0.00012191443919487411,
      "loss": 0.0001,
      "step": 9280
    },
    {
      "epoch": 0.5973892354189441,
      "grad_norm": 4.1344733238220215,
      "learning_rate": 0.0001217202770047246,
      "loss": 0.0006,
      "step": 9290
    },
    {
      "epoch": 0.5980322808822583,
      "grad_norm": 0.0029277715366333723,
      "learning_rate": 0.0001215261148145751,
      "loss": 0.0001,
      "step": 9300
    },
    {
      "epoch": 0.5986753263455726,
      "grad_norm": 0.0013595217606052756,
      "learning_rate": 0.0001213319526244256,
      "loss": 0.0,
      "step": 9310
    },
    {
      "epoch": 0.5993183718088869,
      "grad_norm": 0.0013923544902354479,
      "learning_rate": 0.00012113779043427609,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 0.5999614172722011,
      "grad_norm": 0.0036962570156902075,
      "learning_rate": 0.00012094362824412659,
      "loss": 0.0001,
      "step": 9330
    },
    {
      "epoch": 0.6006044627355154,
      "grad_norm": 0.001504751737229526,
      "learning_rate": 0.00012074946605397709,
      "loss": 0.0001,
      "step": 9340
    },
    {
      "epoch": 0.6012475081988297,
      "grad_norm": 0.0036410619504749775,
      "learning_rate": 0.00012055530386382757,
      "loss": 0.0001,
      "step": 9350
    },
    {
      "epoch": 0.601890553662144,
      "grad_norm": 0.0019964815583080053,
      "learning_rate": 0.00012036114167367807,
      "loss": 0.0004,
      "step": 9360
    },
    {
      "epoch": 0.6025335991254581,
      "grad_norm": 0.03413243219256401,
      "learning_rate": 0.00012016697948352857,
      "loss": 0.0001,
      "step": 9370
    },
    {
      "epoch": 0.6031766445887724,
      "grad_norm": 0.0027205687947571278,
      "learning_rate": 0.00011997281729337905,
      "loss": 0.0001,
      "step": 9380
    },
    {
      "epoch": 0.6038196900520867,
      "grad_norm": 0.0007828169618733227,
      "learning_rate": 0.00011977865510322955,
      "loss": 0.0001,
      "step": 9390
    },
    {
      "epoch": 0.604462735515401,
      "grad_norm": 0.0006051269010640681,
      "learning_rate": 0.00011958449291308005,
      "loss": 0.0002,
      "step": 9400
    },
    {
      "epoch": 0.6051057809787151,
      "grad_norm": 0.0007393297855742276,
      "learning_rate": 0.00011939033072293053,
      "loss": 0.0,
      "step": 9410
    },
    {
      "epoch": 0.6057488264420294,
      "grad_norm": 0.0024086609482765198,
      "learning_rate": 0.00011919616853278104,
      "loss": 0.0001,
      "step": 9420
    },
    {
      "epoch": 0.6063918719053437,
      "grad_norm": 0.005708172917366028,
      "learning_rate": 0.00011900200634263154,
      "loss": 0.0,
      "step": 9430
    },
    {
      "epoch": 0.607034917368658,
      "grad_norm": 0.0008764393860474229,
      "learning_rate": 0.00011880784415248202,
      "loss": 0.0,
      "step": 9440
    },
    {
      "epoch": 0.6076779628319722,
      "grad_norm": 0.0015671673463657498,
      "learning_rate": 0.00011861368196233252,
      "loss": 0.0001,
      "step": 9450
    },
    {
      "epoch": 0.6083210082952865,
      "grad_norm": 0.0006167041137814522,
      "learning_rate": 0.00011841951977218302,
      "loss": 0.0,
      "step": 9460
    },
    {
      "epoch": 0.6089640537586007,
      "grad_norm": 0.000988259445875883,
      "learning_rate": 0.00011822535758203351,
      "loss": 0.0,
      "step": 9470
    },
    {
      "epoch": 0.609607099221915,
      "grad_norm": 0.0008992826915346086,
      "learning_rate": 0.00011803119539188401,
      "loss": 0.0001,
      "step": 9480
    },
    {
      "epoch": 0.6102501446852292,
      "grad_norm": 0.0017857783241197467,
      "learning_rate": 0.00011783703320173451,
      "loss": 0.0002,
      "step": 9490
    },
    {
      "epoch": 0.6108931901485435,
      "grad_norm": 0.0008787265396676958,
      "learning_rate": 0.000117642871011585,
      "loss": 0.0001,
      "step": 9500
    },
    {
      "epoch": 0.6115362356118578,
      "grad_norm": 0.002132699592038989,
      "learning_rate": 0.0001174487088214355,
      "loss": 0.0001,
      "step": 9510
    },
    {
      "epoch": 0.612179281075172,
      "grad_norm": 0.002243062248453498,
      "learning_rate": 0.000117254546631286,
      "loss": 0.0002,
      "step": 9520
    },
    {
      "epoch": 0.6128223265384862,
      "grad_norm": 0.004329511895775795,
      "learning_rate": 0.00011706038444113648,
      "loss": 0.0,
      "step": 9530
    },
    {
      "epoch": 0.6134653720018005,
      "grad_norm": 0.0005632442771457136,
      "learning_rate": 0.00011686622225098698,
      "loss": 0.0001,
      "step": 9540
    },
    {
      "epoch": 0.6141084174651148,
      "grad_norm": 0.0008075055084191263,
      "learning_rate": 0.00011667206006083749,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 0.6147514629284291,
      "grad_norm": 0.000587924849241972,
      "learning_rate": 0.00011647789787068796,
      "loss": 0.0,
      "step": 9560
    },
    {
      "epoch": 0.6153945083917433,
      "grad_norm": 0.00020326788944657892,
      "learning_rate": 0.00011628373568053846,
      "loss": 0.0001,
      "step": 9570
    },
    {
      "epoch": 0.6160375538550575,
      "grad_norm": 0.0009735338389873505,
      "learning_rate": 0.00011608957349038896,
      "loss": 0.0001,
      "step": 9580
    },
    {
      "epoch": 0.6166805993183718,
      "grad_norm": 0.0029423178639262915,
      "learning_rate": 0.00011589541130023945,
      "loss": 0.0,
      "step": 9590
    },
    {
      "epoch": 0.6173236447816861,
      "grad_norm": 0.0036531658843159676,
      "learning_rate": 0.00011570124911008995,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 0.6179666902450003,
      "grad_norm": 0.0013491915306076407,
      "learning_rate": 0.00011550708691994045,
      "loss": 0.0,
      "step": 9610
    },
    {
      "epoch": 0.6186097357083146,
      "grad_norm": 0.0010383442277088761,
      "learning_rate": 0.00011531292472979093,
      "loss": 0.0,
      "step": 9620
    },
    {
      "epoch": 0.6192527811716289,
      "grad_norm": 0.0007424508221447468,
      "learning_rate": 0.00011511876253964143,
      "loss": 0.0001,
      "step": 9630
    },
    {
      "epoch": 0.6198958266349431,
      "grad_norm": 0.0004813809646293521,
      "learning_rate": 0.00011492460034949193,
      "loss": 0.0,
      "step": 9640
    },
    {
      "epoch": 0.6205388720982573,
      "grad_norm": 0.00045378654613159597,
      "learning_rate": 0.00011473043815934242,
      "loss": 0.0,
      "step": 9650
    },
    {
      "epoch": 0.6211819175615716,
      "grad_norm": 0.0004477341426536441,
      "learning_rate": 0.00011453627596919292,
      "loss": 0.0001,
      "step": 9660
    },
    {
      "epoch": 0.6218249630248859,
      "grad_norm": 0.0034400871954858303,
      "learning_rate": 0.00011434211377904342,
      "loss": 0.0,
      "step": 9670
    },
    {
      "epoch": 0.6224680084882002,
      "grad_norm": 0.0007851376431062818,
      "learning_rate": 0.00011414795158889391,
      "loss": 0.0,
      "step": 9680
    },
    {
      "epoch": 0.6231110539515143,
      "grad_norm": 0.0016856478760018945,
      "learning_rate": 0.00011395378939874441,
      "loss": 0.0001,
      "step": 9690
    },
    {
      "epoch": 0.6237540994148286,
      "grad_norm": 0.0003594055015128106,
      "learning_rate": 0.00011375962720859491,
      "loss": 0.0001,
      "step": 9700
    },
    {
      "epoch": 0.6243971448781429,
      "grad_norm": 0.00041813813732005656,
      "learning_rate": 0.00011356546501844541,
      "loss": 0.0,
      "step": 9710
    },
    {
      "epoch": 0.6250401903414572,
      "grad_norm": 0.0006487001664936543,
      "learning_rate": 0.0001133713028282959,
      "loss": 0.0,
      "step": 9720
    },
    {
      "epoch": 0.6256832358047714,
      "grad_norm": 0.0015823557041585445,
      "learning_rate": 0.0001131771406381464,
      "loss": 0.0002,
      "step": 9730
    },
    {
      "epoch": 0.6263262812680856,
      "grad_norm": 0.0002685284707695246,
      "learning_rate": 0.0001129829784479969,
      "loss": 0.0,
      "step": 9740
    },
    {
      "epoch": 0.6269693267313999,
      "grad_norm": 0.00267645507119596,
      "learning_rate": 0.00011278881625784737,
      "loss": 0.0041,
      "step": 9750
    },
    {
      "epoch": 0.6276123721947142,
      "grad_norm": 0.0003354515938553959,
      "learning_rate": 0.00011259465406769787,
      "loss": 0.0,
      "step": 9760
    },
    {
      "epoch": 0.6282554176580284,
      "grad_norm": 0.004071907140314579,
      "learning_rate": 0.00011240049187754837,
      "loss": 0.0001,
      "step": 9770
    },
    {
      "epoch": 0.6288984631213427,
      "grad_norm": 0.002093250397592783,
      "learning_rate": 0.00011220632968739886,
      "loss": 0.0001,
      "step": 9780
    },
    {
      "epoch": 0.629541508584657,
      "grad_norm": 0.0011045377468690276,
      "learning_rate": 0.00011201216749724936,
      "loss": 0.0,
      "step": 9790
    },
    {
      "epoch": 0.6301845540479712,
      "grad_norm": 0.00378820882178843,
      "learning_rate": 0.00011181800530709986,
      "loss": 0.0001,
      "step": 9800
    },
    {
      "epoch": 0.6308275995112854,
      "grad_norm": 0.001336901099421084,
      "learning_rate": 0.00011162384311695034,
      "loss": 0.0001,
      "step": 9810
    },
    {
      "epoch": 0.6314706449745997,
      "grad_norm": 0.0003945833013858646,
      "learning_rate": 0.00011142968092680085,
      "loss": 0.0001,
      "step": 9820
    },
    {
      "epoch": 0.632113690437914,
      "grad_norm": 0.0003708822187036276,
      "learning_rate": 0.00011123551873665135,
      "loss": 0.0001,
      "step": 9830
    },
    {
      "epoch": 0.6327567359012282,
      "grad_norm": 0.0006451227818615735,
      "learning_rate": 0.00011104135654650183,
      "loss": 0.0,
      "step": 9840
    },
    {
      "epoch": 0.6333997813645424,
      "grad_norm": 0.002784363692626357,
      "learning_rate": 0.00011084719435635233,
      "loss": 0.0,
      "step": 9850
    },
    {
      "epoch": 0.6340428268278567,
      "grad_norm": 0.0004761791497003287,
      "learning_rate": 0.00011065303216620283,
      "loss": 0.0,
      "step": 9860
    },
    {
      "epoch": 0.634685872291171,
      "grad_norm": 0.022902311757206917,
      "learning_rate": 0.00011045886997605332,
      "loss": 0.0001,
      "step": 9870
    },
    {
      "epoch": 0.6353289177544852,
      "grad_norm": 0.00138101854827255,
      "learning_rate": 0.00011026470778590382,
      "loss": 0.0,
      "step": 9880
    },
    {
      "epoch": 0.6359719632177995,
      "grad_norm": 0.0007626926526427269,
      "learning_rate": 0.00011007054559575432,
      "loss": 0.0001,
      "step": 9890
    },
    {
      "epoch": 0.6366150086811138,
      "grad_norm": 0.002183808945119381,
      "learning_rate": 0.00010987638340560481,
      "loss": 0.0001,
      "step": 9900
    },
    {
      "epoch": 0.637258054144428,
      "grad_norm": 0.06795252859592438,
      "learning_rate": 0.00010968222121545531,
      "loss": 0.0001,
      "step": 9910
    },
    {
      "epoch": 0.6379010996077422,
      "grad_norm": 0.00031642874819226563,
      "learning_rate": 0.00010948805902530581,
      "loss": 0.0,
      "step": 9920
    },
    {
      "epoch": 0.6385441450710565,
      "grad_norm": 0.0003552561975084245,
      "learning_rate": 0.00010929389683515628,
      "loss": 0.0001,
      "step": 9930
    },
    {
      "epoch": 0.6391871905343708,
      "grad_norm": 0.0006125819054432213,
      "learning_rate": 0.00010909973464500678,
      "loss": 0.0,
      "step": 9940
    },
    {
      "epoch": 0.6398302359976851,
      "grad_norm": 0.0013969516148790717,
      "learning_rate": 0.00010890557245485728,
      "loss": 0.0,
      "step": 9950
    },
    {
      "epoch": 0.6404732814609992,
      "grad_norm": 0.007607653271406889,
      "learning_rate": 0.00010871141026470777,
      "loss": 0.0,
      "step": 9960
    },
    {
      "epoch": 0.6411163269243135,
      "grad_norm": 0.00024125169147737324,
      "learning_rate": 0.00010851724807455827,
      "loss": 0.0001,
      "step": 9970
    },
    {
      "epoch": 0.6417593723876278,
      "grad_norm": 0.0011784496018663049,
      "learning_rate": 0.00010832308588440877,
      "loss": 0.0,
      "step": 9980
    },
    {
      "epoch": 0.6424024178509421,
      "grad_norm": 0.0008578110137023032,
      "learning_rate": 0.00010812892369425926,
      "loss": 0.0,
      "step": 9990
    },
    {
      "epoch": 0.6430454633142563,
      "grad_norm": 0.0009169272379949689,
      "learning_rate": 0.00010793476150410976,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 0.6436885087775706,
      "grad_norm": 0.0010477910982444882,
      "learning_rate": 0.00010774059931396026,
      "loss": 0.0,
      "step": 10010
    },
    {
      "epoch": 0.6443315542408848,
      "grad_norm": 0.0004937588237226009,
      "learning_rate": 0.00010754643712381074,
      "loss": 0.0,
      "step": 10020
    },
    {
      "epoch": 0.6449745997041991,
      "grad_norm": 0.0010748637141659856,
      "learning_rate": 0.00010735227493366124,
      "loss": 0.0,
      "step": 10030
    },
    {
      "epoch": 0.6456176451675133,
      "grad_norm": 0.0006078651058487594,
      "learning_rate": 0.00010715811274351174,
      "loss": 0.0,
      "step": 10040
    },
    {
      "epoch": 0.6462606906308276,
      "grad_norm": 0.0024887702893465757,
      "learning_rate": 0.00010696395055336223,
      "loss": 0.0,
      "step": 10050
    },
    {
      "epoch": 0.6469037360941419,
      "grad_norm": 0.0010484025115147233,
      "learning_rate": 0.00010676978836321273,
      "loss": 0.0,
      "step": 10060
    },
    {
      "epoch": 0.6475467815574562,
      "grad_norm": 0.0003974078281316906,
      "learning_rate": 0.00010657562617306323,
      "loss": 0.0,
      "step": 10070
    },
    {
      "epoch": 0.6481898270207703,
      "grad_norm": 0.002355054719373584,
      "learning_rate": 0.0001063814639829137,
      "loss": 0.0,
      "step": 10080
    },
    {
      "epoch": 0.6488328724840846,
      "grad_norm": 0.002794224303215742,
      "learning_rate": 0.00010618730179276422,
      "loss": 0.0,
      "step": 10090
    },
    {
      "epoch": 0.6494759179473989,
      "grad_norm": 0.0010669659823179245,
      "learning_rate": 0.00010599313960261472,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 0.6501189634107132,
      "grad_norm": 0.0004258898552507162,
      "learning_rate": 0.00010579897741246519,
      "loss": 0.0,
      "step": 10110
    },
    {
      "epoch": 0.6507620088740274,
      "grad_norm": 0.003587715793401003,
      "learning_rate": 0.00010560481522231569,
      "loss": 0.0002,
      "step": 10120
    },
    {
      "epoch": 0.6514050543373416,
      "grad_norm": 0.0038625465240329504,
      "learning_rate": 0.00010541065303216619,
      "loss": 0.0,
      "step": 10130
    },
    {
      "epoch": 0.6520480998006559,
      "grad_norm": 0.002760071773082018,
      "learning_rate": 0.00010521649084201668,
      "loss": 0.0,
      "step": 10140
    },
    {
      "epoch": 0.6526911452639702,
      "grad_norm": 0.0025672209449112415,
      "learning_rate": 0.00010502232865186718,
      "loss": 0.0,
      "step": 10150
    },
    {
      "epoch": 0.6533341907272844,
      "grad_norm": 0.0009679211652837694,
      "learning_rate": 0.00010482816646171768,
      "loss": 0.0,
      "step": 10160
    },
    {
      "epoch": 0.6539772361905987,
      "grad_norm": 0.0041811056435108185,
      "learning_rate": 0.00010463400427156817,
      "loss": 0.0,
      "step": 10170
    },
    {
      "epoch": 0.654620281653913,
      "grad_norm": 0.0018242372898384929,
      "learning_rate": 0.00010443984208141867,
      "loss": 0.0,
      "step": 10180
    },
    {
      "epoch": 0.6552633271172272,
      "grad_norm": 0.0001672983926255256,
      "learning_rate": 0.00010424567989126917,
      "loss": 0.0,
      "step": 10190
    },
    {
      "epoch": 0.6559063725805414,
      "grad_norm": 0.0002912718919105828,
      "learning_rate": 0.00010405151770111965,
      "loss": 0.0,
      "step": 10200
    },
    {
      "epoch": 0.6565494180438557,
      "grad_norm": 0.005930699408054352,
      "learning_rate": 0.00010385735551097016,
      "loss": 0.0178,
      "step": 10210
    },
    {
      "epoch": 0.65719246350717,
      "grad_norm": 0.002233176724985242,
      "learning_rate": 0.00010366319332082066,
      "loss": 0.0,
      "step": 10220
    },
    {
      "epoch": 0.6578355089704843,
      "grad_norm": 0.001358146546408534,
      "learning_rate": 0.00010346903113067114,
      "loss": 0.0,
      "step": 10230
    },
    {
      "epoch": 0.6584785544337984,
      "grad_norm": 0.00024651031708344817,
      "learning_rate": 0.00010327486894052164,
      "loss": 0.0001,
      "step": 10240
    },
    {
      "epoch": 0.6591215998971127,
      "grad_norm": 0.004753839690238237,
      "learning_rate": 0.00010308070675037214,
      "loss": 0.0,
      "step": 10250
    },
    {
      "epoch": 0.659764645360427,
      "grad_norm": 0.0006125036743469536,
      "learning_rate": 0.00010288654456022262,
      "loss": 0.0,
      "step": 10260
    },
    {
      "epoch": 0.6604076908237413,
      "grad_norm": 10.347783088684082,
      "learning_rate": 0.00010269238237007312,
      "loss": 0.0017,
      "step": 10270
    },
    {
      "epoch": 0.6610507362870555,
      "grad_norm": 0.0006511950632557273,
      "learning_rate": 0.00010249822017992362,
      "loss": 0.0001,
      "step": 10280
    },
    {
      "epoch": 0.6616937817503697,
      "grad_norm": 14.330679893493652,
      "learning_rate": 0.0001023040579897741,
      "loss": 0.0058,
      "step": 10290
    },
    {
      "epoch": 0.662336827213684,
      "grad_norm": 0.002874910132959485,
      "learning_rate": 0.0001021098957996246,
      "loss": 0.0001,
      "step": 10300
    },
    {
      "epoch": 0.6629798726769983,
      "grad_norm": 0.0004592021577991545,
      "learning_rate": 0.0001019157336094751,
      "loss": 0.0001,
      "step": 10310
    },
    {
      "epoch": 0.6636229181403125,
      "grad_norm": 0.0007784066256135702,
      "learning_rate": 0.0001017215714193256,
      "loss": 0.0001,
      "step": 10320
    },
    {
      "epoch": 0.6642659636036268,
      "grad_norm": 0.000580250401981175,
      "learning_rate": 0.00010152740922917609,
      "loss": 0.0,
      "step": 10330
    },
    {
      "epoch": 0.6649090090669411,
      "grad_norm": 0.004722888115793467,
      "learning_rate": 0.00010133324703902659,
      "loss": 0.0001,
      "step": 10340
    },
    {
      "epoch": 0.6655520545302553,
      "grad_norm": 0.0007335690897889435,
      "learning_rate": 0.00010113908484887709,
      "loss": 0.0,
      "step": 10350
    },
    {
      "epoch": 0.6661950999935695,
      "grad_norm": 0.011242086067795753,
      "learning_rate": 0.00010094492265872758,
      "loss": 0.0001,
      "step": 10360
    },
    {
      "epoch": 0.6668381454568838,
      "grad_norm": 0.002022984204813838,
      "learning_rate": 0.00010075076046857808,
      "loss": 0.0001,
      "step": 10370
    },
    {
      "epoch": 0.6674811909201981,
      "grad_norm": 0.001838425174355507,
      "learning_rate": 0.00010055659827842858,
      "loss": 0.0,
      "step": 10380
    },
    {
      "epoch": 0.6681242363835123,
      "grad_norm": 0.0006129389512352645,
      "learning_rate": 0.00010036243608827907,
      "loss": 0.0,
      "step": 10390
    },
    {
      "epoch": 0.6687672818468265,
      "grad_norm": 0.00029041108791716397,
      "learning_rate": 0.00010016827389812957,
      "loss": 0.0,
      "step": 10400
    },
    {
      "epoch": 0.6694103273101408,
      "grad_norm": 0.0017483438132330775,
      "learning_rate": 9.997411170798007e-05,
      "loss": 0.0,
      "step": 10410
    },
    {
      "epoch": 0.6700533727734551,
      "grad_norm": 0.00023110276379156858,
      "learning_rate": 9.977994951783055e-05,
      "loss": 0.0,
      "step": 10420
    },
    {
      "epoch": 0.6706964182367693,
      "grad_norm": 0.006923454813659191,
      "learning_rate": 9.958578732768105e-05,
      "loss": 0.0,
      "step": 10430
    },
    {
      "epoch": 0.6713394637000836,
      "grad_norm": 0.0019896402955055237,
      "learning_rate": 9.939162513753155e-05,
      "loss": 0.0,
      "step": 10440
    },
    {
      "epoch": 0.6719825091633979,
      "grad_norm": 0.002383958315476775,
      "learning_rate": 9.919746294738203e-05,
      "loss": 0.0,
      "step": 10450
    },
    {
      "epoch": 0.6726255546267121,
      "grad_norm": 0.0005654376000165939,
      "learning_rate": 9.900330075723253e-05,
      "loss": 0.0,
      "step": 10460
    },
    {
      "epoch": 0.6732686000900263,
      "grad_norm": 0.0004890440031886101,
      "learning_rate": 9.880913856708303e-05,
      "loss": 0.0,
      "step": 10470
    },
    {
      "epoch": 0.6739116455533406,
      "grad_norm": 0.0016284361481666565,
      "learning_rate": 9.861497637693352e-05,
      "loss": 0.0,
      "step": 10480
    },
    {
      "epoch": 0.6745546910166549,
      "grad_norm": 0.0005948352627456188,
      "learning_rate": 9.842081418678402e-05,
      "loss": 0.0,
      "step": 10490
    },
    {
      "epoch": 0.6751977364799692,
      "grad_norm": 0.0022824443876743317,
      "learning_rate": 9.822665199663452e-05,
      "loss": 0.0,
      "step": 10500
    },
    {
      "epoch": 0.6758407819432833,
      "grad_norm": 0.0007490952266380191,
      "learning_rate": 9.8032489806485e-05,
      "loss": 0.0,
      "step": 10510
    },
    {
      "epoch": 0.6764838274065976,
      "grad_norm": 0.001010062755085528,
      "learning_rate": 9.78383276163355e-05,
      "loss": 0.0,
      "step": 10520
    },
    {
      "epoch": 0.6771268728699119,
      "grad_norm": 0.00038256117841228843,
      "learning_rate": 9.7644165426186e-05,
      "loss": 0.0,
      "step": 10530
    },
    {
      "epoch": 0.6777699183332262,
      "grad_norm": 0.00382005563005805,
      "learning_rate": 9.745000323603649e-05,
      "loss": 0.0,
      "step": 10540
    },
    {
      "epoch": 0.6784129637965404,
      "grad_norm": 0.0007515908218920231,
      "learning_rate": 9.725584104588699e-05,
      "loss": 0.0,
      "step": 10550
    },
    {
      "epoch": 0.6790560092598547,
      "grad_norm": 0.0006418652483262122,
      "learning_rate": 9.706167885573749e-05,
      "loss": 0.0,
      "step": 10560
    },
    {
      "epoch": 0.6796990547231689,
      "grad_norm": 0.00023407276603393257,
      "learning_rate": 9.686751666558798e-05,
      "loss": 0.0,
      "step": 10570
    },
    {
      "epoch": 0.6803421001864832,
      "grad_norm": 0.0018120382446795702,
      "learning_rate": 9.667335447543848e-05,
      "loss": 0.0002,
      "step": 10580
    },
    {
      "epoch": 0.6809851456497974,
      "grad_norm": 0.0007833109120838344,
      "learning_rate": 9.647919228528898e-05,
      "loss": 0.0,
      "step": 10590
    },
    {
      "epoch": 0.6816281911131117,
      "grad_norm": 0.05549749359488487,
      "learning_rate": 9.628503009513946e-05,
      "loss": 0.0001,
      "step": 10600
    },
    {
      "epoch": 0.682271236576426,
      "grad_norm": 0.0011272900737822056,
      "learning_rate": 9.609086790498997e-05,
      "loss": 0.0001,
      "step": 10610
    },
    {
      "epoch": 0.6829142820397403,
      "grad_norm": 0.0010672867065295577,
      "learning_rate": 9.589670571484047e-05,
      "loss": 0.0,
      "step": 10620
    },
    {
      "epoch": 0.6835573275030544,
      "grad_norm": 0.000675750954542309,
      "learning_rate": 9.570254352469094e-05,
      "loss": 0.0,
      "step": 10630
    },
    {
      "epoch": 0.6842003729663687,
      "grad_norm": 0.0003360824193805456,
      "learning_rate": 9.550838133454144e-05,
      "loss": 0.0,
      "step": 10640
    },
    {
      "epoch": 0.684843418429683,
      "grad_norm": 0.00043059984454885125,
      "learning_rate": 9.531421914439194e-05,
      "loss": 0.0001,
      "step": 10650
    },
    {
      "epoch": 0.6854864638929973,
      "grad_norm": 0.00320347398519516,
      "learning_rate": 9.512005695424243e-05,
      "loss": 0.0,
      "step": 10660
    },
    {
      "epoch": 0.6861295093563115,
      "grad_norm": 0.005339430179446936,
      "learning_rate": 9.492589476409293e-05,
      "loss": 0.0001,
      "step": 10670
    },
    {
      "epoch": 0.6867725548196257,
      "grad_norm": 0.0009450040524825454,
      "learning_rate": 9.473173257394343e-05,
      "loss": 0.0,
      "step": 10680
    },
    {
      "epoch": 0.68741560028294,
      "grad_norm": 0.0039508156478405,
      "learning_rate": 9.453757038379391e-05,
      "loss": 0.0,
      "step": 10690
    },
    {
      "epoch": 0.6880586457462543,
      "grad_norm": 0.002317856764420867,
      "learning_rate": 9.434340819364441e-05,
      "loss": 0.0,
      "step": 10700
    },
    {
      "epoch": 0.6887016912095685,
      "grad_norm": 0.0015479187713935971,
      "learning_rate": 9.414924600349491e-05,
      "loss": 0.0,
      "step": 10710
    },
    {
      "epoch": 0.6893447366728828,
      "grad_norm": 0.00021808584278915077,
      "learning_rate": 9.39550838133454e-05,
      "loss": 0.0,
      "step": 10720
    },
    {
      "epoch": 0.689987782136197,
      "grad_norm": 0.0014589857310056686,
      "learning_rate": 9.37609216231959e-05,
      "loss": 0.0,
      "step": 10730
    },
    {
      "epoch": 0.6906308275995113,
      "grad_norm": 0.0009859857382252812,
      "learning_rate": 9.35667594330464e-05,
      "loss": 0.0,
      "step": 10740
    },
    {
      "epoch": 0.6912738730628255,
      "grad_norm": 0.0003796436940319836,
      "learning_rate": 9.337259724289689e-05,
      "loss": 0.0,
      "step": 10750
    },
    {
      "epoch": 0.6919169185261398,
      "grad_norm": 0.0006332310731522739,
      "learning_rate": 9.317843505274739e-05,
      "loss": 0.0001,
      "step": 10760
    },
    {
      "epoch": 0.6925599639894541,
      "grad_norm": 0.0030033376533538103,
      "learning_rate": 9.298427286259789e-05,
      "loss": 0.0,
      "step": 10770
    },
    {
      "epoch": 0.6932030094527684,
      "grad_norm": 0.0005373688763938844,
      "learning_rate": 9.279011067244838e-05,
      "loss": 0.0,
      "step": 10780
    },
    {
      "epoch": 0.6938460549160825,
      "grad_norm": 0.00039313192246481776,
      "learning_rate": 9.259594848229888e-05,
      "loss": 0.0,
      "step": 10790
    },
    {
      "epoch": 0.6944891003793968,
      "grad_norm": 0.0002135474787792191,
      "learning_rate": 9.240178629214938e-05,
      "loss": 0.0001,
      "step": 10800
    },
    {
      "epoch": 0.6951321458427111,
      "grad_norm": 0.00019585831614676863,
      "learning_rate": 9.220762410199985e-05,
      "loss": 0.0,
      "step": 10810
    },
    {
      "epoch": 0.6957751913060254,
      "grad_norm": 0.0004250176134519279,
      "learning_rate": 9.201346191185035e-05,
      "loss": 0.0004,
      "step": 10820
    },
    {
      "epoch": 0.6964182367693396,
      "grad_norm": 0.0017086671432480216,
      "learning_rate": 9.181929972170085e-05,
      "loss": 0.0,
      "step": 10830
    },
    {
      "epoch": 0.6970612822326538,
      "grad_norm": 0.07905939221382141,
      "learning_rate": 9.162513753155134e-05,
      "loss": 0.0002,
      "step": 10840
    },
    {
      "epoch": 0.6977043276959681,
      "grad_norm": 0.01619933918118477,
      "learning_rate": 9.143097534140184e-05,
      "loss": 0.0001,
      "step": 10850
    },
    {
      "epoch": 0.6983473731592824,
      "grad_norm": 0.12427453696727753,
      "learning_rate": 9.123681315125234e-05,
      "loss": 0.0,
      "step": 10860
    },
    {
      "epoch": 0.6989904186225966,
      "grad_norm": 0.0004890533164143562,
      "learning_rate": 9.104265096110282e-05,
      "loss": 0.0,
      "step": 10870
    },
    {
      "epoch": 0.6996334640859109,
      "grad_norm": 0.00053964409744367,
      "learning_rate": 9.084848877095333e-05,
      "loss": 0.0,
      "step": 10880
    },
    {
      "epoch": 0.7002765095492252,
      "grad_norm": 0.0013031837297603488,
      "learning_rate": 9.065432658080383e-05,
      "loss": 0.0,
      "step": 10890
    },
    {
      "epoch": 0.7009195550125394,
      "grad_norm": 0.0007824798231013119,
      "learning_rate": 9.046016439065431e-05,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 0.7015626004758536,
      "grad_norm": 0.002632190240547061,
      "learning_rate": 9.026600220050481e-05,
      "loss": 0.0001,
      "step": 10910
    },
    {
      "epoch": 0.7022056459391679,
      "grad_norm": 0.00038782847695983946,
      "learning_rate": 9.007184001035531e-05,
      "loss": 0.0,
      "step": 10920
    },
    {
      "epoch": 0.7028486914024822,
      "grad_norm": 0.0005057547823525965,
      "learning_rate": 8.987767782020581e-05,
      "loss": 0.0,
      "step": 10930
    },
    {
      "epoch": 0.7034917368657964,
      "grad_norm": 0.0006051218369975686,
      "learning_rate": 8.96835156300563e-05,
      "loss": 0.0,
      "step": 10940
    },
    {
      "epoch": 0.7041347823291106,
      "grad_norm": 0.005585671868175268,
      "learning_rate": 8.94893534399068e-05,
      "loss": 0.0,
      "step": 10950
    },
    {
      "epoch": 0.7047778277924249,
      "grad_norm": 0.002700299257412553,
      "learning_rate": 8.92951912497573e-05,
      "loss": 0.0,
      "step": 10960
    },
    {
      "epoch": 0.7054208732557392,
      "grad_norm": 0.0010725818574428558,
      "learning_rate": 8.910102905960779e-05,
      "loss": 0.0,
      "step": 10970
    },
    {
      "epoch": 0.7060639187190534,
      "grad_norm": 0.0009222626104019582,
      "learning_rate": 8.890686686945829e-05,
      "loss": 0.0001,
      "step": 10980
    },
    {
      "epoch": 0.7067069641823677,
      "grad_norm": 0.00046831899089738727,
      "learning_rate": 8.871270467930879e-05,
      "loss": 0.0,
      "step": 10990
    },
    {
      "epoch": 0.707350009645682,
      "grad_norm": 0.0034707398153841496,
      "learning_rate": 8.851854248915926e-05,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 0.7079930551089962,
      "grad_norm": 0.0016950055724009871,
      "learning_rate": 8.832438029900976e-05,
      "loss": 0.0,
      "step": 11010
    },
    {
      "epoch": 0.7086361005723104,
      "grad_norm": 0.0011689959792420268,
      "learning_rate": 8.813021810886026e-05,
      "loss": 0.0,
      "step": 11020
    },
    {
      "epoch": 0.7092791460356247,
      "grad_norm": 0.0053083160892128944,
      "learning_rate": 8.793605591871075e-05,
      "loss": 0.0,
      "step": 11030
    },
    {
      "epoch": 0.709922191498939,
      "grad_norm": 0.001724619185552001,
      "learning_rate": 8.774189372856125e-05,
      "loss": 0.0,
      "step": 11040
    },
    {
      "epoch": 0.7105652369622533,
      "grad_norm": 0.0009561660699546337,
      "learning_rate": 8.754773153841175e-05,
      "loss": 0.0,
      "step": 11050
    },
    {
      "epoch": 0.7112082824255674,
      "grad_norm": 0.0032398917246609926,
      "learning_rate": 8.735356934826224e-05,
      "loss": 0.0,
      "step": 11060
    },
    {
      "epoch": 0.7118513278888817,
      "grad_norm": 0.004838115070015192,
      "learning_rate": 8.715940715811274e-05,
      "loss": 0.0,
      "step": 11070
    },
    {
      "epoch": 0.712494373352196,
      "grad_norm": 10.65848159790039,
      "learning_rate": 8.696524496796324e-05,
      "loss": 0.0043,
      "step": 11080
    },
    {
      "epoch": 0.7131374188155103,
      "grad_norm": 0.0006903161993250251,
      "learning_rate": 8.677108277781372e-05,
      "loss": 0.0,
      "step": 11090
    },
    {
      "epoch": 0.7137804642788245,
      "grad_norm": 0.001511826878413558,
      "learning_rate": 8.657692058766422e-05,
      "loss": 0.0001,
      "step": 11100
    },
    {
      "epoch": 0.7144235097421388,
      "grad_norm": 0.0007038578623905778,
      "learning_rate": 8.638275839751472e-05,
      "loss": 0.0,
      "step": 11110
    },
    {
      "epoch": 0.715066555205453,
      "grad_norm": 0.0014989947667345405,
      "learning_rate": 8.618859620736521e-05,
      "loss": 0.0001,
      "step": 11120
    },
    {
      "epoch": 0.7157096006687673,
      "grad_norm": 0.0006454346585087478,
      "learning_rate": 8.599443401721571e-05,
      "loss": 0.0,
      "step": 11130
    },
    {
      "epoch": 0.7163526461320815,
      "grad_norm": 0.0009188905241899192,
      "learning_rate": 8.580027182706621e-05,
      "loss": 0.0004,
      "step": 11140
    },
    {
      "epoch": 0.7169956915953958,
      "grad_norm": 0.0036056358367204666,
      "learning_rate": 8.56061096369167e-05,
      "loss": 0.0001,
      "step": 11150
    },
    {
      "epoch": 0.7176387370587101,
      "grad_norm": 0.0006858411943539977,
      "learning_rate": 8.54119474467672e-05,
      "loss": 0.0001,
      "step": 11160
    },
    {
      "epoch": 0.7182817825220243,
      "grad_norm": 0.0016975689213722944,
      "learning_rate": 8.52177852566177e-05,
      "loss": 0.0101,
      "step": 11170
    },
    {
      "epoch": 0.7189248279853385,
      "grad_norm": 0.00196564057841897,
      "learning_rate": 8.502362306646817e-05,
      "loss": 0.0,
      "step": 11180
    },
    {
      "epoch": 0.7195678734486528,
      "grad_norm": 0.0004125229606870562,
      "learning_rate": 8.482946087631867e-05,
      "loss": 0.0001,
      "step": 11190
    },
    {
      "epoch": 0.7202109189119671,
      "grad_norm": 0.006994870025664568,
      "learning_rate": 8.463529868616917e-05,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 0.7208539643752814,
      "grad_norm": 0.0013524902751669288,
      "learning_rate": 8.444113649601966e-05,
      "loss": 0.0,
      "step": 11210
    },
    {
      "epoch": 0.7214970098385955,
      "grad_norm": 0.0007782502216286957,
      "learning_rate": 8.424697430587016e-05,
      "loss": 0.0,
      "step": 11220
    },
    {
      "epoch": 0.7221400553019098,
      "grad_norm": 0.006525293458253145,
      "learning_rate": 8.405281211572066e-05,
      "loss": 0.0001,
      "step": 11230
    },
    {
      "epoch": 0.7227831007652241,
      "grad_norm": 0.028751887381076813,
      "learning_rate": 8.385864992557115e-05,
      "loss": 0.0001,
      "step": 11240
    },
    {
      "epoch": 0.7234261462285384,
      "grad_norm": 0.0011269953101873398,
      "learning_rate": 8.366448773542165e-05,
      "loss": 0.0,
      "step": 11250
    },
    {
      "epoch": 0.7240691916918526,
      "grad_norm": 0.0003957937879022211,
      "learning_rate": 8.347032554527215e-05,
      "loss": 0.0088,
      "step": 11260
    },
    {
      "epoch": 0.7247122371551669,
      "grad_norm": 0.0027437498793005943,
      "learning_rate": 8.327616335512264e-05,
      "loss": 0.0001,
      "step": 11270
    },
    {
      "epoch": 0.7253552826184811,
      "grad_norm": 0.0018226085230708122,
      "learning_rate": 8.308200116497314e-05,
      "loss": 0.0,
      "step": 11280
    },
    {
      "epoch": 0.7259983280817954,
      "grad_norm": 0.007952512241899967,
      "learning_rate": 8.288783897482364e-05,
      "loss": 0.0,
      "step": 11290
    },
    {
      "epoch": 0.7266413735451096,
      "grad_norm": 0.0017003087559714913,
      "learning_rate": 8.269367678467412e-05,
      "loss": 0.0001,
      "step": 11300
    },
    {
      "epoch": 0.7272844190084239,
      "grad_norm": 0.0006891303928568959,
      "learning_rate": 8.249951459452462e-05,
      "loss": 0.0001,
      "step": 11310
    },
    {
      "epoch": 0.7279274644717382,
      "grad_norm": 0.0017579160630702972,
      "learning_rate": 8.230535240437512e-05,
      "loss": 0.0,
      "step": 11320
    },
    {
      "epoch": 0.7285705099350525,
      "grad_norm": 0.0008538583642803133,
      "learning_rate": 8.21111902142256e-05,
      "loss": 0.0,
      "step": 11330
    },
    {
      "epoch": 0.7292135553983666,
      "grad_norm": 0.001999424071982503,
      "learning_rate": 8.19170280240761e-05,
      "loss": 0.0,
      "step": 11340
    },
    {
      "epoch": 0.7298566008616809,
      "grad_norm": 0.0010579926893115044,
      "learning_rate": 8.172286583392661e-05,
      "loss": 0.0043,
      "step": 11350
    },
    {
      "epoch": 0.7304996463249952,
      "grad_norm": 0.0024036483373492956,
      "learning_rate": 8.152870364377708e-05,
      "loss": 0.0001,
      "step": 11360
    },
    {
      "epoch": 0.7311426917883095,
      "grad_norm": 0.0022626749705523252,
      "learning_rate": 8.133454145362758e-05,
      "loss": 0.0001,
      "step": 11370
    },
    {
      "epoch": 0.7317857372516237,
      "grad_norm": 0.006268913391977549,
      "learning_rate": 8.114037926347808e-05,
      "loss": 0.0,
      "step": 11380
    },
    {
      "epoch": 0.7324287827149379,
      "grad_norm": 0.0022937029134482145,
      "learning_rate": 8.094621707332857e-05,
      "loss": 0.0001,
      "step": 11390
    },
    {
      "epoch": 0.7330718281782522,
      "grad_norm": 0.001117704319767654,
      "learning_rate": 8.075205488317907e-05,
      "loss": 0.0001,
      "step": 11400
    },
    {
      "epoch": 0.7337148736415665,
      "grad_norm": 0.0013172595063224435,
      "learning_rate": 8.055789269302957e-05,
      "loss": 0.0001,
      "step": 11410
    },
    {
      "epoch": 0.7343579191048807,
      "grad_norm": 0.0019602205138653517,
      "learning_rate": 8.036373050288006e-05,
      "loss": 0.0,
      "step": 11420
    },
    {
      "epoch": 0.735000964568195,
      "grad_norm": 0.10558150708675385,
      "learning_rate": 8.016956831273056e-05,
      "loss": 0.0001,
      "step": 11430
    },
    {
      "epoch": 0.7356440100315093,
      "grad_norm": 0.0011976673267781734,
      "learning_rate": 7.997540612258106e-05,
      "loss": 0.0001,
      "step": 11440
    },
    {
      "epoch": 0.7362870554948235,
      "grad_norm": 0.000806029187515378,
      "learning_rate": 7.978124393243155e-05,
      "loss": 0.0001,
      "step": 11450
    },
    {
      "epoch": 0.7369301009581377,
      "grad_norm": 0.0017942044651135802,
      "learning_rate": 7.958708174228205e-05,
      "loss": 0.0,
      "step": 11460
    },
    {
      "epoch": 0.737573146421452,
      "grad_norm": 0.0003420714638195932,
      "learning_rate": 7.939291955213255e-05,
      "loss": 0.0,
      "step": 11470
    },
    {
      "epoch": 0.7382161918847663,
      "grad_norm": 0.0006803469732403755,
      "learning_rate": 7.919875736198303e-05,
      "loss": 0.0,
      "step": 11480
    },
    {
      "epoch": 0.7388592373480805,
      "grad_norm": 0.01355068851262331,
      "learning_rate": 7.900459517183353e-05,
      "loss": 0.0,
      "step": 11490
    },
    {
      "epoch": 0.7395022828113947,
      "grad_norm": 0.0013042596401646733,
      "learning_rate": 7.881043298168403e-05,
      "loss": 0.0003,
      "step": 11500
    },
    {
      "epoch": 0.740145328274709,
      "grad_norm": 0.000899612030480057,
      "learning_rate": 7.861627079153451e-05,
      "loss": 0.0001,
      "step": 11510
    },
    {
      "epoch": 0.7407883737380233,
      "grad_norm": 0.0044864751398563385,
      "learning_rate": 7.842210860138501e-05,
      "loss": 0.0031,
      "step": 11520
    },
    {
      "epoch": 0.7414314192013375,
      "grad_norm": 0.00028244967688806355,
      "learning_rate": 7.822794641123551e-05,
      "loss": 0.0,
      "step": 11530
    },
    {
      "epoch": 0.7420744646646518,
      "grad_norm": 0.000879076833371073,
      "learning_rate": 7.8033784221086e-05,
      "loss": 0.0,
      "step": 11540
    },
    {
      "epoch": 0.742717510127966,
      "grad_norm": 0.00029020942747592926,
      "learning_rate": 7.78396220309365e-05,
      "loss": 0.0001,
      "step": 11550
    },
    {
      "epoch": 0.7433605555912803,
      "grad_norm": 0.0006534614367410541,
      "learning_rate": 7.7645459840787e-05,
      "loss": 0.0,
      "step": 11560
    },
    {
      "epoch": 0.7440036010545945,
      "grad_norm": 0.002180284820497036,
      "learning_rate": 7.74512976506375e-05,
      "loss": 0.0,
      "step": 11570
    },
    {
      "epoch": 0.7446466465179088,
      "grad_norm": 0.0013815902639180422,
      "learning_rate": 7.725713546048798e-05,
      "loss": 0.0001,
      "step": 11580
    },
    {
      "epoch": 0.7452896919812231,
      "grad_norm": 0.004259872250258923,
      "learning_rate": 7.706297327033848e-05,
      "loss": 0.0,
      "step": 11590
    },
    {
      "epoch": 0.7459327374445374,
      "grad_norm": 0.0013271862408146262,
      "learning_rate": 7.686881108018898e-05,
      "loss": 0.0001,
      "step": 11600
    },
    {
      "epoch": 0.7465757829078515,
      "grad_norm": 0.003933869302272797,
      "learning_rate": 7.667464889003947e-05,
      "loss": 0.0,
      "step": 11610
    },
    {
      "epoch": 0.7472188283711658,
      "grad_norm": 0.0015479223802685738,
      "learning_rate": 7.648048669988997e-05,
      "loss": 0.0,
      "step": 11620
    },
    {
      "epoch": 0.7478618738344801,
      "grad_norm": 0.000569749332498759,
      "learning_rate": 7.628632450974047e-05,
      "loss": 0.0,
      "step": 11630
    },
    {
      "epoch": 0.7485049192977944,
      "grad_norm": 0.0014048301381990314,
      "learning_rate": 7.609216231959096e-05,
      "loss": 0.0,
      "step": 11640
    },
    {
      "epoch": 0.7491479647611086,
      "grad_norm": 0.002778529655188322,
      "learning_rate": 7.589800012944146e-05,
      "loss": 0.0,
      "step": 11650
    },
    {
      "epoch": 0.7497910102244228,
      "grad_norm": 0.0003223049861844629,
      "learning_rate": 7.570383793929196e-05,
      "loss": 0.0,
      "step": 11660
    },
    {
      "epoch": 0.7504340556877371,
      "grad_norm": 0.0008444809354841709,
      "learning_rate": 7.550967574914245e-05,
      "loss": 0.0,
      "step": 11670
    },
    {
      "epoch": 0.7510771011510514,
      "grad_norm": 0.0009894465329125524,
      "learning_rate": 7.531551355899295e-05,
      "loss": 0.0,
      "step": 11680
    },
    {
      "epoch": 0.7517201466143656,
      "grad_norm": 0.00030100246658548713,
      "learning_rate": 7.512135136884345e-05,
      "loss": 0.0,
      "step": 11690
    },
    {
      "epoch": 0.7523631920776799,
      "grad_norm": 0.0052633266896009445,
      "learning_rate": 7.492718917869393e-05,
      "loss": 0.0,
      "step": 11700
    },
    {
      "epoch": 0.7530062375409942,
      "grad_norm": 0.001781396334990859,
      "learning_rate": 7.473302698854442e-05,
      "loss": 0.0001,
      "step": 11710
    },
    {
      "epoch": 0.7536492830043084,
      "grad_norm": 0.00030505924951285124,
      "learning_rate": 7.453886479839492e-05,
      "loss": 0.0,
      "step": 11720
    },
    {
      "epoch": 0.7542923284676226,
      "grad_norm": 0.00013378645235206932,
      "learning_rate": 7.434470260824542e-05,
      "loss": 0.0,
      "step": 11730
    },
    {
      "epoch": 0.7549353739309369,
      "grad_norm": 0.004383506253361702,
      "learning_rate": 7.415054041809591e-05,
      "loss": 0.0,
      "step": 11740
    },
    {
      "epoch": 0.7555784193942512,
      "grad_norm": 0.001271539367735386,
      "learning_rate": 7.395637822794641e-05,
      "loss": 0.0,
      "step": 11750
    },
    {
      "epoch": 0.7562214648575655,
      "grad_norm": 0.0006397546385414898,
      "learning_rate": 7.376221603779691e-05,
      "loss": 0.0,
      "step": 11760
    },
    {
      "epoch": 0.7568645103208796,
      "grad_norm": 0.0005756761529482901,
      "learning_rate": 7.35680538476474e-05,
      "loss": 0.0,
      "step": 11770
    },
    {
      "epoch": 0.7575075557841939,
      "grad_norm": 0.0006092588300816715,
      "learning_rate": 7.33738916574979e-05,
      "loss": 0.0,
      "step": 11780
    },
    {
      "epoch": 0.7581506012475082,
      "grad_norm": 0.0005383455427363515,
      "learning_rate": 7.31797294673484e-05,
      "loss": 0.0,
      "step": 11790
    },
    {
      "epoch": 0.7587936467108225,
      "grad_norm": 0.001626742072403431,
      "learning_rate": 7.298556727719888e-05,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 0.7594366921741367,
      "grad_norm": 0.0017922284314408898,
      "learning_rate": 7.279140508704937e-05,
      "loss": 0.0,
      "step": 11810
    },
    {
      "epoch": 0.760079737637451,
      "grad_norm": 0.000979645294137299,
      "learning_rate": 7.259724289689987e-05,
      "loss": 0.0,
      "step": 11820
    },
    {
      "epoch": 0.7607227831007652,
      "grad_norm": 0.0011910703033208847,
      "learning_rate": 7.240308070675037e-05,
      "loss": 0.0001,
      "step": 11830
    },
    {
      "epoch": 0.7613658285640795,
      "grad_norm": 0.034334421157836914,
      "learning_rate": 7.220891851660086e-05,
      "loss": 0.0001,
      "step": 11840
    },
    {
      "epoch": 0.7620088740273937,
      "grad_norm": 0.00026244096807204187,
      "learning_rate": 7.201475632645136e-05,
      "loss": 0.0,
      "step": 11850
    },
    {
      "epoch": 0.762651919490708,
      "grad_norm": 0.0023175054229795933,
      "learning_rate": 7.182059413630186e-05,
      "loss": 0.0,
      "step": 11860
    },
    {
      "epoch": 0.7632949649540223,
      "grad_norm": 0.00026536567020229995,
      "learning_rate": 7.162643194615234e-05,
      "loss": 0.0,
      "step": 11870
    },
    {
      "epoch": 0.7639380104173366,
      "grad_norm": 0.006477858405560255,
      "learning_rate": 7.143226975600284e-05,
      "loss": 0.0,
      "step": 11880
    },
    {
      "epoch": 0.7645810558806507,
      "grad_norm": 0.0009409182239323854,
      "learning_rate": 7.123810756585333e-05,
      "loss": 0.0,
      "step": 11890
    },
    {
      "epoch": 0.765224101343965,
      "grad_norm": 0.0003211350704077631,
      "learning_rate": 7.104394537570383e-05,
      "loss": 0.0002,
      "step": 11900
    },
    {
      "epoch": 0.7658671468072793,
      "grad_norm": 0.0001710911892587319,
      "learning_rate": 7.084978318555433e-05,
      "loss": 0.0,
      "step": 11910
    },
    {
      "epoch": 0.7665101922705936,
      "grad_norm": 0.004835548810660839,
      "learning_rate": 7.065562099540482e-05,
      "loss": 0.0001,
      "step": 11920
    },
    {
      "epoch": 0.7671532377339078,
      "grad_norm": 0.0008696298464201391,
      "learning_rate": 7.046145880525532e-05,
      "loss": 0.0006,
      "step": 11930
    },
    {
      "epoch": 0.767796283197222,
      "grad_norm": 0.004672395531088114,
      "learning_rate": 7.026729661510582e-05,
      "loss": 0.0,
      "step": 11940
    },
    {
      "epoch": 0.7684393286605363,
      "grad_norm": 0.0022536003962159157,
      "learning_rate": 7.00731344249563e-05,
      "loss": 0.0013,
      "step": 11950
    },
    {
      "epoch": 0.7690823741238506,
      "grad_norm": 0.0007927982951514423,
      "learning_rate": 6.987897223480679e-05,
      "loss": 0.0,
      "step": 11960
    },
    {
      "epoch": 0.7697254195871648,
      "grad_norm": 0.009228996001183987,
      "learning_rate": 6.968481004465729e-05,
      "loss": 0.0,
      "step": 11970
    },
    {
      "epoch": 0.7703684650504791,
      "grad_norm": 0.0013904256047680974,
      "learning_rate": 6.949064785450779e-05,
      "loss": 0.0001,
      "step": 11980
    },
    {
      "epoch": 0.7710115105137934,
      "grad_norm": 0.0006398542900569737,
      "learning_rate": 6.931590188337324e-05,
      "loss": 0.0022,
      "step": 11990
    },
    {
      "epoch": 0.7716545559771076,
      "grad_norm": 0.0006346140871755779,
      "learning_rate": 6.912173969322372e-05,
      "loss": 0.0,
      "step": 12000
    },
    {
      "epoch": 0.7722976014404218,
      "grad_norm": 13.791332244873047,
      "learning_rate": 6.892757750307422e-05,
      "loss": 0.0033,
      "step": 12010
    },
    {
      "epoch": 0.7729406469037361,
      "grad_norm": 0.0008253863197751343,
      "learning_rate": 6.873341531292472e-05,
      "loss": 0.0,
      "step": 12020
    },
    {
      "epoch": 0.7735836923670504,
      "grad_norm": 0.0010623253183439374,
      "learning_rate": 6.853925312277522e-05,
      "loss": 0.0,
      "step": 12030
    },
    {
      "epoch": 0.7742267378303646,
      "grad_norm": 0.0005240517784841359,
      "learning_rate": 6.834509093262571e-05,
      "loss": 0.0,
      "step": 12040
    },
    {
      "epoch": 0.7748697832936788,
      "grad_norm": 0.0033895010128617287,
      "learning_rate": 6.815092874247621e-05,
      "loss": 0.0,
      "step": 12050
    },
    {
      "epoch": 0.7755128287569931,
      "grad_norm": 0.008915184997022152,
      "learning_rate": 6.795676655232671e-05,
      "loss": 0.0,
      "step": 12060
    },
    {
      "epoch": 0.7761558742203074,
      "grad_norm": 0.0005869801389053464,
      "learning_rate": 6.77626043621772e-05,
      "loss": 0.0,
      "step": 12070
    },
    {
      "epoch": 0.7767989196836216,
      "grad_norm": 0.0013901743805035949,
      "learning_rate": 6.75684421720277e-05,
      "loss": 0.0,
      "step": 12080
    },
    {
      "epoch": 0.7774419651469359,
      "grad_norm": 0.02166573703289032,
      "learning_rate": 6.73742799818782e-05,
      "loss": 0.0,
      "step": 12090
    },
    {
      "epoch": 0.7780850106102501,
      "grad_norm": 0.0006926673231646419,
      "learning_rate": 6.718011779172869e-05,
      "loss": 0.0,
      "step": 12100
    },
    {
      "epoch": 0.7787280560735644,
      "grad_norm": 0.0010969397844746709,
      "learning_rate": 6.698595560157917e-05,
      "loss": 0.0,
      "step": 12110
    },
    {
      "epoch": 0.7793711015368786,
      "grad_norm": 0.008536127395927906,
      "learning_rate": 6.679179341142967e-05,
      "loss": 0.0,
      "step": 12120
    },
    {
      "epoch": 0.7800141470001929,
      "grad_norm": 0.003242544364184141,
      "learning_rate": 6.659763122128017e-05,
      "loss": 0.0,
      "step": 12130
    },
    {
      "epoch": 0.7806571924635072,
      "grad_norm": 0.002049186499789357,
      "learning_rate": 6.640346903113066e-05,
      "loss": 0.0,
      "step": 12140
    },
    {
      "epoch": 0.7813002379268215,
      "grad_norm": 0.001511420588940382,
      "learning_rate": 6.620930684098116e-05,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 0.7819432833901356,
      "grad_norm": 0.0011171676451340318,
      "learning_rate": 6.601514465083166e-05,
      "loss": 0.0001,
      "step": 12160
    },
    {
      "epoch": 0.7825863288534499,
      "grad_norm": 0.0004662679275497794,
      "learning_rate": 6.582098246068215e-05,
      "loss": 0.0,
      "step": 12170
    },
    {
      "epoch": 0.7832293743167642,
      "grad_norm": 0.0003857884439639747,
      "learning_rate": 6.562682027053265e-05,
      "loss": 0.0,
      "step": 12180
    },
    {
      "epoch": 0.7838724197800785,
      "grad_norm": 0.00025620823726058006,
      "learning_rate": 6.543265808038313e-05,
      "loss": 0.0001,
      "step": 12190
    },
    {
      "epoch": 0.7845154652433927,
      "grad_norm": 0.010724951513111591,
      "learning_rate": 6.523849589023364e-05,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 0.785158510706707,
      "grad_norm": 0.0011508919997140765,
      "learning_rate": 6.504433370008414e-05,
      "loss": 0.0,
      "step": 12210
    },
    {
      "epoch": 0.7858015561700212,
      "grad_norm": 0.0006272295140661299,
      "learning_rate": 6.485017150993462e-05,
      "loss": 0.0,
      "step": 12220
    },
    {
      "epoch": 0.7864446016333355,
      "grad_norm": 0.0013804163318127394,
      "learning_rate": 6.465600931978512e-05,
      "loss": 0.0,
      "step": 12230
    },
    {
      "epoch": 0.7870876470966497,
      "grad_norm": 0.002222110517323017,
      "learning_rate": 6.446184712963562e-05,
      "loss": 0.0,
      "step": 12240
    },
    {
      "epoch": 0.787730692559964,
      "grad_norm": 0.003476119367405772,
      "learning_rate": 6.426768493948611e-05,
      "loss": 0.0,
      "step": 12250
    },
    {
      "epoch": 0.7883737380232783,
      "grad_norm": 0.00830608420073986,
      "learning_rate": 6.40735227493366e-05,
      "loss": 0.0,
      "step": 12260
    },
    {
      "epoch": 0.7890167834865925,
      "grad_norm": 0.0002905612054746598,
      "learning_rate": 6.387936055918711e-05,
      "loss": 0.0,
      "step": 12270
    },
    {
      "epoch": 0.7896598289499067,
      "grad_norm": 0.001511816051788628,
      "learning_rate": 6.36851983690376e-05,
      "loss": 0.0,
      "step": 12280
    },
    {
      "epoch": 0.790302874413221,
      "grad_norm": 0.0003114911960437894,
      "learning_rate": 6.349103617888808e-05,
      "loss": 0.0,
      "step": 12290
    },
    {
      "epoch": 0.7909459198765353,
      "grad_norm": 0.0006430977955460548,
      "learning_rate": 6.329687398873858e-05,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 0.7915889653398496,
      "grad_norm": 0.00040422374149784446,
      "learning_rate": 6.310271179858908e-05,
      "loss": 0.0,
      "step": 12310
    },
    {
      "epoch": 0.7922320108031637,
      "grad_norm": 0.000344662374118343,
      "learning_rate": 6.290854960843959e-05,
      "loss": 0.0004,
      "step": 12320
    },
    {
      "epoch": 0.792875056266478,
      "grad_norm": 0.0007405102369375527,
      "learning_rate": 6.271438741829007e-05,
      "loss": 0.0,
      "step": 12330
    },
    {
      "epoch": 0.7935181017297923,
      "grad_norm": 0.0028328229673206806,
      "learning_rate": 6.252022522814057e-05,
      "loss": 0.0001,
      "step": 12340
    },
    {
      "epoch": 0.7941611471931066,
      "grad_norm": 0.0011968581238761544,
      "learning_rate": 6.232606303799107e-05,
      "loss": 0.0,
      "step": 12350
    },
    {
      "epoch": 0.7948041926564208,
      "grad_norm": 0.0007511491421610117,
      "learning_rate": 6.213190084784156e-05,
      "loss": 0.0,
      "step": 12360
    },
    {
      "epoch": 0.7954472381197351,
      "grad_norm": 0.001990783028304577,
      "learning_rate": 6.193773865769205e-05,
      "loss": 0.0,
      "step": 12370
    },
    {
      "epoch": 0.7960902835830493,
      "grad_norm": 0.002532063750550151,
      "learning_rate": 6.174357646754255e-05,
      "loss": 0.0,
      "step": 12380
    },
    {
      "epoch": 0.7967333290463636,
      "grad_norm": 0.0002841705281753093,
      "learning_rate": 6.154941427739305e-05,
      "loss": 0.0,
      "step": 12390
    },
    {
      "epoch": 0.7973763745096778,
      "grad_norm": 0.00015387387247756124,
      "learning_rate": 6.135525208724353e-05,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 0.7980194199729921,
      "grad_norm": 0.002757089212536812,
      "learning_rate": 6.116108989709403e-05,
      "loss": 0.0,
      "step": 12410
    },
    {
      "epoch": 0.7986624654363064,
      "grad_norm": 0.0018312848405912519,
      "learning_rate": 6.096692770694453e-05,
      "loss": 0.0,
      "step": 12420
    },
    {
      "epoch": 0.7993055108996207,
      "grad_norm": 0.0008595590479671955,
      "learning_rate": 6.077276551679502e-05,
      "loss": 0.0,
      "step": 12430
    },
    {
      "epoch": 0.7999485563629348,
      "grad_norm": 0.0006815912202000618,
      "learning_rate": 6.057860332664552e-05,
      "loss": 0.0,
      "step": 12440
    },
    {
      "epoch": 0.8005916018262491,
      "grad_norm": 0.0019151854794472456,
      "learning_rate": 6.0384441136496015e-05,
      "loss": 0.0,
      "step": 12450
    },
    {
      "epoch": 0.8012346472895634,
      "grad_norm": 0.0007442302885465324,
      "learning_rate": 6.019027894634651e-05,
      "loss": 0.0,
      "step": 12460
    },
    {
      "epoch": 0.8018776927528777,
      "grad_norm": 0.001133177662268281,
      "learning_rate": 5.999611675619701e-05,
      "loss": 0.0,
      "step": 12470
    },
    {
      "epoch": 0.8025207382161919,
      "grad_norm": 0.002412363886833191,
      "learning_rate": 5.98019545660475e-05,
      "loss": 0.0,
      "step": 12480
    },
    {
      "epoch": 0.8031637836795061,
      "grad_norm": 0.00016176595818251371,
      "learning_rate": 5.960779237589799e-05,
      "loss": 0.0,
      "step": 12490
    },
    {
      "epoch": 0.8038068291428204,
      "grad_norm": 0.00019404002523515373,
      "learning_rate": 5.941363018574849e-05,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 0.8044498746061347,
      "grad_norm": 0.0006771291373297572,
      "learning_rate": 5.921946799559898e-05,
      "loss": 0.0,
      "step": 12510
    },
    {
      "epoch": 0.8050929200694489,
      "grad_norm": 0.0006720146047882736,
      "learning_rate": 5.902530580544948e-05,
      "loss": 0.0,
      "step": 12520
    },
    {
      "epoch": 0.8057359655327632,
      "grad_norm": 0.0005479427054524422,
      "learning_rate": 5.883114361529998e-05,
      "loss": 0.0,
      "step": 12530
    },
    {
      "epoch": 0.8063790109960774,
      "grad_norm": 0.009626404382288456,
      "learning_rate": 5.863698142515047e-05,
      "loss": 0.0,
      "step": 12540
    },
    {
      "epoch": 0.8070220564593916,
      "grad_norm": 0.000842084176838398,
      "learning_rate": 5.8442819235000964e-05,
      "loss": 0.0001,
      "step": 12550
    },
    {
      "epoch": 0.8076651019227059,
      "grad_norm": 0.0015105056809261441,
      "learning_rate": 5.8248657044851464e-05,
      "loss": 0.0,
      "step": 12560
    },
    {
      "epoch": 0.8083081473860202,
      "grad_norm": 0.0014042762340977788,
      "learning_rate": 5.805449485470196e-05,
      "loss": 0.0,
      "step": 12570
    },
    {
      "epoch": 0.8089511928493345,
      "grad_norm": 0.0021989350207149982,
      "learning_rate": 5.7860332664552445e-05,
      "loss": 0.0,
      "step": 12580
    },
    {
      "epoch": 0.8095942383126487,
      "grad_norm": 0.0003279078227933496,
      "learning_rate": 5.7666170474402945e-05,
      "loss": 0.0,
      "step": 12590
    },
    {
      "epoch": 0.8102372837759629,
      "grad_norm": 0.0006342252600006759,
      "learning_rate": 5.747200828425344e-05,
      "loss": 0.0,
      "step": 12600
    },
    {
      "epoch": 0.8108803292392772,
      "grad_norm": 0.00038579353713430464,
      "learning_rate": 5.727784609410393e-05,
      "loss": 0.0,
      "step": 12610
    },
    {
      "epoch": 0.8115233747025915,
      "grad_norm": 0.00014103703142609447,
      "learning_rate": 5.708368390395443e-05,
      "loss": 0.0001,
      "step": 12620
    },
    {
      "epoch": 0.8121664201659057,
      "grad_norm": 0.0007377972942776978,
      "learning_rate": 5.6889521713804926e-05,
      "loss": 0.0,
      "step": 12630
    },
    {
      "epoch": 0.81280946562922,
      "grad_norm": 0.0006567022064700723,
      "learning_rate": 5.6695359523655426e-05,
      "loss": 0.0,
      "step": 12640
    },
    {
      "epoch": 0.8134525110925342,
      "grad_norm": 0.001805687672458589,
      "learning_rate": 5.650119733350592e-05,
      "loss": 0.0,
      "step": 12650
    },
    {
      "epoch": 0.8140955565558485,
      "grad_norm": 0.0020456218626350164,
      "learning_rate": 5.6307035143356414e-05,
      "loss": 0.0,
      "step": 12660
    },
    {
      "epoch": 0.8147386020191627,
      "grad_norm": 0.018359044566750526,
      "learning_rate": 5.6112872953206914e-05,
      "loss": 0.0,
      "step": 12670
    },
    {
      "epoch": 0.815381647482477,
      "grad_norm": 0.000596065423451364,
      "learning_rate": 5.59187107630574e-05,
      "loss": 0.0,
      "step": 12680
    },
    {
      "epoch": 0.8160246929457913,
      "grad_norm": 0.0006495024426840246,
      "learning_rate": 5.5724548572907894e-05,
      "loss": 0.0,
      "step": 12690
    },
    {
      "epoch": 0.8166677384091056,
      "grad_norm": 0.0004963303217664361,
      "learning_rate": 5.5530386382758395e-05,
      "loss": 0.0,
      "step": 12700
    },
    {
      "epoch": 0.8173107838724197,
      "grad_norm": 0.00012074835103703663,
      "learning_rate": 5.533622419260889e-05,
      "loss": 0.0,
      "step": 12710
    },
    {
      "epoch": 0.817953829335734,
      "grad_norm": 0.0008190712542273104,
      "learning_rate": 5.514206200245938e-05,
      "loss": 0.0,
      "step": 12720
    },
    {
      "epoch": 0.8185968747990483,
      "grad_norm": 0.0008404247346334159,
      "learning_rate": 5.494789981230988e-05,
      "loss": 0.0,
      "step": 12730
    },
    {
      "epoch": 0.8192399202623626,
      "grad_norm": 0.00034329923801124096,
      "learning_rate": 5.4753737622160376e-05,
      "loss": 0.0,
      "step": 12740
    },
    {
      "epoch": 0.8198829657256768,
      "grad_norm": 0.0038367651868611574,
      "learning_rate": 5.455957543201087e-05,
      "loss": 0.0,
      "step": 12750
    },
    {
      "epoch": 0.820526011188991,
      "grad_norm": 0.000970755354501307,
      "learning_rate": 5.436541324186137e-05,
      "loss": 0.0,
      "step": 12760
    },
    {
      "epoch": 0.8211690566523053,
      "grad_norm": 0.0003300268726889044,
      "learning_rate": 5.4171251051711856e-05,
      "loss": 0.0,
      "step": 12770
    },
    {
      "epoch": 0.8218121021156196,
      "grad_norm": 0.00014501660189125687,
      "learning_rate": 5.397708886156235e-05,
      "loss": 0.0,
      "step": 12780
    },
    {
      "epoch": 0.8224551475789338,
      "grad_norm": 0.00078148691682145,
      "learning_rate": 5.378292667141285e-05,
      "loss": 0.0,
      "step": 12790
    },
    {
      "epoch": 0.8230981930422481,
      "grad_norm": 0.0012846050085499883,
      "learning_rate": 5.3588764481263344e-05,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 0.8237412385055624,
      "grad_norm": 0.0008307581883855164,
      "learning_rate": 5.339460229111384e-05,
      "loss": 0.0002,
      "step": 12810
    },
    {
      "epoch": 0.8243842839688766,
      "grad_norm": 0.0003076965513173491,
      "learning_rate": 5.320044010096434e-05,
      "loss": 0.0,
      "step": 12820
    },
    {
      "epoch": 0.8250273294321908,
      "grad_norm": 0.0007557401550002396,
      "learning_rate": 5.300627791081483e-05,
      "loss": 0.0,
      "step": 12830
    },
    {
      "epoch": 0.8256703748955051,
      "grad_norm": 0.0006337473751045763,
      "learning_rate": 5.281211572066532e-05,
      "loss": 0.0,
      "step": 12840
    },
    {
      "epoch": 0.8263134203588194,
      "grad_norm": 0.0003939591988455504,
      "learning_rate": 5.2617953530515825e-05,
      "loss": 0.0001,
      "step": 12850
    },
    {
      "epoch": 0.8269564658221337,
      "grad_norm": 0.00044183791032992303,
      "learning_rate": 5.242379134036631e-05,
      "loss": 0.0,
      "step": 12860
    },
    {
      "epoch": 0.8275995112854478,
      "grad_norm": 0.005634332541376352,
      "learning_rate": 5.2229629150216805e-05,
      "loss": 0.0,
      "step": 12870
    },
    {
      "epoch": 0.8282425567487621,
      "grad_norm": 0.00033439931576140225,
      "learning_rate": 5.2035466960067306e-05,
      "loss": 0.0,
      "step": 12880
    },
    {
      "epoch": 0.8288856022120764,
      "grad_norm": 0.00030908919870853424,
      "learning_rate": 5.18413047699178e-05,
      "loss": 0.0003,
      "step": 12890
    },
    {
      "epoch": 0.8295286476753907,
      "grad_norm": 0.0007325265323743224,
      "learning_rate": 5.164714257976829e-05,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 0.8301716931387049,
      "grad_norm": 0.00032815340091474354,
      "learning_rate": 5.145298038961879e-05,
      "loss": 0.0001,
      "step": 12910
    },
    {
      "epoch": 0.8308147386020192,
      "grad_norm": 0.00020513984782155603,
      "learning_rate": 5.125881819946929e-05,
      "loss": 0.0,
      "step": 12920
    },
    {
      "epoch": 0.8314577840653334,
      "grad_norm": 0.0027912186924368143,
      "learning_rate": 5.1064656009319774e-05,
      "loss": 0.0001,
      "step": 12930
    },
    {
      "epoch": 0.8321008295286477,
      "grad_norm": 0.012794439680874348,
      "learning_rate": 5.0870493819170274e-05,
      "loss": 0.0,
      "step": 12940
    },
    {
      "epoch": 0.8327438749919619,
      "grad_norm": 0.001607550773769617,
      "learning_rate": 5.067633162902077e-05,
      "loss": 0.0,
      "step": 12950
    },
    {
      "epoch": 0.8333869204552762,
      "grad_norm": 0.0010718805715441704,
      "learning_rate": 5.048216943887127e-05,
      "loss": 0.0,
      "step": 12960
    },
    {
      "epoch": 0.8340299659185905,
      "grad_norm": 0.0006474778638221323,
      "learning_rate": 5.028800724872176e-05,
      "loss": 0.0,
      "step": 12970
    },
    {
      "epoch": 0.8346730113819048,
      "grad_norm": 0.0001751358067849651,
      "learning_rate": 5.0093845058572255e-05,
      "loss": 0.0,
      "step": 12980
    },
    {
      "epoch": 0.8353160568452189,
      "grad_norm": 0.001762061263434589,
      "learning_rate": 4.9899682868422755e-05,
      "loss": 0.0,
      "step": 12990
    },
    {
      "epoch": 0.8359591023085332,
      "grad_norm": 0.0013354021357372403,
      "learning_rate": 4.970552067827325e-05,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 0.8366021477718475,
      "grad_norm": 0.00034114037407562137,
      "learning_rate": 4.951135848812374e-05,
      "loss": 0.0,
      "step": 13010
    },
    {
      "epoch": 0.8372451932351618,
      "grad_norm": 0.0008688519592396915,
      "learning_rate": 4.931719629797424e-05,
      "loss": 0.0,
      "step": 13020
    },
    {
      "epoch": 0.837888238698476,
      "grad_norm": 0.0002700390759855509,
      "learning_rate": 4.912303410782473e-05,
      "loss": 0.0,
      "step": 13030
    },
    {
      "epoch": 0.8385312841617902,
      "grad_norm": 0.0026128538884222507,
      "learning_rate": 4.892887191767522e-05,
      "loss": 0.0,
      "step": 13040
    },
    {
      "epoch": 0.8391743296251045,
      "grad_norm": 0.00033285023528151214,
      "learning_rate": 4.8734709727525723e-05,
      "loss": 0.0,
      "step": 13050
    },
    {
      "epoch": 0.8398173750884188,
      "grad_norm": 0.001790001755580306,
      "learning_rate": 4.854054753737622e-05,
      "loss": 0.0,
      "step": 13060
    },
    {
      "epoch": 0.840460420551733,
      "grad_norm": 0.0006184607627801597,
      "learning_rate": 4.834638534722671e-05,
      "loss": 0.0,
      "step": 13070
    },
    {
      "epoch": 0.8411034660150473,
      "grad_norm": 0.000541210756637156,
      "learning_rate": 4.815222315707721e-05,
      "loss": 0.0,
      "step": 13080
    },
    {
      "epoch": 0.8417465114783615,
      "grad_norm": 0.005644055083394051,
      "learning_rate": 4.7958060966927704e-05,
      "loss": 0.0,
      "step": 13090
    },
    {
      "epoch": 0.8423895569416757,
      "grad_norm": 0.002928958274424076,
      "learning_rate": 4.77638987767782e-05,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 0.84303260240499,
      "grad_norm": 0.0011469523888081312,
      "learning_rate": 4.75697365866287e-05,
      "loss": 0.0,
      "step": 13110
    },
    {
      "epoch": 0.8436756478683043,
      "grad_norm": 0.00020997304818592966,
      "learning_rate": 4.7375574396479185e-05,
      "loss": 0.0,
      "step": 13120
    },
    {
      "epoch": 0.8443186933316186,
      "grad_norm": 0.0013143847463652492,
      "learning_rate": 4.718141220632968e-05,
      "loss": 0.0,
      "step": 13130
    },
    {
      "epoch": 0.8449617387949327,
      "grad_norm": 0.00022913819702807814,
      "learning_rate": 4.698725001618018e-05,
      "loss": 0.0,
      "step": 13140
    },
    {
      "epoch": 0.845604784258247,
      "grad_norm": 0.0002728087711147964,
      "learning_rate": 4.679308782603067e-05,
      "loss": 0.0,
      "step": 13150
    },
    {
      "epoch": 0.8462478297215613,
      "grad_norm": 0.0025595370680093765,
      "learning_rate": 4.6598925635881166e-05,
      "loss": 0.0,
      "step": 13160
    },
    {
      "epoch": 0.8468908751848756,
      "grad_norm": 0.002187425037845969,
      "learning_rate": 4.6404763445731666e-05,
      "loss": 0.0,
      "step": 13170
    },
    {
      "epoch": 0.8475339206481898,
      "grad_norm": 0.00036419343086890876,
      "learning_rate": 4.621060125558216e-05,
      "loss": 0.0001,
      "step": 13180
    },
    {
      "epoch": 0.8481769661115041,
      "grad_norm": 0.0005153042729943991,
      "learning_rate": 4.6016439065432654e-05,
      "loss": 0.0,
      "step": 13190
    },
    {
      "epoch": 0.8488200115748183,
      "grad_norm": 0.0009052553796209395,
      "learning_rate": 4.5822276875283154e-05,
      "loss": 0.0,
      "step": 13200
    },
    {
      "epoch": 0.8494630570381326,
      "grad_norm": 0.0003250341978855431,
      "learning_rate": 4.562811468513364e-05,
      "loss": 0.0,
      "step": 13210
    },
    {
      "epoch": 0.8501061025014468,
      "grad_norm": 0.0007754556718282402,
      "learning_rate": 4.5433952494984134e-05,
      "loss": 0.0,
      "step": 13220
    },
    {
      "epoch": 0.8507491479647611,
      "grad_norm": 0.0016153488541021943,
      "learning_rate": 4.5239790304834635e-05,
      "loss": 0.0003,
      "step": 13230
    },
    {
      "epoch": 0.8513921934280754,
      "grad_norm": 0.001192359603010118,
      "learning_rate": 4.504562811468513e-05,
      "loss": 0.0,
      "step": 13240
    },
    {
      "epoch": 0.8520352388913897,
      "grad_norm": 0.001773080904968083,
      "learning_rate": 4.485146592453563e-05,
      "loss": 0.0,
      "step": 13250
    },
    {
      "epoch": 0.8526782843547038,
      "grad_norm": 0.00040373089723289013,
      "learning_rate": 4.465730373438612e-05,
      "loss": 0.0001,
      "step": 13260
    },
    {
      "epoch": 0.8533213298180181,
      "grad_norm": 0.0008993378141894937,
      "learning_rate": 4.4463141544236616e-05,
      "loss": 0.0,
      "step": 13270
    },
    {
      "epoch": 0.8539643752813324,
      "grad_norm": 0.00043804605957120657,
      "learning_rate": 4.4268979354087116e-05,
      "loss": 0.0,
      "step": 13280
    },
    {
      "epoch": 0.8546074207446467,
      "grad_norm": 0.0007213089265860617,
      "learning_rate": 4.407481716393761e-05,
      "loss": 0.0,
      "step": 13290
    },
    {
      "epoch": 0.8552504662079609,
      "grad_norm": 0.0028081948403269053,
      "learning_rate": 4.3880654973788096e-05,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 0.8558935116712751,
      "grad_norm": 0.0007410545367747545,
      "learning_rate": 4.36864927836386e-05,
      "loss": 0.0,
      "step": 13310
    },
    {
      "epoch": 0.8565365571345894,
      "grad_norm": 0.0013763898750767112,
      "learning_rate": 4.349233059348909e-05,
      "loss": 0.0,
      "step": 13320
    },
    {
      "epoch": 0.8571796025979037,
      "grad_norm": 0.001311913481913507,
      "learning_rate": 4.3298168403339584e-05,
      "loss": 0.0,
      "step": 13330
    },
    {
      "epoch": 0.8578226480612179,
      "grad_norm": 0.003605814417824149,
      "learning_rate": 4.3104006213190084e-05,
      "loss": 0.0,
      "step": 13340
    },
    {
      "epoch": 0.8584656935245322,
      "grad_norm": 0.002981176832690835,
      "learning_rate": 4.290984402304058e-05,
      "loss": 0.0001,
      "step": 13350
    },
    {
      "epoch": 0.8591087389878465,
      "grad_norm": 0.0015884839231148362,
      "learning_rate": 4.271568183289107e-05,
      "loss": 0.0,
      "step": 13360
    },
    {
      "epoch": 0.8597517844511607,
      "grad_norm": 0.00058026856277138,
      "learning_rate": 4.252151964274157e-05,
      "loss": 0.0,
      "step": 13370
    },
    {
      "epoch": 0.8603948299144749,
      "grad_norm": 0.0006196305039338768,
      "learning_rate": 4.232735745259206e-05,
      "loss": 0.0,
      "step": 13380
    },
    {
      "epoch": 0.8610378753777892,
      "grad_norm": 0.0009535035933367908,
      "learning_rate": 4.213319526244255e-05,
      "loss": 0.0,
      "step": 13390
    },
    {
      "epoch": 0.8616809208411035,
      "grad_norm": 0.0001194183569168672,
      "learning_rate": 4.193903307229305e-05,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 0.8623239663044178,
      "grad_norm": 0.00043020621524192393,
      "learning_rate": 4.1744870882143546e-05,
      "loss": 0.0,
      "step": 13410
    },
    {
      "epoch": 0.8629670117677319,
      "grad_norm": 0.0011506116716191173,
      "learning_rate": 4.155070869199404e-05,
      "loss": 0.0,
      "step": 13420
    },
    {
      "epoch": 0.8636100572310462,
      "grad_norm": 0.0015766125870868564,
      "learning_rate": 4.135654650184454e-05,
      "loss": 0.0,
      "step": 13430
    },
    {
      "epoch": 0.8642531026943605,
      "grad_norm": 0.0004535540647339076,
      "learning_rate": 4.116238431169503e-05,
      "loss": 0.0,
      "step": 13440
    },
    {
      "epoch": 0.8648961481576748,
      "grad_norm": 0.000606100948061794,
      "learning_rate": 4.096822212154553e-05,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 0.865539193620989,
      "grad_norm": 0.00486975209787488,
      "learning_rate": 4.077405993139603e-05,
      "loss": 0.0,
      "step": 13460
    },
    {
      "epoch": 0.8661822390843033,
      "grad_norm": 0.0005809107678942382,
      "learning_rate": 4.0579897741246514e-05,
      "loss": 0.0,
      "step": 13470
    },
    {
      "epoch": 0.8668252845476175,
      "grad_norm": 0.0007214915822260082,
      "learning_rate": 4.038573555109701e-05,
      "loss": 0.0,
      "step": 13480
    },
    {
      "epoch": 0.8674683300109318,
      "grad_norm": 0.001124141039326787,
      "learning_rate": 4.019157336094751e-05,
      "loss": 0.0,
      "step": 13490
    },
    {
      "epoch": 0.868111375474246,
      "grad_norm": 0.0011941000120714307,
      "learning_rate": 3.9997411170798e-05,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 0.8687544209375603,
      "grad_norm": 0.013980495743453503,
      "learning_rate": 3.9803248980648495e-05,
      "loss": 0.0,
      "step": 13510
    },
    {
      "epoch": 0.8693974664008746,
      "grad_norm": 0.0009315572679042816,
      "learning_rate": 3.9609086790498995e-05,
      "loss": 0.0,
      "step": 13520
    },
    {
      "epoch": 0.8700405118641888,
      "grad_norm": 0.0003844614839181304,
      "learning_rate": 3.941492460034949e-05,
      "loss": 0.0,
      "step": 13530
    },
    {
      "epoch": 0.870683557327503,
      "grad_norm": 0.002987929154187441,
      "learning_rate": 3.922076241019998e-05,
      "loss": 0.0,
      "step": 13540
    },
    {
      "epoch": 0.8713266027908173,
      "grad_norm": 0.0014470018213614821,
      "learning_rate": 3.902660022005048e-05,
      "loss": 0.0001,
      "step": 13550
    },
    {
      "epoch": 0.8719696482541316,
      "grad_norm": 0.0006063174805603921,
      "learning_rate": 3.883243802990097e-05,
      "loss": 0.0001,
      "step": 13560
    },
    {
      "epoch": 0.8726126937174459,
      "grad_norm": 0.0002163177850889042,
      "learning_rate": 3.863827583975147e-05,
      "loss": 0.0,
      "step": 13570
    },
    {
      "epoch": 0.87325573918076,
      "grad_norm": 0.0007803746848367155,
      "learning_rate": 3.8444113649601963e-05,
      "loss": 0.0,
      "step": 13580
    },
    {
      "epoch": 0.8738987846440743,
      "grad_norm": 9.267593850381672e-05,
      "learning_rate": 3.824995145945246e-05,
      "loss": 0.0,
      "step": 13590
    },
    {
      "epoch": 0.8745418301073886,
      "grad_norm": 0.000814066210296005,
      "learning_rate": 3.805578926930296e-05,
      "loss": 0.0004,
      "step": 13600
    },
    {
      "epoch": 0.8751848755707029,
      "grad_norm": 0.005704821087419987,
      "learning_rate": 3.786162707915345e-05,
      "loss": 0.0,
      "step": 13610
    },
    {
      "epoch": 0.8758279210340171,
      "grad_norm": 0.00023025440168567002,
      "learning_rate": 3.7667464889003944e-05,
      "loss": 0.0,
      "step": 13620
    },
    {
      "epoch": 0.8764709664973314,
      "grad_norm": 0.00015201956557575613,
      "learning_rate": 3.747330269885444e-05,
      "loss": 0.0001,
      "step": 13630
    },
    {
      "epoch": 0.8771140119606456,
      "grad_norm": 0.0002583807799965143,
      "learning_rate": 3.727914050870494e-05,
      "loss": 0.0,
      "step": 13640
    },
    {
      "epoch": 0.8777570574239598,
      "grad_norm": 0.0003812221984844655,
      "learning_rate": 3.708497831855543e-05,
      "loss": 0.0,
      "step": 13650
    },
    {
      "epoch": 0.8784001028872741,
      "grad_norm": 0.001067209872417152,
      "learning_rate": 3.6890816128405925e-05,
      "loss": 0.0,
      "step": 13660
    },
    {
      "epoch": 0.8790431483505884,
      "grad_norm": 0.0005576355033554137,
      "learning_rate": 3.669665393825642e-05,
      "loss": 0.0001,
      "step": 13670
    },
    {
      "epoch": 0.8796861938139027,
      "grad_norm": 0.00031073472928255796,
      "learning_rate": 3.650249174810692e-05,
      "loss": 0.0,
      "step": 13680
    },
    {
      "epoch": 0.8803292392772168,
      "grad_norm": 0.00047861531493254006,
      "learning_rate": 3.6308329557957406e-05,
      "loss": 0.0,
      "step": 13690
    },
    {
      "epoch": 0.8809722847405311,
      "grad_norm": 0.0004500403010752052,
      "learning_rate": 3.6114167367807906e-05,
      "loss": 0.0,
      "step": 13700
    },
    {
      "epoch": 0.8816153302038454,
      "grad_norm": 0.0011571745853871107,
      "learning_rate": 3.59200051776584e-05,
      "loss": 0.0,
      "step": 13710
    },
    {
      "epoch": 0.8822583756671597,
      "grad_norm": 0.00021073904645163566,
      "learning_rate": 3.5725842987508894e-05,
      "loss": 0.0,
      "step": 13720
    },
    {
      "epoch": 0.8829014211304739,
      "grad_norm": 0.0010021032067015767,
      "learning_rate": 3.5531680797359394e-05,
      "loss": 0.0,
      "step": 13730
    },
    {
      "epoch": 0.8835444665937882,
      "grad_norm": 0.00033079495187848806,
      "learning_rate": 3.533751860720989e-05,
      "loss": 0.0001,
      "step": 13740
    },
    {
      "epoch": 0.8841875120571024,
      "grad_norm": 0.0006520735914818943,
      "learning_rate": 3.514335641706038e-05,
      "loss": 0.0,
      "step": 13750
    },
    {
      "epoch": 0.8848305575204167,
      "grad_norm": 0.0005118439439684153,
      "learning_rate": 3.4949194226910875e-05,
      "loss": 0.0,
      "step": 13760
    },
    {
      "epoch": 0.8854736029837309,
      "grad_norm": 0.0003593234287109226,
      "learning_rate": 3.4755032036761375e-05,
      "loss": 0.0,
      "step": 13770
    },
    {
      "epoch": 0.8861166484470452,
      "grad_norm": 0.00031378722633235157,
      "learning_rate": 3.456086984661186e-05,
      "loss": 0.0,
      "step": 13780
    },
    {
      "epoch": 0.8867596939103595,
      "grad_norm": 0.0034937269520014524,
      "learning_rate": 3.436670765646236e-05,
      "loss": 0.0001,
      "step": 13790
    },
    {
      "epoch": 0.8874027393736738,
      "grad_norm": 0.00017837191990111023,
      "learning_rate": 3.4172545466312856e-05,
      "loss": 0.0,
      "step": 13800
    },
    {
      "epoch": 0.8880457848369879,
      "grad_norm": 0.00026806036476045847,
      "learning_rate": 3.3978383276163356e-05,
      "loss": 0.0,
      "step": 13810
    },
    {
      "epoch": 0.8886888303003022,
      "grad_norm": 0.00390756456181407,
      "learning_rate": 3.378422108601385e-05,
      "loss": 0.0,
      "step": 13820
    },
    {
      "epoch": 0.8893318757636165,
      "grad_norm": 0.0005210120580159128,
      "learning_rate": 3.359005889586434e-05,
      "loss": 0.0,
      "step": 13830
    },
    {
      "epoch": 0.8899749212269308,
      "grad_norm": 0.0005440935492515564,
      "learning_rate": 3.339589670571484e-05,
      "loss": 0.0,
      "step": 13840
    },
    {
      "epoch": 0.890617966690245,
      "grad_norm": 0.0009837769903242588,
      "learning_rate": 3.320173451556533e-05,
      "loss": 0.0,
      "step": 13850
    },
    {
      "epoch": 0.8912610121535592,
      "grad_norm": 0.002023241249844432,
      "learning_rate": 3.300757232541583e-05,
      "loss": 0.0,
      "step": 13860
    },
    {
      "epoch": 0.8919040576168735,
      "grad_norm": 6.67434505885467e-05,
      "learning_rate": 3.2813410135266324e-05,
      "loss": 0.0,
      "step": 13870
    },
    {
      "epoch": 0.8925471030801878,
      "grad_norm": 0.018746931105852127,
      "learning_rate": 3.261924794511682e-05,
      "loss": 0.0,
      "step": 13880
    },
    {
      "epoch": 0.893190148543502,
      "grad_norm": 0.00046224394463934004,
      "learning_rate": 3.242508575496731e-05,
      "loss": 0.0,
      "step": 13890
    },
    {
      "epoch": 0.8938331940068163,
      "grad_norm": 0.00012161797349108383,
      "learning_rate": 3.223092356481781e-05,
      "loss": 0.0,
      "step": 13900
    },
    {
      "epoch": 0.8944762394701306,
      "grad_norm": 0.00013453306746669114,
      "learning_rate": 3.20367613746683e-05,
      "loss": 0.0,
      "step": 13910
    },
    {
      "epoch": 0.8951192849334448,
      "grad_norm": 0.0015272052260115743,
      "learning_rate": 3.18425991845188e-05,
      "loss": 0.0,
      "step": 13920
    },
    {
      "epoch": 0.895762330396759,
      "grad_norm": 0.0018522109603509307,
      "learning_rate": 3.164843699436929e-05,
      "loss": 0.0,
      "step": 13930
    },
    {
      "epoch": 0.8964053758600733,
      "grad_norm": 0.0005428125150501728,
      "learning_rate": 3.145427480421979e-05,
      "loss": 0.0,
      "step": 13940
    },
    {
      "epoch": 0.8970484213233876,
      "grad_norm": 8.313098805956542e-05,
      "learning_rate": 3.1260112614070286e-05,
      "loss": 0.0,
      "step": 13950
    },
    {
      "epoch": 0.8976914667867019,
      "grad_norm": 0.0002764050441328436,
      "learning_rate": 3.106595042392078e-05,
      "loss": 0.0,
      "step": 13960
    },
    {
      "epoch": 0.898334512250016,
      "grad_norm": 0.0002974857052322477,
      "learning_rate": 3.087178823377127e-05,
      "loss": 0.0,
      "step": 13970
    },
    {
      "epoch": 0.8989775577133303,
      "grad_norm": 0.0028838838916271925,
      "learning_rate": 3.067762604362177e-05,
      "loss": 0.0,
      "step": 13980
    },
    {
      "epoch": 0.8996206031766446,
      "grad_norm": 0.0010769730433821678,
      "learning_rate": 3.0483463853472264e-05,
      "loss": 0.0,
      "step": 13990
    },
    {
      "epoch": 0.9002636486399589,
      "grad_norm": 0.0005541890277527273,
      "learning_rate": 3.028930166332276e-05,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 0.9009066941032731,
      "grad_norm": 8.57196282595396e-05,
      "learning_rate": 3.0095139473173254e-05,
      "loss": 0.0001,
      "step": 14010
    },
    {
      "epoch": 0.9015497395665873,
      "grad_norm": 0.014753653667867184,
      "learning_rate": 2.990097728302375e-05,
      "loss": 0.0,
      "step": 14020
    },
    {
      "epoch": 0.9021927850299016,
      "grad_norm": 0.00038040627259761095,
      "learning_rate": 2.9706815092874245e-05,
      "loss": 0.0,
      "step": 14030
    },
    {
      "epoch": 0.9028358304932159,
      "grad_norm": 0.0020512540359050035,
      "learning_rate": 2.951265290272474e-05,
      "loss": 0.0,
      "step": 14040
    },
    {
      "epoch": 0.9034788759565301,
      "grad_norm": 0.0008537965477444232,
      "learning_rate": 2.9318490712575235e-05,
      "loss": 0.0,
      "step": 14050
    },
    {
      "epoch": 0.9041219214198444,
      "grad_norm": 0.0006947494694031775,
      "learning_rate": 2.9124328522425732e-05,
      "loss": 0.0,
      "step": 14060
    },
    {
      "epoch": 0.9047649668831587,
      "grad_norm": 0.0022616833448410034,
      "learning_rate": 2.8930166332276222e-05,
      "loss": 0.0,
      "step": 14070
    },
    {
      "epoch": 0.905408012346473,
      "grad_norm": 0.00015328293375205249,
      "learning_rate": 2.873600414212672e-05,
      "loss": 0.0,
      "step": 14080
    },
    {
      "epoch": 0.9060510578097871,
      "grad_norm": 0.0002680807956494391,
      "learning_rate": 2.8541841951977216e-05,
      "loss": 0.0,
      "step": 14090
    },
    {
      "epoch": 0.9066941032731014,
      "grad_norm": 0.0013857748126611114,
      "learning_rate": 2.8347679761827713e-05,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 0.9073371487364157,
      "grad_norm": 0.0016564737306907773,
      "learning_rate": 2.8153517571678207e-05,
      "loss": 0.0,
      "step": 14110
    },
    {
      "epoch": 0.90798019419973,
      "grad_norm": 0.00015328568406403065,
      "learning_rate": 2.79593553815287e-05,
      "loss": 0.0,
      "step": 14120
    },
    {
      "epoch": 0.9086232396630441,
      "grad_norm": 0.00034563805093057454,
      "learning_rate": 2.7765193191379197e-05,
      "loss": 0.0,
      "step": 14130
    },
    {
      "epoch": 0.9092662851263584,
      "grad_norm": 0.0009482689783908427,
      "learning_rate": 2.757103100122969e-05,
      "loss": 0.0,
      "step": 14140
    },
    {
      "epoch": 0.9099093305896727,
      "grad_norm": 0.029269929975271225,
      "learning_rate": 2.7376868811080188e-05,
      "loss": 0.0,
      "step": 14150
    },
    {
      "epoch": 0.910552376052987,
      "grad_norm": 0.0009232556913048029,
      "learning_rate": 2.7182706620930685e-05,
      "loss": 0.0,
      "step": 14160
    },
    {
      "epoch": 0.9111954215163012,
      "grad_norm": 0.002856279956176877,
      "learning_rate": 2.6988544430781175e-05,
      "loss": 0.0,
      "step": 14170
    },
    {
      "epoch": 0.9118384669796155,
      "grad_norm": 0.0010427925735712051,
      "learning_rate": 2.6794382240631672e-05,
      "loss": 0.0,
      "step": 14180
    },
    {
      "epoch": 0.9124815124429297,
      "grad_norm": 0.003910386003553867,
      "learning_rate": 2.660022005048217e-05,
      "loss": 0.0,
      "step": 14190
    },
    {
      "epoch": 0.9131245579062439,
      "grad_norm": 0.0010959719074890018,
      "learning_rate": 2.640605786033266e-05,
      "loss": 0.0,
      "step": 14200
    },
    {
      "epoch": 0.9137676033695582,
      "grad_norm": 0.00021074179676361382,
      "learning_rate": 2.6211895670183156e-05,
      "loss": 0.0,
      "step": 14210
    },
    {
      "epoch": 0.9144106488328725,
      "grad_norm": 0.006371954455971718,
      "learning_rate": 2.6017733480033653e-05,
      "loss": 0.0,
      "step": 14220
    },
    {
      "epoch": 0.9150536942961868,
      "grad_norm": 0.0004842444323003292,
      "learning_rate": 2.5823571289884146e-05,
      "loss": 0.0,
      "step": 14230
    },
    {
      "epoch": 0.9156967397595009,
      "grad_norm": 0.0005917912349104881,
      "learning_rate": 2.5629409099734643e-05,
      "loss": 0.0,
      "step": 14240
    },
    {
      "epoch": 0.9163397852228152,
      "grad_norm": 0.0006582131609320641,
      "learning_rate": 2.5435246909585137e-05,
      "loss": 0.0,
      "step": 14250
    },
    {
      "epoch": 0.9169828306861295,
      "grad_norm": 0.00012580701150000095,
      "learning_rate": 2.5241084719435634e-05,
      "loss": 0.0,
      "step": 14260
    },
    {
      "epoch": 0.9176258761494438,
      "grad_norm": 0.00010755498078651726,
      "learning_rate": 2.5046922529286127e-05,
      "loss": 0.0,
      "step": 14270
    },
    {
      "epoch": 0.918268921612758,
      "grad_norm": 0.0035273521207273006,
      "learning_rate": 2.4852760339136624e-05,
      "loss": 0.0,
      "step": 14280
    },
    {
      "epoch": 0.9189119670760723,
      "grad_norm": 0.0003750836185645312,
      "learning_rate": 2.465859814898712e-05,
      "loss": 0.0,
      "step": 14290
    },
    {
      "epoch": 0.9195550125393865,
      "grad_norm": 0.0002557106490712613,
      "learning_rate": 2.446443595883761e-05,
      "loss": 0.0,
      "step": 14300
    },
    {
      "epoch": 0.9201980580027008,
      "grad_norm": 0.0001754331315169111,
      "learning_rate": 2.427027376868811e-05,
      "loss": 0.0,
      "step": 14310
    },
    {
      "epoch": 0.920841103466015,
      "grad_norm": 0.0005707709933631122,
      "learning_rate": 2.4076111578538605e-05,
      "loss": 0.0,
      "step": 14320
    },
    {
      "epoch": 0.9214841489293293,
      "grad_norm": 0.24859103560447693,
      "learning_rate": 2.38819493883891e-05,
      "loss": 0.0002,
      "step": 14330
    },
    {
      "epoch": 0.9221271943926436,
      "grad_norm": 0.0003382110153324902,
      "learning_rate": 2.3687787198239593e-05,
      "loss": 0.0,
      "step": 14340
    },
    {
      "epoch": 0.9227702398559579,
      "grad_norm": 0.00104239908978343,
      "learning_rate": 2.349362500809009e-05,
      "loss": 0.0,
      "step": 14350
    },
    {
      "epoch": 0.923413285319272,
      "grad_norm": 0.004927624017000198,
      "learning_rate": 2.3299462817940583e-05,
      "loss": 0.0,
      "step": 14360
    },
    {
      "epoch": 0.9240563307825863,
      "grad_norm": 0.0012188872788101435,
      "learning_rate": 2.310530062779108e-05,
      "loss": 0.0,
      "step": 14370
    },
    {
      "epoch": 0.9246993762459006,
      "grad_norm": 0.00017095450311899185,
      "learning_rate": 2.2911138437641577e-05,
      "loss": 0.0,
      "step": 14380
    },
    {
      "epoch": 0.9253424217092149,
      "grad_norm": 0.0012721600942313671,
      "learning_rate": 2.2716976247492067e-05,
      "loss": 0.0,
      "step": 14390
    },
    {
      "epoch": 0.925985467172529,
      "grad_norm": 0.007880370132625103,
      "learning_rate": 2.2522814057342564e-05,
      "loss": 0.0,
      "step": 14400
    },
    {
      "epoch": 0.9266285126358433,
      "grad_norm": 0.0011188758071511984,
      "learning_rate": 2.232865186719306e-05,
      "loss": 0.0,
      "step": 14410
    },
    {
      "epoch": 0.9272715580991576,
      "grad_norm": 0.0010300393914803863,
      "learning_rate": 2.2134489677043558e-05,
      "loss": 0.0,
      "step": 14420
    },
    {
      "epoch": 0.9279146035624719,
      "grad_norm": 0.00014320136688183993,
      "learning_rate": 2.1940327486894048e-05,
      "loss": 0.0,
      "step": 14430
    },
    {
      "epoch": 0.9285576490257861,
      "grad_norm": 0.003208571346476674,
      "learning_rate": 2.1746165296744545e-05,
      "loss": 0.0,
      "step": 14440
    },
    {
      "epoch": 0.9292006944891004,
      "grad_norm": 0.0004451903223525733,
      "learning_rate": 2.1552003106595042e-05,
      "loss": 0.0,
      "step": 14450
    },
    {
      "epoch": 0.9298437399524146,
      "grad_norm": 0.00019993669411633164,
      "learning_rate": 2.1357840916445536e-05,
      "loss": 0.0,
      "step": 14460
    },
    {
      "epoch": 0.9304867854157289,
      "grad_norm": 0.0005316718015819788,
      "learning_rate": 2.116367872629603e-05,
      "loss": 0.0,
      "step": 14470
    },
    {
      "epoch": 0.9311298308790431,
      "grad_norm": 0.00030759655055589974,
      "learning_rate": 2.0969516536146526e-05,
      "loss": 0.0,
      "step": 14480
    },
    {
      "epoch": 0.9317728763423574,
      "grad_norm": 0.0012095799902454019,
      "learning_rate": 2.077535434599702e-05,
      "loss": 0.0,
      "step": 14490
    },
    {
      "epoch": 0.9324159218056717,
      "grad_norm": 0.00045811478048563004,
      "learning_rate": 2.0581192155847517e-05,
      "loss": 0.0,
      "step": 14500
    },
    {
      "epoch": 0.933058967268986,
      "grad_norm": 0.0010490786517038941,
      "learning_rate": 2.0387029965698014e-05,
      "loss": 0.0,
      "step": 14510
    },
    {
      "epoch": 0.9337020127323001,
      "grad_norm": 0.002217921894043684,
      "learning_rate": 2.0192867775548504e-05,
      "loss": 0.0,
      "step": 14520
    },
    {
      "epoch": 0.9343450581956144,
      "grad_norm": 0.0005485630827024579,
      "learning_rate": 1.9998705585399e-05,
      "loss": 0.0,
      "step": 14530
    },
    {
      "epoch": 0.9349881036589287,
      "grad_norm": 0.0011428309371694922,
      "learning_rate": 1.9804543395249498e-05,
      "loss": 0.0,
      "step": 14540
    },
    {
      "epoch": 0.935631149122243,
      "grad_norm": 0.0006729696760885417,
      "learning_rate": 1.961038120509999e-05,
      "loss": 0.0,
      "step": 14550
    },
    {
      "epoch": 0.9362741945855572,
      "grad_norm": 0.00031345142633654177,
      "learning_rate": 1.9416219014950485e-05,
      "loss": 0.0,
      "step": 14560
    },
    {
      "epoch": 0.9369172400488714,
      "grad_norm": 0.00018908627680502832,
      "learning_rate": 1.9222056824800982e-05,
      "loss": 0.0,
      "step": 14570
    },
    {
      "epoch": 0.9375602855121857,
      "grad_norm": 0.0003363551222719252,
      "learning_rate": 1.902789463465148e-05,
      "loss": 0.0,
      "step": 14580
    },
    {
      "epoch": 0.9382033309755,
      "grad_norm": 0.0008200563606806099,
      "learning_rate": 1.8833732444501972e-05,
      "loss": 0.0,
      "step": 14590
    },
    {
      "epoch": 0.9388463764388142,
      "grad_norm": 0.0002579166612122208,
      "learning_rate": 1.863957025435247e-05,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 0.9394894219021285,
      "grad_norm": 0.00010983428364852443,
      "learning_rate": 1.8445408064202963e-05,
      "loss": 0.0,
      "step": 14610
    },
    {
      "epoch": 0.9401324673654428,
      "grad_norm": 0.0006227638223208487,
      "learning_rate": 1.825124587405346e-05,
      "loss": 0.0,
      "step": 14620
    },
    {
      "epoch": 0.940775512828757,
      "grad_norm": 0.0003034793771803379,
      "learning_rate": 1.8057083683903953e-05,
      "loss": 0.0,
      "step": 14630
    },
    {
      "epoch": 0.9414185582920712,
      "grad_norm": 0.0004448248364496976,
      "learning_rate": 1.7862921493754447e-05,
      "loss": 0.0,
      "step": 14640
    },
    {
      "epoch": 0.9420616037553855,
      "grad_norm": 0.0010726487962529063,
      "learning_rate": 1.7668759303604944e-05,
      "loss": 0.0,
      "step": 14650
    },
    {
      "epoch": 0.9427046492186998,
      "grad_norm": 0.0019925208762288094,
      "learning_rate": 1.7474597113455437e-05,
      "loss": 0.0,
      "step": 14660
    },
    {
      "epoch": 0.9433476946820141,
      "grad_norm": 0.00024465619935654104,
      "learning_rate": 1.728043492330593e-05,
      "loss": 0.0,
      "step": 14670
    },
    {
      "epoch": 0.9439907401453282,
      "grad_norm": 0.0004807966761291027,
      "learning_rate": 1.7086272733156428e-05,
      "loss": 0.0,
      "step": 14680
    },
    {
      "epoch": 0.9446337856086425,
      "grad_norm": 0.024167455732822418,
      "learning_rate": 1.6892110543006925e-05,
      "loss": 0.0,
      "step": 14690
    },
    {
      "epoch": 0.9452768310719568,
      "grad_norm": 0.00033855976653285325,
      "learning_rate": 1.669794835285742e-05,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 0.9459198765352711,
      "grad_norm": 0.0004719873541034758,
      "learning_rate": 1.6503786162707915e-05,
      "loss": 0.0,
      "step": 14710
    },
    {
      "epoch": 0.9465629219985853,
      "grad_norm": 0.0014553762739524245,
      "learning_rate": 1.630962397255841e-05,
      "loss": 0.0,
      "step": 14720
    },
    {
      "epoch": 0.9472059674618996,
      "grad_norm": 0.00018718447245191783,
      "learning_rate": 1.6115461782408906e-05,
      "loss": 0.0,
      "step": 14730
    },
    {
      "epoch": 0.9478490129252138,
      "grad_norm": 0.0003216617333237082,
      "learning_rate": 1.59212995922594e-05,
      "loss": 0.0,
      "step": 14740
    },
    {
      "epoch": 0.948492058388528,
      "grad_norm": 0.001431209733709693,
      "learning_rate": 1.5727137402109896e-05,
      "loss": 0.0,
      "step": 14750
    },
    {
      "epoch": 0.9491351038518423,
      "grad_norm": 0.0024011177010834217,
      "learning_rate": 1.553297521196039e-05,
      "loss": 0.0,
      "step": 14760
    },
    {
      "epoch": 0.9497781493151566,
      "grad_norm": 0.0010134091135114431,
      "learning_rate": 1.5338813021810883e-05,
      "loss": 0.0,
      "step": 14770
    },
    {
      "epoch": 0.9504211947784709,
      "grad_norm": 0.0007195535581558943,
      "learning_rate": 1.514465083166138e-05,
      "loss": 0.0,
      "step": 14780
    },
    {
      "epoch": 0.951064240241785,
      "grad_norm": 0.0011501243570819497,
      "learning_rate": 1.4950488641511876e-05,
      "loss": 0.0,
      "step": 14790
    },
    {
      "epoch": 0.9517072857050993,
      "grad_norm": 0.0003437205159571022,
      "learning_rate": 1.475632645136237e-05,
      "loss": 0.0,
      "step": 14800
    },
    {
      "epoch": 0.9523503311684136,
      "grad_norm": 0.0010330997174605727,
      "learning_rate": 1.4562164261212866e-05,
      "loss": 0.0,
      "step": 14810
    },
    {
      "epoch": 0.9529933766317279,
      "grad_norm": 0.0003559403994586319,
      "learning_rate": 1.436800207106336e-05,
      "loss": 0.0,
      "step": 14820
    },
    {
      "epoch": 0.9536364220950421,
      "grad_norm": 0.0012692258460447192,
      "learning_rate": 1.4173839880913857e-05,
      "loss": 0.0,
      "step": 14830
    },
    {
      "epoch": 0.9542794675583564,
      "grad_norm": 0.0007251736242324114,
      "learning_rate": 1.397967769076435e-05,
      "loss": 0.0,
      "step": 14840
    },
    {
      "epoch": 0.9549225130216706,
      "grad_norm": 0.0006037934217602015,
      "learning_rate": 1.3785515500614845e-05,
      "loss": 0.0,
      "step": 14850
    },
    {
      "epoch": 0.9555655584849849,
      "grad_norm": 0.00056268903426826,
      "learning_rate": 1.3591353310465342e-05,
      "loss": 0.0,
      "step": 14860
    },
    {
      "epoch": 0.9562086039482991,
      "grad_norm": 0.0009304818813689053,
      "learning_rate": 1.3397191120315836e-05,
      "loss": 0.0,
      "step": 14870
    },
    {
      "epoch": 0.9568516494116134,
      "grad_norm": 0.0015450386563315988,
      "learning_rate": 1.320302893016633e-05,
      "loss": 0.0,
      "step": 14880
    },
    {
      "epoch": 0.9574946948749277,
      "grad_norm": 0.0004304956819396466,
      "learning_rate": 1.3008866740016826e-05,
      "loss": 0.0,
      "step": 14890
    },
    {
      "epoch": 0.958137740338242,
      "grad_norm": 0.0009446403128094971,
      "learning_rate": 1.2814704549867322e-05,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 0.9587807858015561,
      "grad_norm": 0.0011033975752070546,
      "learning_rate": 1.2620542359717817e-05,
      "loss": 0.0,
      "step": 14910
    },
    {
      "epoch": 0.9594238312648704,
      "grad_norm": 0.0012853407533839345,
      "learning_rate": 1.2426380169568312e-05,
      "loss": 0.0,
      "step": 14920
    },
    {
      "epoch": 0.9600668767281847,
      "grad_norm": 0.0005791909643448889,
      "learning_rate": 1.2232217979418806e-05,
      "loss": 0.0,
      "step": 14930
    },
    {
      "epoch": 0.960709922191499,
      "grad_norm": 0.00028979324270039797,
      "learning_rate": 1.2038055789269303e-05,
      "loss": 0.0,
      "step": 14940
    },
    {
      "epoch": 0.9613529676548132,
      "grad_norm": 0.0009095023269765079,
      "learning_rate": 1.1843893599119796e-05,
      "loss": 0.0,
      "step": 14950
    },
    {
      "epoch": 0.9619960131181274,
      "grad_norm": 0.002051370218396187,
      "learning_rate": 1.1649731408970292e-05,
      "loss": 0.0,
      "step": 14960
    },
    {
      "epoch": 0.9626390585814417,
      "grad_norm": 0.0008702244376763701,
      "learning_rate": 1.1474985437835737e-05,
      "loss": 0.0107,
      "step": 14970
    },
    {
      "epoch": 0.963282104044756,
      "grad_norm": 0.0004343619802966714,
      "learning_rate": 1.1280823247686234e-05,
      "loss": 0.0,
      "step": 14980
    },
    {
      "epoch": 0.9639251495080702,
      "grad_norm": 0.00022454792633652687,
      "learning_rate": 1.1086661057536727e-05,
      "loss": 0.0,
      "step": 14990
    },
    {
      "epoch": 0.9645681949713845,
      "grad_norm": 0.00027624453650787473,
      "learning_rate": 1.0892498867387224e-05,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 0.9652112404346987,
      "grad_norm": 0.0011634856928139925,
      "learning_rate": 1.0698336677237718e-05,
      "loss": 0.0,
      "step": 15010
    },
    {
      "epoch": 0.965854285898013,
      "grad_norm": 0.0011542059946805239,
      "learning_rate": 1.0504174487088213e-05,
      "loss": 0.0,
      "step": 15020
    },
    {
      "epoch": 0.9664973313613272,
      "grad_norm": 0.0006811366765759885,
      "learning_rate": 1.031001229693871e-05,
      "loss": 0.0,
      "step": 15030
    },
    {
      "epoch": 0.9671403768246415,
      "grad_norm": 0.002376171527430415,
      "learning_rate": 1.0115850106789204e-05,
      "loss": 0.0,
      "step": 15040
    },
    {
      "epoch": 0.9677834222879558,
      "grad_norm": 0.0010878617176786065,
      "learning_rate": 9.921687916639697e-06,
      "loss": 0.0,
      "step": 15050
    },
    {
      "epoch": 0.9684264677512701,
      "grad_norm": 0.0001989854936255142,
      "learning_rate": 9.727525726490194e-06,
      "loss": 0.0,
      "step": 15060
    },
    {
      "epoch": 0.9690695132145842,
      "grad_norm": 0.0003761418629437685,
      "learning_rate": 9.53336353634069e-06,
      "loss": 0.0,
      "step": 15070
    },
    {
      "epoch": 0.9697125586778985,
      "grad_norm": 0.00024033499357756227,
      "learning_rate": 9.339201346191185e-06,
      "loss": 0.0,
      "step": 15080
    },
    {
      "epoch": 0.9703556041412128,
      "grad_norm": 0.0003267079882789403,
      "learning_rate": 9.14503915604168e-06,
      "loss": 0.0,
      "step": 15090
    },
    {
      "epoch": 0.9709986496045271,
      "grad_norm": 0.0009027307969518006,
      "learning_rate": 8.950876965892175e-06,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 0.9716416950678413,
      "grad_norm": 0.0003737019142135978,
      "learning_rate": 8.756714775742669e-06,
      "loss": 0.0,
      "step": 15110
    },
    {
      "epoch": 0.9722847405311555,
      "grad_norm": 0.00046257447684183717,
      "learning_rate": 8.562552585593164e-06,
      "loss": 0.0,
      "step": 15120
    },
    {
      "epoch": 0.9729277859944698,
      "grad_norm": 0.0006144405342638493,
      "learning_rate": 8.368390395443659e-06,
      "loss": 0.0,
      "step": 15130
    },
    {
      "epoch": 0.9735708314577841,
      "grad_norm": 0.0014591754879802465,
      "learning_rate": 8.174228205294156e-06,
      "loss": 0.0,
      "step": 15140
    },
    {
      "epoch": 0.9742138769210983,
      "grad_norm": 0.0003223379608243704,
      "learning_rate": 7.98006601514465e-06,
      "loss": 0.0,
      "step": 15150
    },
    {
      "epoch": 0.9748569223844126,
      "grad_norm": 0.0003165263042319566,
      "learning_rate": 7.785903824995145e-06,
      "loss": 0.0,
      "step": 15160
    },
    {
      "epoch": 0.9754999678477269,
      "grad_norm": 0.0012068584328517318,
      "learning_rate": 7.59174163484564e-06,
      "loss": 0.0,
      "step": 15170
    },
    {
      "epoch": 0.9761430133110411,
      "grad_norm": 6.997468153713271e-05,
      "learning_rate": 7.397579444696136e-06,
      "loss": 0.0,
      "step": 15180
    },
    {
      "epoch": 0.9767860587743553,
      "grad_norm": 0.002168722217902541,
      "learning_rate": 7.20341725454663e-06,
      "loss": 0.0124,
      "step": 15190
    },
    {
      "epoch": 0.9774291042376696,
      "grad_norm": 0.0014155469834804535,
      "learning_rate": 7.009255064397126e-06,
      "loss": 0.0,
      "step": 15200
    },
    {
      "epoch": 0.9780721497009839,
      "grad_norm": 0.00014815774920862168,
      "learning_rate": 6.815092874247621e-06,
      "loss": 0.0,
      "step": 15210
    },
    {
      "epoch": 0.9787151951642982,
      "grad_norm": 0.0004161920805927366,
      "learning_rate": 6.620930684098116e-06,
      "loss": 0.0,
      "step": 15220
    },
    {
      "epoch": 0.9793582406276123,
      "grad_norm": 0.00019330662325955927,
      "learning_rate": 6.426768493948611e-06,
      "loss": 0.0,
      "step": 15230
    },
    {
      "epoch": 0.9800012860909266,
      "grad_norm": 0.00045613013207912445,
      "learning_rate": 6.232606303799106e-06,
      "loss": 0.0,
      "step": 15240
    },
    {
      "epoch": 0.9806443315542409,
      "grad_norm": 0.00047418149188160896,
      "learning_rate": 6.038444113649601e-06,
      "loss": 0.0,
      "step": 15250
    },
    {
      "epoch": 0.9812873770175552,
      "grad_norm": 0.0003799763217102736,
      "learning_rate": 5.844281923500097e-06,
      "loss": 0.0,
      "step": 15260
    },
    {
      "epoch": 0.9819304224808694,
      "grad_norm": 0.0002478728711139411,
      "learning_rate": 5.650119733350591e-06,
      "loss": 0.0,
      "step": 15270
    },
    {
      "epoch": 0.9825734679441837,
      "grad_norm": 0.00047316981363110244,
      "learning_rate": 5.455957543201086e-06,
      "loss": 0.0,
      "step": 15280
    },
    {
      "epoch": 0.9832165134074979,
      "grad_norm": 0.0005913010099902749,
      "learning_rate": 5.261795353051582e-06,
      "loss": 0.0,
      "step": 15290
    },
    {
      "epoch": 0.9838595588708121,
      "grad_norm": 0.00043987840763293207,
      "learning_rate": 5.067633162902078e-06,
      "loss": 0.0,
      "step": 15300
    },
    {
      "epoch": 0.9845026043341264,
      "grad_norm": 0.0003107887750957161,
      "learning_rate": 4.873470972752573e-06,
      "loss": 0.0,
      "step": 15310
    },
    {
      "epoch": 0.9851456497974407,
      "grad_norm": 0.0009970032842829823,
      "learning_rate": 4.679308782603067e-06,
      "loss": 0.0,
      "step": 15320
    },
    {
      "epoch": 0.985788695260755,
      "grad_norm": 0.00022636374342255294,
      "learning_rate": 4.4851465924535625e-06,
      "loss": 0.0,
      "step": 15330
    },
    {
      "epoch": 0.9864317407240691,
      "grad_norm": 0.00020720408065244555,
      "learning_rate": 4.290984402304058e-06,
      "loss": 0.0,
      "step": 15340
    },
    {
      "epoch": 0.9870747861873834,
      "grad_norm": 0.0008331402204930782,
      "learning_rate": 4.096822212154553e-06,
      "loss": 0.0001,
      "step": 15350
    },
    {
      "epoch": 0.9877178316506977,
      "grad_norm": 0.00663942564278841,
      "learning_rate": 3.902660022005048e-06,
      "loss": 0.0,
      "step": 15360
    },
    {
      "epoch": 0.988360877114012,
      "grad_norm": 0.00012133036216255277,
      "learning_rate": 3.708497831855543e-06,
      "loss": 0.0,
      "step": 15370
    },
    {
      "epoch": 0.9890039225773262,
      "grad_norm": 0.00028599778306670487,
      "learning_rate": 3.5143356417060384e-06,
      "loss": 0.0,
      "step": 15380
    },
    {
      "epoch": 0.9896469680406405,
      "grad_norm": 0.0016473097493872046,
      "learning_rate": 3.320173451556533e-06,
      "loss": 0.0,
      "step": 15390
    },
    {
      "epoch": 0.9902900135039547,
      "grad_norm": 0.0004219982656650245,
      "learning_rate": 3.1260112614070284e-06,
      "loss": 0.0,
      "step": 15400
    },
    {
      "epoch": 0.990933058967269,
      "grad_norm": 0.0016209735767915845,
      "learning_rate": 2.9318490712575237e-06,
      "loss": 0.0,
      "step": 15410
    },
    {
      "epoch": 0.9915761044305832,
      "grad_norm": 0.021006407216191292,
      "learning_rate": 2.737686881108019e-06,
      "loss": 0.0,
      "step": 15420
    },
    {
      "epoch": 0.9922191498938975,
      "grad_norm": 0.0011212454410269856,
      "learning_rate": 2.5435246909585138e-06,
      "loss": 0.0,
      "step": 15430
    },
    {
      "epoch": 0.9928621953572118,
      "grad_norm": 0.00026682415045797825,
      "learning_rate": 2.349362500809009e-06,
      "loss": 0.0,
      "step": 15440
    },
    {
      "epoch": 0.993505240820526,
      "grad_norm": 0.00859220139682293,
      "learning_rate": 2.155200310659504e-06,
      "loss": 0.0,
      "step": 15450
    },
    {
      "epoch": 0.9941482862838402,
      "grad_norm": 0.00034318340476602316,
      "learning_rate": 1.961038120509999e-06,
      "loss": 0.0,
      "step": 15460
    },
    {
      "epoch": 0.9947913317471545,
      "grad_norm": 0.001190221169963479,
      "learning_rate": 1.7668759303604942e-06,
      "loss": 0.0,
      "step": 15470
    },
    {
      "epoch": 0.9954343772104688,
      "grad_norm": 0.0011749168625101447,
      "learning_rate": 1.5727137402109894e-06,
      "loss": 0.0,
      "step": 15480
    },
    {
      "epoch": 0.9960774226737831,
      "grad_norm": 0.0005856493371538818,
      "learning_rate": 1.3785515500614845e-06,
      "loss": 0.0,
      "step": 15490
    },
    {
      "epoch": 0.9967204681370972,
      "grad_norm": 0.0002734710869845003,
      "learning_rate": 1.1843893599119797e-06,
      "loss": 0.0,
      "step": 15500
    },
    {
      "epoch": 0.9973635136004115,
      "grad_norm": 7.709597412031144e-05,
      "learning_rate": 9.902271697624748e-07,
      "loss": 0.0,
      "step": 15510
    },
    {
      "epoch": 0.9980065590637258,
      "grad_norm": 0.001471454743295908,
      "learning_rate": 7.9606497961297e-07,
      "loss": 0.0,
      "step": 15520
    },
    {
      "epoch": 0.9986496045270401,
      "grad_norm": 0.0002675551804713905,
      "learning_rate": 6.019027894634652e-07,
      "loss": 0.0,
      "step": 15530
    },
    {
      "epoch": 0.9992926499903543,
      "grad_norm": 0.0005677523440681398,
      "learning_rate": 4.077405993139602e-07,
      "loss": 0.0,
      "step": 15540
    },
    {
      "epoch": 0.9999356954536686,
      "grad_norm": 0.0007514042081311345,
      "learning_rate": 2.1357840916445535e-07,
      "loss": 0.0,
      "step": 15550
    }
  ],
  "logging_steps": 10,
  "max_steps": 15551,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.89504638770217e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
