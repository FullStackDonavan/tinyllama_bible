{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7776,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001286008230452675,
      "grad_norm": 2.8241889476776123,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.3755,
      "step": 10
    },
    {
      "epoch": 0.00257201646090535,
      "grad_norm": 1.995219111442566,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.3171,
      "step": 20
    },
    {
      "epoch": 0.0038580246913580245,
      "grad_norm": 6.534790992736816,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.3541,
      "step": 30
    },
    {
      "epoch": 0.0051440329218107,
      "grad_norm": 1.9922451972961426,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.2357,
      "step": 40
    },
    {
      "epoch": 0.006430041152263375,
      "grad_norm": 2.0182669162750244,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.1796,
      "step": 50
    },
    {
      "epoch": 0.007716049382716049,
      "grad_norm": 0.5275962948799133,
      "learning_rate": 1.9979290706704636e-05,
      "loss": 0.0637,
      "step": 60
    },
    {
      "epoch": 0.009002057613168725,
      "grad_norm": 3.1107659339904785,
      "learning_rate": 1.9953404090085425e-05,
      "loss": 0.0289,
      "step": 70
    },
    {
      "epoch": 0.0102880658436214,
      "grad_norm": 1.20088791847229,
      "learning_rate": 1.9927517473466222e-05,
      "loss": 0.0242,
      "step": 80
    },
    {
      "epoch": 0.011574074074074073,
      "grad_norm": 2.2686355113983154,
      "learning_rate": 1.990163085684701e-05,
      "loss": 0.0249,
      "step": 90
    },
    {
      "epoch": 0.01286008230452675,
      "grad_norm": 1.0075855255126953,
      "learning_rate": 1.9875744240227804e-05,
      "loss": 0.0118,
      "step": 100
    },
    {
      "epoch": 0.014146090534979424,
      "grad_norm": 0.03686186298727989,
      "learning_rate": 1.9849857623608594e-05,
      "loss": 0.0069,
      "step": 110
    },
    {
      "epoch": 0.015432098765432098,
      "grad_norm": 0.12679412961006165,
      "learning_rate": 1.982397100698939e-05,
      "loss": 0.0047,
      "step": 120
    },
    {
      "epoch": 0.016718106995884774,
      "grad_norm": 0.05494442209601402,
      "learning_rate": 1.979808439037018e-05,
      "loss": 0.0039,
      "step": 130
    },
    {
      "epoch": 0.01800411522633745,
      "grad_norm": 0.17885908484458923,
      "learning_rate": 1.9772197773750972e-05,
      "loss": 0.0063,
      "step": 140
    },
    {
      "epoch": 0.019290123456790122,
      "grad_norm": 0.11457022279500961,
      "learning_rate": 1.9746311157131762e-05,
      "loss": 0.003,
      "step": 150
    },
    {
      "epoch": 0.0205761316872428,
      "grad_norm": 0.029476743191480637,
      "learning_rate": 1.9720424540512558e-05,
      "loss": 0.0059,
      "step": 160
    },
    {
      "epoch": 0.021862139917695474,
      "grad_norm": 0.654805064201355,
      "learning_rate": 1.9694537923893348e-05,
      "loss": 0.0079,
      "step": 170
    },
    {
      "epoch": 0.023148148148148147,
      "grad_norm": 0.03318110853433609,
      "learning_rate": 1.966865130727414e-05,
      "loss": 0.0029,
      "step": 180
    },
    {
      "epoch": 0.024434156378600823,
      "grad_norm": 0.5059823989868164,
      "learning_rate": 1.9642764690654933e-05,
      "loss": 0.0024,
      "step": 190
    },
    {
      "epoch": 0.0257201646090535,
      "grad_norm": 0.9083608388900757,
      "learning_rate": 1.9616878074035726e-05,
      "loss": 0.0164,
      "step": 200
    },
    {
      "epoch": 0.02700617283950617,
      "grad_norm": 0.0685613676905632,
      "learning_rate": 1.9590991457416516e-05,
      "loss": 0.0021,
      "step": 210
    },
    {
      "epoch": 0.028292181069958847,
      "grad_norm": 0.19142155349254608,
      "learning_rate": 1.956510484079731e-05,
      "loss": 0.0025,
      "step": 220
    },
    {
      "epoch": 0.029578189300411523,
      "grad_norm": 0.17562668025493622,
      "learning_rate": 1.95392182241781e-05,
      "loss": 0.0024,
      "step": 230
    },
    {
      "epoch": 0.030864197530864196,
      "grad_norm": 0.491508424282074,
      "learning_rate": 1.9513331607558894e-05,
      "loss": 0.0033,
      "step": 240
    },
    {
      "epoch": 0.03215020576131687,
      "grad_norm": 0.021444180980324745,
      "learning_rate": 1.9487444990939687e-05,
      "loss": 0.0028,
      "step": 250
    },
    {
      "epoch": 0.03343621399176955,
      "grad_norm": 0.06820228695869446,
      "learning_rate": 1.9461558374320477e-05,
      "loss": 0.0009,
      "step": 260
    },
    {
      "epoch": 0.034722222222222224,
      "grad_norm": 0.4946959316730499,
      "learning_rate": 1.943567175770127e-05,
      "loss": 0.0034,
      "step": 270
    },
    {
      "epoch": 0.0360082304526749,
      "grad_norm": 0.041516706347465515,
      "learning_rate": 1.9409785141082063e-05,
      "loss": 0.0022,
      "step": 280
    },
    {
      "epoch": 0.03729423868312757,
      "grad_norm": 0.02452404797077179,
      "learning_rate": 1.9383898524462855e-05,
      "loss": 0.0052,
      "step": 290
    },
    {
      "epoch": 0.038580246913580245,
      "grad_norm": 0.015263981185853481,
      "learning_rate": 1.9358011907843645e-05,
      "loss": 0.0013,
      "step": 300
    },
    {
      "epoch": 0.03986625514403292,
      "grad_norm": 2.082648515701294,
      "learning_rate": 1.9332125291224438e-05,
      "loss": 0.0024,
      "step": 310
    },
    {
      "epoch": 0.0411522633744856,
      "grad_norm": 0.06564851850271225,
      "learning_rate": 1.930623867460523e-05,
      "loss": 0.0023,
      "step": 320
    },
    {
      "epoch": 0.04243827160493827,
      "grad_norm": 2.9142415523529053,
      "learning_rate": 1.9280352057986024e-05,
      "loss": 0.0166,
      "step": 330
    },
    {
      "epoch": 0.04372427983539095,
      "grad_norm": 0.040859222412109375,
      "learning_rate": 1.9254465441366813e-05,
      "loss": 0.002,
      "step": 340
    },
    {
      "epoch": 0.045010288065843625,
      "grad_norm": 1.8259098529815674,
      "learning_rate": 1.922857882474761e-05,
      "loss": 0.0014,
      "step": 350
    },
    {
      "epoch": 0.046296296296296294,
      "grad_norm": 4.139556407928467,
      "learning_rate": 1.92026922081284e-05,
      "loss": 0.0095,
      "step": 360
    },
    {
      "epoch": 0.04758230452674897,
      "grad_norm": 0.023175613954663277,
      "learning_rate": 1.9176805591509192e-05,
      "loss": 0.0019,
      "step": 370
    },
    {
      "epoch": 0.048868312757201646,
      "grad_norm": 0.033154334872961044,
      "learning_rate": 1.915091897488998e-05,
      "loss": 0.0012,
      "step": 380
    },
    {
      "epoch": 0.05015432098765432,
      "grad_norm": 0.07590152323246002,
      "learning_rate": 1.9125032358270778e-05,
      "loss": 0.001,
      "step": 390
    },
    {
      "epoch": 0.051440329218107,
      "grad_norm": 0.04915453866124153,
      "learning_rate": 1.9099145741651567e-05,
      "loss": 0.0031,
      "step": 400
    },
    {
      "epoch": 0.052726337448559674,
      "grad_norm": 0.03681567683815956,
      "learning_rate": 1.907325912503236e-05,
      "loss": 0.0045,
      "step": 410
    },
    {
      "epoch": 0.05401234567901234,
      "grad_norm": 0.07229015231132507,
      "learning_rate": 1.9049961170075073e-05,
      "loss": 0.0051,
      "step": 420
    },
    {
      "epoch": 0.05529835390946502,
      "grad_norm": 0.014440062455832958,
      "learning_rate": 1.9024074553455863e-05,
      "loss": 0.0024,
      "step": 430
    },
    {
      "epoch": 0.056584362139917695,
      "grad_norm": 0.051165059208869934,
      "learning_rate": 1.8998187936836656e-05,
      "loss": 0.0081,
      "step": 440
    },
    {
      "epoch": 0.05787037037037037,
      "grad_norm": 0.08305805176496506,
      "learning_rate": 1.897230132021745e-05,
      "loss": 0.0008,
      "step": 450
    },
    {
      "epoch": 0.05915637860082305,
      "grad_norm": 0.044529471546411514,
      "learning_rate": 1.894641470359824e-05,
      "loss": 0.014,
      "step": 460
    },
    {
      "epoch": 0.06044238683127572,
      "grad_norm": 0.03773808479309082,
      "learning_rate": 1.8920528086979035e-05,
      "loss": 0.0015,
      "step": 470
    },
    {
      "epoch": 0.06172839506172839,
      "grad_norm": 0.03894053399562836,
      "learning_rate": 1.8894641470359824e-05,
      "loss": 0.003,
      "step": 480
    },
    {
      "epoch": 0.06301440329218107,
      "grad_norm": 0.10684599727392197,
      "learning_rate": 1.8868754853740617e-05,
      "loss": 0.0019,
      "step": 490
    },
    {
      "epoch": 0.06430041152263374,
      "grad_norm": 0.06726348400115967,
      "learning_rate": 1.884286823712141e-05,
      "loss": 0.0021,
      "step": 500
    },
    {
      "epoch": 0.06558641975308642,
      "grad_norm": 0.47746846079826355,
      "learning_rate": 1.8816981620502203e-05,
      "loss": 0.007,
      "step": 510
    },
    {
      "epoch": 0.0668724279835391,
      "grad_norm": 0.05075488239526749,
      "learning_rate": 1.8791095003882992e-05,
      "loss": 0.0007,
      "step": 520
    },
    {
      "epoch": 0.06815843621399177,
      "grad_norm": 0.017865771427750587,
      "learning_rate": 1.876520838726379e-05,
      "loss": 0.0007,
      "step": 530
    },
    {
      "epoch": 0.06944444444444445,
      "grad_norm": 0.04474996402859688,
      "learning_rate": 1.8739321770644578e-05,
      "loss": 0.001,
      "step": 540
    },
    {
      "epoch": 0.07073045267489712,
      "grad_norm": 0.02034052275121212,
      "learning_rate": 1.871343515402537e-05,
      "loss": 0.0029,
      "step": 550
    },
    {
      "epoch": 0.0720164609053498,
      "grad_norm": 0.013610988855361938,
      "learning_rate": 1.868754853740616e-05,
      "loss": 0.0004,
      "step": 560
    },
    {
      "epoch": 0.07330246913580248,
      "grad_norm": 0.03239923343062401,
      "learning_rate": 1.8661661920786957e-05,
      "loss": 0.0025,
      "step": 570
    },
    {
      "epoch": 0.07458847736625514,
      "grad_norm": 0.0525372289121151,
      "learning_rate": 1.8635775304167746e-05,
      "loss": 0.0013,
      "step": 580
    },
    {
      "epoch": 0.07587448559670781,
      "grad_norm": 0.009160849265754223,
      "learning_rate": 1.860988868754854e-05,
      "loss": 0.0007,
      "step": 590
    },
    {
      "epoch": 0.07716049382716049,
      "grad_norm": 9.250012397766113,
      "learning_rate": 1.858400207092933e-05,
      "loss": 0.0091,
      "step": 600
    },
    {
      "epoch": 0.07844650205761317,
      "grad_norm": 3.501796245574951,
      "learning_rate": 1.8558115454310125e-05,
      "loss": 0.0022,
      "step": 610
    },
    {
      "epoch": 0.07973251028806584,
      "grad_norm": 0.28841960430145264,
      "learning_rate": 1.8532228837690914e-05,
      "loss": 0.001,
      "step": 620
    },
    {
      "epoch": 0.08101851851851852,
      "grad_norm": 0.5229330062866211,
      "learning_rate": 1.8506342221071707e-05,
      "loss": 0.0029,
      "step": 630
    },
    {
      "epoch": 0.0823045267489712,
      "grad_norm": 0.5033537745475769,
      "learning_rate": 1.84804556044525e-05,
      "loss": 0.0087,
      "step": 640
    },
    {
      "epoch": 0.08359053497942387,
      "grad_norm": 0.02947104722261429,
      "learning_rate": 1.8454568987833293e-05,
      "loss": 0.0082,
      "step": 650
    },
    {
      "epoch": 0.08487654320987655,
      "grad_norm": 0.04155810549855232,
      "learning_rate": 1.8428682371214082e-05,
      "loss": 0.0005,
      "step": 660
    },
    {
      "epoch": 0.08616255144032922,
      "grad_norm": 0.14513497054576874,
      "learning_rate": 1.8402795754594875e-05,
      "loss": 0.005,
      "step": 670
    },
    {
      "epoch": 0.0874485596707819,
      "grad_norm": 0.024738673120737076,
      "learning_rate": 1.8376909137975668e-05,
      "loss": 0.0007,
      "step": 680
    },
    {
      "epoch": 0.08873456790123457,
      "grad_norm": 0.013203302398324013,
      "learning_rate": 1.835102252135646e-05,
      "loss": 0.0008,
      "step": 690
    },
    {
      "epoch": 0.09002057613168725,
      "grad_norm": 0.035671357065439224,
      "learning_rate": 1.8325135904737254e-05,
      "loss": 0.0008,
      "step": 700
    },
    {
      "epoch": 0.09130658436213991,
      "grad_norm": 1.7542517185211182,
      "learning_rate": 1.8299249288118043e-05,
      "loss": 0.0014,
      "step": 710
    },
    {
      "epoch": 0.09259259259259259,
      "grad_norm": 0.0067239925265312195,
      "learning_rate": 1.8273362671498836e-05,
      "loss": 0.0006,
      "step": 720
    },
    {
      "epoch": 0.09387860082304526,
      "grad_norm": 0.009932032786309719,
      "learning_rate": 1.824747605487963e-05,
      "loss": 0.0021,
      "step": 730
    },
    {
      "epoch": 0.09516460905349794,
      "grad_norm": 0.025572096928954124,
      "learning_rate": 1.8221589438260422e-05,
      "loss": 0.0007,
      "step": 740
    },
    {
      "epoch": 0.09645061728395062,
      "grad_norm": 0.021635862067341805,
      "learning_rate": 1.819570282164121e-05,
      "loss": 0.0013,
      "step": 750
    },
    {
      "epoch": 0.09773662551440329,
      "grad_norm": 0.006453149951994419,
      "learning_rate": 1.8169816205022005e-05,
      "loss": 0.0007,
      "step": 760
    },
    {
      "epoch": 0.09902263374485597,
      "grad_norm": 0.09834152460098267,
      "learning_rate": 1.8143929588402797e-05,
      "loss": 0.0007,
      "step": 770
    },
    {
      "epoch": 0.10030864197530864,
      "grad_norm": 0.005574420560151339,
      "learning_rate": 1.811804297178359e-05,
      "loss": 0.0006,
      "step": 780
    },
    {
      "epoch": 0.10159465020576132,
      "grad_norm": 0.1446549892425537,
      "learning_rate": 1.809215635516438e-05,
      "loss": 0.0005,
      "step": 790
    },
    {
      "epoch": 0.102880658436214,
      "grad_norm": 0.007559837307780981,
      "learning_rate": 1.8066269738545176e-05,
      "loss": 0.0006,
      "step": 800
    },
    {
      "epoch": 0.10416666666666667,
      "grad_norm": 0.013866521418094635,
      "learning_rate": 1.8040383121925966e-05,
      "loss": 0.0079,
      "step": 810
    },
    {
      "epoch": 0.10545267489711935,
      "grad_norm": 0.5996298789978027,
      "learning_rate": 1.801449650530676e-05,
      "loss": 0.0008,
      "step": 820
    },
    {
      "epoch": 0.10673868312757202,
      "grad_norm": 0.07180358469486237,
      "learning_rate": 1.7988609888687548e-05,
      "loss": 0.0007,
      "step": 830
    },
    {
      "epoch": 0.10802469135802469,
      "grad_norm": 0.32114145159721375,
      "learning_rate": 1.7962723272068344e-05,
      "loss": 0.0012,
      "step": 840
    },
    {
      "epoch": 0.10931069958847736,
      "grad_norm": 0.1633060723543167,
      "learning_rate": 1.7936836655449134e-05,
      "loss": 0.0005,
      "step": 850
    },
    {
      "epoch": 0.11059670781893004,
      "grad_norm": 0.03517277538776398,
      "learning_rate": 1.7910950038829927e-05,
      "loss": 0.0004,
      "step": 860
    },
    {
      "epoch": 0.11188271604938271,
      "grad_norm": 0.22026173770427704,
      "learning_rate": 1.7885063422210716e-05,
      "loss": 0.0006,
      "step": 870
    },
    {
      "epoch": 0.11316872427983539,
      "grad_norm": 0.00809743907302618,
      "learning_rate": 1.7859176805591512e-05,
      "loss": 0.0006,
      "step": 880
    },
    {
      "epoch": 0.11445473251028807,
      "grad_norm": 0.012302571907639503,
      "learning_rate": 1.7833290188972302e-05,
      "loss": 0.0004,
      "step": 890
    },
    {
      "epoch": 0.11574074074074074,
      "grad_norm": 0.010035421699285507,
      "learning_rate": 1.7807403572353095e-05,
      "loss": 0.0013,
      "step": 900
    },
    {
      "epoch": 0.11702674897119342,
      "grad_norm": 0.08545147627592087,
      "learning_rate": 1.7781516955733888e-05,
      "loss": 0.0007,
      "step": 910
    },
    {
      "epoch": 0.1183127572016461,
      "grad_norm": 0.6321840882301331,
      "learning_rate": 1.775563033911468e-05,
      "loss": 0.0008,
      "step": 920
    },
    {
      "epoch": 0.11959876543209877,
      "grad_norm": 0.002407100750133395,
      "learning_rate": 1.772974372249547e-05,
      "loss": 0.0005,
      "step": 930
    },
    {
      "epoch": 0.12088477366255145,
      "grad_norm": 0.005813314113765955,
      "learning_rate": 1.7703857105876263e-05,
      "loss": 0.0004,
      "step": 940
    },
    {
      "epoch": 0.12217078189300412,
      "grad_norm": 0.33162757754325867,
      "learning_rate": 1.7677970489257056e-05,
      "loss": 0.0034,
      "step": 950
    },
    {
      "epoch": 0.12345679012345678,
      "grad_norm": 0.010317258536815643,
      "learning_rate": 1.765208387263785e-05,
      "loss": 0.0004,
      "step": 960
    },
    {
      "epoch": 0.12474279835390946,
      "grad_norm": 0.12624813616275787,
      "learning_rate": 1.762619725601864e-05,
      "loss": 0.0006,
      "step": 970
    },
    {
      "epoch": 0.12602880658436214,
      "grad_norm": 0.005827741231769323,
      "learning_rate": 1.760031063939943e-05,
      "loss": 0.0015,
      "step": 980
    },
    {
      "epoch": 0.12731481481481483,
      "grad_norm": 0.00580379506573081,
      "learning_rate": 1.7574424022780224e-05,
      "loss": 0.0008,
      "step": 990
    },
    {
      "epoch": 0.1286008230452675,
      "grad_norm": 0.005833849776536226,
      "learning_rate": 1.7548537406161017e-05,
      "loss": 0.0008,
      "step": 1000
    },
    {
      "epoch": 0.12988683127572018,
      "grad_norm": 0.22152191400527954,
      "learning_rate": 1.752265078954181e-05,
      "loss": 0.0018,
      "step": 1010
    },
    {
      "epoch": 0.13117283950617284,
      "grad_norm": 0.027321819216012955,
      "learning_rate": 1.74967641729226e-05,
      "loss": 0.0005,
      "step": 1020
    },
    {
      "epoch": 0.1324588477366255,
      "grad_norm": 0.07533461600542068,
      "learning_rate": 1.7470877556303392e-05,
      "loss": 0.0012,
      "step": 1030
    },
    {
      "epoch": 0.1337448559670782,
      "grad_norm": 0.01805019937455654,
      "learning_rate": 1.7444990939684185e-05,
      "loss": 0.0005,
      "step": 1040
    },
    {
      "epoch": 0.13503086419753085,
      "grad_norm": 0.021173639222979546,
      "learning_rate": 1.7419104323064978e-05,
      "loss": 0.0013,
      "step": 1050
    },
    {
      "epoch": 0.13631687242798354,
      "grad_norm": 0.2316560447216034,
      "learning_rate": 1.7393217706445767e-05,
      "loss": 0.0011,
      "step": 1060
    },
    {
      "epoch": 0.1376028806584362,
      "grad_norm": 0.03353199362754822,
      "learning_rate": 1.736733108982656e-05,
      "loss": 0.0026,
      "step": 1070
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 0.0034249259624630213,
      "learning_rate": 1.7341444473207353e-05,
      "loss": 0.0121,
      "step": 1080
    },
    {
      "epoch": 0.14017489711934156,
      "grad_norm": 2.0878729820251465,
      "learning_rate": 1.7315557856588146e-05,
      "loss": 0.0054,
      "step": 1090
    },
    {
      "epoch": 0.14146090534979425,
      "grad_norm": 0.01671804115176201,
      "learning_rate": 1.7289671239968936e-05,
      "loss": 0.0004,
      "step": 1100
    },
    {
      "epoch": 0.1427469135802469,
      "grad_norm": 0.02899187058210373,
      "learning_rate": 1.726378462334973e-05,
      "loss": 0.0005,
      "step": 1110
    },
    {
      "epoch": 0.1440329218106996,
      "grad_norm": 5.958176612854004,
      "learning_rate": 1.723789800673052e-05,
      "loss": 0.0028,
      "step": 1120
    },
    {
      "epoch": 0.14531893004115226,
      "grad_norm": 0.012594031170010567,
      "learning_rate": 1.7212011390111314e-05,
      "loss": 0.0003,
      "step": 1130
    },
    {
      "epoch": 0.14660493827160495,
      "grad_norm": 0.5856702327728271,
      "learning_rate": 1.7186124773492107e-05,
      "loss": 0.0012,
      "step": 1140
    },
    {
      "epoch": 0.1478909465020576,
      "grad_norm": 0.03656510263681412,
      "learning_rate": 1.7160238156872897e-05,
      "loss": 0.0004,
      "step": 1150
    },
    {
      "epoch": 0.14917695473251028,
      "grad_norm": 0.01810039021074772,
      "learning_rate": 1.713435154025369e-05,
      "loss": 0.0005,
      "step": 1160
    },
    {
      "epoch": 0.15046296296296297,
      "grad_norm": 0.029902908951044083,
      "learning_rate": 1.7108464923634482e-05,
      "loss": 0.0007,
      "step": 1170
    },
    {
      "epoch": 0.15174897119341563,
      "grad_norm": 0.04915241897106171,
      "learning_rate": 1.7082578307015275e-05,
      "loss": 0.0003,
      "step": 1180
    },
    {
      "epoch": 0.15303497942386832,
      "grad_norm": 0.00845555029809475,
      "learning_rate": 1.7056691690396065e-05,
      "loss": 0.0009,
      "step": 1190
    },
    {
      "epoch": 0.15432098765432098,
      "grad_norm": 0.018069950863718987,
      "learning_rate": 1.7030805073776858e-05,
      "loss": 0.0006,
      "step": 1200
    },
    {
      "epoch": 0.15560699588477367,
      "grad_norm": 0.005187836941331625,
      "learning_rate": 1.700491845715765e-05,
      "loss": 0.0004,
      "step": 1210
    },
    {
      "epoch": 0.15689300411522633,
      "grad_norm": 0.007601161487400532,
      "learning_rate": 1.6979031840538443e-05,
      "loss": 0.0004,
      "step": 1220
    },
    {
      "epoch": 0.15817901234567902,
      "grad_norm": 0.01687069982290268,
      "learning_rate": 1.6953145223919236e-05,
      "loss": 0.0025,
      "step": 1230
    },
    {
      "epoch": 0.15946502057613168,
      "grad_norm": 0.018648209050297737,
      "learning_rate": 1.692725860730003e-05,
      "loss": 0.0004,
      "step": 1240
    },
    {
      "epoch": 0.16075102880658437,
      "grad_norm": 0.0075149391777813435,
      "learning_rate": 1.690137199068082e-05,
      "loss": 0.0003,
      "step": 1250
    },
    {
      "epoch": 0.16203703703703703,
      "grad_norm": 0.007288591470569372,
      "learning_rate": 1.687548537406161e-05,
      "loss": 0.0007,
      "step": 1260
    },
    {
      "epoch": 0.16332304526748972,
      "grad_norm": 0.0036832401528954506,
      "learning_rate": 1.6849598757442405e-05,
      "loss": 0.0004,
      "step": 1270
    },
    {
      "epoch": 0.1646090534979424,
      "grad_norm": 0.004324021749198437,
      "learning_rate": 1.6823712140823197e-05,
      "loss": 0.0003,
      "step": 1280
    },
    {
      "epoch": 0.16589506172839505,
      "grad_norm": 0.004745665937662125,
      "learning_rate": 1.6797825524203987e-05,
      "loss": 0.0004,
      "step": 1290
    },
    {
      "epoch": 0.16718106995884774,
      "grad_norm": 0.029108423739671707,
      "learning_rate": 1.677193890758478e-05,
      "loss": 0.0003,
      "step": 1300
    },
    {
      "epoch": 0.1684670781893004,
      "grad_norm": 0.006162194535136223,
      "learning_rate": 1.6746052290965573e-05,
      "loss": 0.0003,
      "step": 1310
    },
    {
      "epoch": 0.1697530864197531,
      "grad_norm": 0.0021418598480522633,
      "learning_rate": 1.6720165674346366e-05,
      "loss": 0.0046,
      "step": 1320
    },
    {
      "epoch": 0.17103909465020575,
      "grad_norm": 0.002693336922675371,
      "learning_rate": 1.6694279057727155e-05,
      "loss": 0.0003,
      "step": 1330
    },
    {
      "epoch": 0.17232510288065844,
      "grad_norm": 0.0024755659978836775,
      "learning_rate": 1.6668392441107948e-05,
      "loss": 0.0003,
      "step": 1340
    },
    {
      "epoch": 0.1736111111111111,
      "grad_norm": 0.048722196370363235,
      "learning_rate": 1.664250582448874e-05,
      "loss": 0.0003,
      "step": 1350
    },
    {
      "epoch": 0.1748971193415638,
      "grad_norm": 0.10411235690116882,
      "learning_rate": 1.6616619207869534e-05,
      "loss": 0.0004,
      "step": 1360
    },
    {
      "epoch": 0.17618312757201646,
      "grad_norm": 0.0051464359275996685,
      "learning_rate": 1.6590732591250323e-05,
      "loss": 0.0007,
      "step": 1370
    },
    {
      "epoch": 0.17746913580246915,
      "grad_norm": 0.012125639244914055,
      "learning_rate": 1.6564845974631116e-05,
      "loss": 0.0003,
      "step": 1380
    },
    {
      "epoch": 0.1787551440329218,
      "grad_norm": 0.0059714969247579575,
      "learning_rate": 1.653895935801191e-05,
      "loss": 0.0003,
      "step": 1390
    },
    {
      "epoch": 0.1800411522633745,
      "grad_norm": 0.0635431632399559,
      "learning_rate": 1.6513072741392702e-05,
      "loss": 0.0003,
      "step": 1400
    },
    {
      "epoch": 0.18132716049382716,
      "grad_norm": 0.04083487018942833,
      "learning_rate": 1.6487186124773495e-05,
      "loss": 0.0003,
      "step": 1410
    },
    {
      "epoch": 0.18261316872427982,
      "grad_norm": 0.018695343285799026,
      "learning_rate": 1.6461299508154284e-05,
      "loss": 0.0004,
      "step": 1420
    },
    {
      "epoch": 0.1838991769547325,
      "grad_norm": 0.0023892875760793686,
      "learning_rate": 1.6435412891535077e-05,
      "loss": 0.0003,
      "step": 1430
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.08789891749620438,
      "learning_rate": 1.640952627491587e-05,
      "loss": 0.0004,
      "step": 1440
    },
    {
      "epoch": 0.18647119341563786,
      "grad_norm": 0.006560328416526318,
      "learning_rate": 1.6383639658296663e-05,
      "loss": 0.001,
      "step": 1450
    },
    {
      "epoch": 0.18775720164609053,
      "grad_norm": 0.005645970348268747,
      "learning_rate": 1.6357753041677452e-05,
      "loss": 0.0006,
      "step": 1460
    },
    {
      "epoch": 0.18904320987654322,
      "grad_norm": 0.021844957023859024,
      "learning_rate": 1.633186642505825e-05,
      "loss": 0.0002,
      "step": 1470
    },
    {
      "epoch": 0.19032921810699588,
      "grad_norm": 0.013465337455272675,
      "learning_rate": 1.6305979808439038e-05,
      "loss": 0.0002,
      "step": 1480
    },
    {
      "epoch": 0.19161522633744857,
      "grad_norm": 0.013624273240566254,
      "learning_rate": 1.628009319181983e-05,
      "loss": 0.0003,
      "step": 1490
    },
    {
      "epoch": 0.19290123456790123,
      "grad_norm": 0.011503764428198338,
      "learning_rate": 1.625420657520062e-05,
      "loss": 0.0004,
      "step": 1500
    },
    {
      "epoch": 0.19418724279835392,
      "grad_norm": 0.03228166326880455,
      "learning_rate": 1.6228319958581417e-05,
      "loss": 0.0004,
      "step": 1510
    },
    {
      "epoch": 0.19547325102880658,
      "grad_norm": 0.028112540021538734,
      "learning_rate": 1.6202433341962206e-05,
      "loss": 0.0029,
      "step": 1520
    },
    {
      "epoch": 0.19675925925925927,
      "grad_norm": 0.07571243494749069,
      "learning_rate": 1.6176546725343e-05,
      "loss": 0.0008,
      "step": 1530
    },
    {
      "epoch": 0.19804526748971193,
      "grad_norm": 0.010189180262386799,
      "learning_rate": 1.615066010872379e-05,
      "loss": 0.0002,
      "step": 1540
    },
    {
      "epoch": 0.1993312757201646,
      "grad_norm": 0.01354430615901947,
      "learning_rate": 1.6124773492104585e-05,
      "loss": 0.0002,
      "step": 1550
    },
    {
      "epoch": 0.2006172839506173,
      "grad_norm": 0.00444028852507472,
      "learning_rate": 1.6098886875485375e-05,
      "loss": 0.0002,
      "step": 1560
    },
    {
      "epoch": 0.20190329218106995,
      "grad_norm": 0.11989294737577438,
      "learning_rate": 1.6073000258866167e-05,
      "loss": 0.0003,
      "step": 1570
    },
    {
      "epoch": 0.20318930041152264,
      "grad_norm": 0.0030372582841664553,
      "learning_rate": 1.604711364224696e-05,
      "loss": 0.0056,
      "step": 1580
    },
    {
      "epoch": 0.2044753086419753,
      "grad_norm": 0.0054763914085924625,
      "learning_rate": 1.6021227025627753e-05,
      "loss": 0.0003,
      "step": 1590
    },
    {
      "epoch": 0.205761316872428,
      "grad_norm": 0.0038155450019985437,
      "learning_rate": 1.5995340409008543e-05,
      "loss": 0.0006,
      "step": 1600
    },
    {
      "epoch": 0.20704732510288065,
      "grad_norm": 0.01680488884449005,
      "learning_rate": 1.5969453792389336e-05,
      "loss": 0.0002,
      "step": 1610
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 0.03297477215528488,
      "learning_rate": 1.594356717577013e-05,
      "loss": 0.0003,
      "step": 1620
    },
    {
      "epoch": 0.209619341563786,
      "grad_norm": 0.033002424985170364,
      "learning_rate": 1.591768055915092e-05,
      "loss": 0.0033,
      "step": 1630
    },
    {
      "epoch": 0.2109053497942387,
      "grad_norm": 0.014904025010764599,
      "learning_rate": 1.589179394253171e-05,
      "loss": 0.0002,
      "step": 1640
    },
    {
      "epoch": 0.21219135802469136,
      "grad_norm": 2.789062023162842,
      "learning_rate": 1.5865907325912504e-05,
      "loss": 0.0031,
      "step": 1650
    },
    {
      "epoch": 0.21347736625514405,
      "grad_norm": 0.006749952677637339,
      "learning_rate": 1.5840020709293297e-05,
      "loss": 0.0015,
      "step": 1660
    },
    {
      "epoch": 0.2147633744855967,
      "grad_norm": 0.026447540149092674,
      "learning_rate": 1.581413409267409e-05,
      "loss": 0.0004,
      "step": 1670
    },
    {
      "epoch": 0.21604938271604937,
      "grad_norm": 0.004199475049972534,
      "learning_rate": 1.5788247476054882e-05,
      "loss": 0.0003,
      "step": 1680
    },
    {
      "epoch": 0.21733539094650206,
      "grad_norm": 0.017208503559231758,
      "learning_rate": 1.5762360859435672e-05,
      "loss": 0.0004,
      "step": 1690
    },
    {
      "epoch": 0.21862139917695472,
      "grad_norm": 0.013588565401732922,
      "learning_rate": 1.5736474242816465e-05,
      "loss": 0.0003,
      "step": 1700
    },
    {
      "epoch": 0.2199074074074074,
      "grad_norm": 0.003981903661042452,
      "learning_rate": 1.5710587626197258e-05,
      "loss": 0.0002,
      "step": 1710
    },
    {
      "epoch": 0.22119341563786007,
      "grad_norm": 0.00686329510062933,
      "learning_rate": 1.568470100957805e-05,
      "loss": 0.0006,
      "step": 1720
    },
    {
      "epoch": 0.22247942386831276,
      "grad_norm": 0.009704211726784706,
      "learning_rate": 1.565881439295884e-05,
      "loss": 0.0006,
      "step": 1730
    },
    {
      "epoch": 0.22376543209876543,
      "grad_norm": 0.017174888402223587,
      "learning_rate": 1.5632927776339636e-05,
      "loss": 0.0002,
      "step": 1740
    },
    {
      "epoch": 0.22505144032921812,
      "grad_norm": 0.0037774373777210712,
      "learning_rate": 1.5607041159720426e-05,
      "loss": 0.0005,
      "step": 1750
    },
    {
      "epoch": 0.22633744855967078,
      "grad_norm": 0.015127899125218391,
      "learning_rate": 1.558115454310122e-05,
      "loss": 0.0002,
      "step": 1760
    },
    {
      "epoch": 0.22762345679012347,
      "grad_norm": 0.0022702564019709826,
      "learning_rate": 1.5555267926482008e-05,
      "loss": 0.0003,
      "step": 1770
    },
    {
      "epoch": 0.22890946502057613,
      "grad_norm": 0.024958666414022446,
      "learning_rate": 1.5529381309862804e-05,
      "loss": 0.0002,
      "step": 1780
    },
    {
      "epoch": 0.23019547325102882,
      "grad_norm": 0.021651122719049454,
      "learning_rate": 1.5503494693243594e-05,
      "loss": 0.004,
      "step": 1790
    },
    {
      "epoch": 0.23148148148148148,
      "grad_norm": 0.00966478418558836,
      "learning_rate": 1.5477608076624387e-05,
      "loss": 0.0004,
      "step": 1800
    },
    {
      "epoch": 0.23276748971193414,
      "grad_norm": 0.007701236288994551,
      "learning_rate": 1.5451721460005176e-05,
      "loss": 0.001,
      "step": 1810
    },
    {
      "epoch": 0.23405349794238683,
      "grad_norm": 0.46474236249923706,
      "learning_rate": 1.5425834843385973e-05,
      "loss": 0.0006,
      "step": 1820
    },
    {
      "epoch": 0.2353395061728395,
      "grad_norm": 0.022491060197353363,
      "learning_rate": 1.5399948226766762e-05,
      "loss": 0.0002,
      "step": 1830
    },
    {
      "epoch": 0.2366255144032922,
      "grad_norm": 0.004457518924027681,
      "learning_rate": 1.5374061610147555e-05,
      "loss": 0.0001,
      "step": 1840
    },
    {
      "epoch": 0.23791152263374485,
      "grad_norm": 0.03174513205885887,
      "learning_rate": 1.5348174993528348e-05,
      "loss": 0.0002,
      "step": 1850
    },
    {
      "epoch": 0.23919753086419754,
      "grad_norm": 0.008294301107525826,
      "learning_rate": 1.532228837690914e-05,
      "loss": 0.0013,
      "step": 1860
    },
    {
      "epoch": 0.2404835390946502,
      "grad_norm": 0.08314786106348038,
      "learning_rate": 1.529640176028993e-05,
      "loss": 0.0003,
      "step": 1870
    },
    {
      "epoch": 0.2417695473251029,
      "grad_norm": 0.003059303155168891,
      "learning_rate": 1.5270515143670723e-05,
      "loss": 0.0003,
      "step": 1880
    },
    {
      "epoch": 0.24305555555555555,
      "grad_norm": 0.010307340882718563,
      "learning_rate": 1.5244628527051514e-05,
      "loss": 0.0024,
      "step": 1890
    },
    {
      "epoch": 0.24434156378600824,
      "grad_norm": 0.01300770789384842,
      "learning_rate": 1.5218741910432309e-05,
      "loss": 0.0003,
      "step": 1900
    },
    {
      "epoch": 0.2456275720164609,
      "grad_norm": 0.013395089656114578,
      "learning_rate": 1.51928552938131e-05,
      "loss": 0.0006,
      "step": 1910
    },
    {
      "epoch": 0.24691358024691357,
      "grad_norm": 0.006929834373295307,
      "learning_rate": 1.5166968677193891e-05,
      "loss": 0.0002,
      "step": 1920
    },
    {
      "epoch": 0.24819958847736626,
      "grad_norm": 0.002993897069245577,
      "learning_rate": 1.5141082060574683e-05,
      "loss": 0.0004,
      "step": 1930
    },
    {
      "epoch": 0.24948559670781892,
      "grad_norm": 0.013384846039116383,
      "learning_rate": 1.5115195443955477e-05,
      "loss": 0.001,
      "step": 1940
    },
    {
      "epoch": 0.2507716049382716,
      "grad_norm": 0.015069877728819847,
      "learning_rate": 1.5089308827336268e-05,
      "loss": 0.0003,
      "step": 1950
    },
    {
      "epoch": 0.25205761316872427,
      "grad_norm": 0.002307063667103648,
      "learning_rate": 1.506342221071706e-05,
      "loss": 0.0002,
      "step": 1960
    },
    {
      "epoch": 0.25334362139917693,
      "grad_norm": 0.014769896864891052,
      "learning_rate": 1.5037535594097852e-05,
      "loss": 0.0006,
      "step": 1970
    },
    {
      "epoch": 0.25462962962962965,
      "grad_norm": 0.008958869613707066,
      "learning_rate": 1.5011648977478645e-05,
      "loss": 0.0002,
      "step": 1980
    },
    {
      "epoch": 0.2559156378600823,
      "grad_norm": 4.4970173835754395,
      "learning_rate": 1.4985762360859436e-05,
      "loss": 0.0023,
      "step": 1990
    },
    {
      "epoch": 0.257201646090535,
      "grad_norm": 0.006462501361966133,
      "learning_rate": 1.495987574424023e-05,
      "loss": 0.0002,
      "step": 2000
    },
    {
      "epoch": 0.25848765432098764,
      "grad_norm": 0.13849622011184692,
      "learning_rate": 1.493398912762102e-05,
      "loss": 0.0006,
      "step": 2010
    },
    {
      "epoch": 0.25977366255144035,
      "grad_norm": 0.05833177641034126,
      "learning_rate": 1.4908102511001813e-05,
      "loss": 0.0016,
      "step": 2020
    },
    {
      "epoch": 0.261059670781893,
      "grad_norm": 0.007260804995894432,
      "learning_rate": 1.4882215894382606e-05,
      "loss": 0.0002,
      "step": 2030
    },
    {
      "epoch": 0.2623456790123457,
      "grad_norm": 0.01105191744863987,
      "learning_rate": 1.4856329277763398e-05,
      "loss": 0.0003,
      "step": 2040
    },
    {
      "epoch": 0.26363168724279834,
      "grad_norm": 0.4821562170982361,
      "learning_rate": 1.4830442661144189e-05,
      "loss": 0.0004,
      "step": 2050
    },
    {
      "epoch": 0.264917695473251,
      "grad_norm": 0.007556474301964045,
      "learning_rate": 1.4804556044524983e-05,
      "loss": 0.0002,
      "step": 2060
    },
    {
      "epoch": 0.2662037037037037,
      "grad_norm": 0.009185340255498886,
      "learning_rate": 1.4778669427905774e-05,
      "loss": 0.0002,
      "step": 2070
    },
    {
      "epoch": 0.2674897119341564,
      "grad_norm": 0.005269467830657959,
      "learning_rate": 1.4752782811286566e-05,
      "loss": 0.0002,
      "step": 2080
    },
    {
      "epoch": 0.26877572016460904,
      "grad_norm": 0.003319025272503495,
      "learning_rate": 1.4726896194667357e-05,
      "loss": 0.0001,
      "step": 2090
    },
    {
      "epoch": 0.2700617283950617,
      "grad_norm": 0.001934068975970149,
      "learning_rate": 1.4701009578048151e-05,
      "loss": 0.0044,
      "step": 2100
    },
    {
      "epoch": 0.2713477366255144,
      "grad_norm": 0.011595238000154495,
      "learning_rate": 1.4675122961428943e-05,
      "loss": 0.0002,
      "step": 2110
    },
    {
      "epoch": 0.2726337448559671,
      "grad_norm": 0.0042834896594285965,
      "learning_rate": 1.4649236344809734e-05,
      "loss": 0.0005,
      "step": 2120
    },
    {
      "epoch": 0.27391975308641975,
      "grad_norm": 0.001413092017173767,
      "learning_rate": 1.4623349728190525e-05,
      "loss": 0.0001,
      "step": 2130
    },
    {
      "epoch": 0.2752057613168724,
      "grad_norm": 0.0031807038467377424,
      "learning_rate": 1.459746311157132e-05,
      "loss": 0.0002,
      "step": 2140
    },
    {
      "epoch": 0.27649176954732513,
      "grad_norm": 0.008233258500695229,
      "learning_rate": 1.457157649495211e-05,
      "loss": 0.0001,
      "step": 2150
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 0.028814444318413734,
      "learning_rate": 1.4545689878332902e-05,
      "loss": 0.0002,
      "step": 2160
    },
    {
      "epoch": 0.27906378600823045,
      "grad_norm": 0.016220763325691223,
      "learning_rate": 1.4519803261713695e-05,
      "loss": 0.0002,
      "step": 2170
    },
    {
      "epoch": 0.2803497942386831,
      "grad_norm": 0.048291005194187164,
      "learning_rate": 1.4493916645094488e-05,
      "loss": 0.0001,
      "step": 2180
    },
    {
      "epoch": 0.2816358024691358,
      "grad_norm": 0.02208450809121132,
      "learning_rate": 1.4468030028475279e-05,
      "loss": 0.0008,
      "step": 2190
    },
    {
      "epoch": 0.2829218106995885,
      "grad_norm": 0.005151178687810898,
      "learning_rate": 1.4442143411856072e-05,
      "loss": 0.0046,
      "step": 2200
    },
    {
      "epoch": 0.28420781893004116,
      "grad_norm": 0.008582638576626778,
      "learning_rate": 1.4416256795236863e-05,
      "loss": 0.0015,
      "step": 2210
    },
    {
      "epoch": 0.2854938271604938,
      "grad_norm": 6.161271572113037,
      "learning_rate": 1.4392958840279577e-05,
      "loss": 0.0077,
      "step": 2220
    },
    {
      "epoch": 0.2867798353909465,
      "grad_norm": 0.0034473473206162453,
      "learning_rate": 1.4367072223660368e-05,
      "loss": 0.0011,
      "step": 2230
    },
    {
      "epoch": 0.2880658436213992,
      "grad_norm": 0.002061111619696021,
      "learning_rate": 1.434118560704116e-05,
      "loss": 0.0004,
      "step": 2240
    },
    {
      "epoch": 0.28935185185185186,
      "grad_norm": 0.02903497964143753,
      "learning_rate": 1.4315298990421954e-05,
      "loss": 0.0002,
      "step": 2250
    },
    {
      "epoch": 0.2906378600823045,
      "grad_norm": 0.010171102359890938,
      "learning_rate": 1.4289412373802745e-05,
      "loss": 0.0001,
      "step": 2260
    },
    {
      "epoch": 0.2919238683127572,
      "grad_norm": 0.002345239743590355,
      "learning_rate": 1.4263525757183538e-05,
      "loss": 0.0001,
      "step": 2270
    },
    {
      "epoch": 0.2932098765432099,
      "grad_norm": 0.0056466213427484035,
      "learning_rate": 1.423763914056433e-05,
      "loss": 0.0002,
      "step": 2280
    },
    {
      "epoch": 0.29449588477366256,
      "grad_norm": 0.001895365072414279,
      "learning_rate": 1.4211752523945122e-05,
      "loss": 0.0002,
      "step": 2290
    },
    {
      "epoch": 0.2957818930041152,
      "grad_norm": 0.0031834731344133615,
      "learning_rate": 1.4185865907325913e-05,
      "loss": 0.0002,
      "step": 2300
    },
    {
      "epoch": 0.2970679012345679,
      "grad_norm": 0.07902386784553528,
      "learning_rate": 1.4159979290706708e-05,
      "loss": 0.0003,
      "step": 2310
    },
    {
      "epoch": 0.29835390946502055,
      "grad_norm": 0.0023226765915751457,
      "learning_rate": 1.4134092674087499e-05,
      "loss": 0.0042,
      "step": 2320
    },
    {
      "epoch": 0.29963991769547327,
      "grad_norm": 0.013002325780689716,
      "learning_rate": 1.410820605746829e-05,
      "loss": 0.0002,
      "step": 2330
    },
    {
      "epoch": 0.30092592592592593,
      "grad_norm": 0.0049904948100447655,
      "learning_rate": 1.4082319440849081e-05,
      "loss": 0.002,
      "step": 2340
    },
    {
      "epoch": 0.3022119341563786,
      "grad_norm": 0.014395059086382389,
      "learning_rate": 1.4056432824229876e-05,
      "loss": 0.0002,
      "step": 2350
    },
    {
      "epoch": 0.30349794238683125,
      "grad_norm": 0.011691811494529247,
      "learning_rate": 1.4030546207610667e-05,
      "loss": 0.0002,
      "step": 2360
    },
    {
      "epoch": 0.30478395061728397,
      "grad_norm": 0.004487456753849983,
      "learning_rate": 1.4004659590991458e-05,
      "loss": 0.0003,
      "step": 2370
    },
    {
      "epoch": 0.30606995884773663,
      "grad_norm": 0.022054996341466904,
      "learning_rate": 1.397877297437225e-05,
      "loss": 0.0002,
      "step": 2380
    },
    {
      "epoch": 0.3073559670781893,
      "grad_norm": 0.00384191214106977,
      "learning_rate": 1.3952886357753044e-05,
      "loss": 0.0006,
      "step": 2390
    },
    {
      "epoch": 0.30864197530864196,
      "grad_norm": 0.007318391930311918,
      "learning_rate": 1.3926999741133835e-05,
      "loss": 0.0002,
      "step": 2400
    },
    {
      "epoch": 0.3099279835390947,
      "grad_norm": 0.01499517634510994,
      "learning_rate": 1.3901113124514626e-05,
      "loss": 0.0002,
      "step": 2410
    },
    {
      "epoch": 0.31121399176954734,
      "grad_norm": 0.005330075044184923,
      "learning_rate": 1.3875226507895419e-05,
      "loss": 0.0001,
      "step": 2420
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.0171794630587101,
      "learning_rate": 1.3849339891276212e-05,
      "loss": 0.0001,
      "step": 2430
    },
    {
      "epoch": 0.31378600823045266,
      "grad_norm": 0.004555178340524435,
      "learning_rate": 1.3823453274657003e-05,
      "loss": 0.0002,
      "step": 2440
    },
    {
      "epoch": 0.3150720164609053,
      "grad_norm": 0.02234659157693386,
      "learning_rate": 1.3797566658037796e-05,
      "loss": 0.0002,
      "step": 2450
    },
    {
      "epoch": 0.31635802469135804,
      "grad_norm": 0.003751201555132866,
      "learning_rate": 1.3771680041418587e-05,
      "loss": 0.0002,
      "step": 2460
    },
    {
      "epoch": 0.3176440329218107,
      "grad_norm": 0.002197541296482086,
      "learning_rate": 1.374579342479938e-05,
      "loss": 0.0001,
      "step": 2470
    },
    {
      "epoch": 0.31893004115226337,
      "grad_norm": 0.0028906483203172684,
      "learning_rate": 1.3719906808180173e-05,
      "loss": 0.005,
      "step": 2480
    },
    {
      "epoch": 0.32021604938271603,
      "grad_norm": 0.010643011890351772,
      "learning_rate": 1.3694020191560964e-05,
      "loss": 0.0002,
      "step": 2490
    },
    {
      "epoch": 0.32150205761316875,
      "grad_norm": 0.3746863901615143,
      "learning_rate": 1.3668133574941755e-05,
      "loss": 0.0002,
      "step": 2500
    },
    {
      "epoch": 0.3227880658436214,
      "grad_norm": 0.006350196897983551,
      "learning_rate": 1.364224695832255e-05,
      "loss": 0.0003,
      "step": 2510
    },
    {
      "epoch": 0.32407407407407407,
      "grad_norm": 0.010075053200125694,
      "learning_rate": 1.3616360341703341e-05,
      "loss": 0.0001,
      "step": 2520
    },
    {
      "epoch": 0.32536008230452673,
      "grad_norm": 0.00211609760299325,
      "learning_rate": 1.3590473725084132e-05,
      "loss": 0.0001,
      "step": 2530
    },
    {
      "epoch": 0.32664609053497945,
      "grad_norm": 0.030098019167780876,
      "learning_rate": 1.3564587108464924e-05,
      "loss": 0.0007,
      "step": 2540
    },
    {
      "epoch": 0.3279320987654321,
      "grad_norm": 0.015603299252688885,
      "learning_rate": 1.3538700491845718e-05,
      "loss": 0.0002,
      "step": 2550
    },
    {
      "epoch": 0.3292181069958848,
      "grad_norm": 0.004938019439578056,
      "learning_rate": 1.351281387522651e-05,
      "loss": 0.001,
      "step": 2560
    },
    {
      "epoch": 0.33050411522633744,
      "grad_norm": 0.014423523098230362,
      "learning_rate": 1.34869272586073e-05,
      "loss": 0.0001,
      "step": 2570
    },
    {
      "epoch": 0.3317901234567901,
      "grad_norm": 0.010145632550120354,
      "learning_rate": 1.3461040641988092e-05,
      "loss": 0.0002,
      "step": 2580
    },
    {
      "epoch": 0.3330761316872428,
      "grad_norm": 0.016762226819992065,
      "learning_rate": 1.3435154025368886e-05,
      "loss": 0.0002,
      "step": 2590
    },
    {
      "epoch": 0.3343621399176955,
      "grad_norm": 0.0027637574821710587,
      "learning_rate": 1.3409267408749678e-05,
      "loss": 0.0002,
      "step": 2600
    },
    {
      "epoch": 0.33564814814814814,
      "grad_norm": 0.0033985415939241648,
      "learning_rate": 1.3383380792130469e-05,
      "loss": 0.0001,
      "step": 2610
    },
    {
      "epoch": 0.3369341563786008,
      "grad_norm": 0.005832142196595669,
      "learning_rate": 1.3357494175511262e-05,
      "loss": 0.0002,
      "step": 2620
    },
    {
      "epoch": 0.3382201646090535,
      "grad_norm": 0.0030646345112472773,
      "learning_rate": 1.3331607558892055e-05,
      "loss": 0.0004,
      "step": 2630
    },
    {
      "epoch": 0.3395061728395062,
      "grad_norm": 0.008392298594117165,
      "learning_rate": 1.3305720942272846e-05,
      "loss": 0.0001,
      "step": 2640
    },
    {
      "epoch": 0.34079218106995884,
      "grad_norm": 0.00224258447997272,
      "learning_rate": 1.3279834325653637e-05,
      "loss": 0.0001,
      "step": 2650
    },
    {
      "epoch": 0.3420781893004115,
      "grad_norm": 0.019151056185364723,
      "learning_rate": 1.325394770903443e-05,
      "loss": 0.0002,
      "step": 2660
    },
    {
      "epoch": 0.3433641975308642,
      "grad_norm": 0.0036297799088060856,
      "learning_rate": 1.3228061092415223e-05,
      "loss": 0.0002,
      "step": 2670
    },
    {
      "epoch": 0.3446502057613169,
      "grad_norm": 0.0024732323363423347,
      "learning_rate": 1.3202174475796014e-05,
      "loss": 0.0001,
      "step": 2680
    },
    {
      "epoch": 0.34593621399176955,
      "grad_norm": 0.0037586044054478407,
      "learning_rate": 1.3176287859176807e-05,
      "loss": 0.0001,
      "step": 2690
    },
    {
      "epoch": 0.3472222222222222,
      "grad_norm": 0.035130154341459274,
      "learning_rate": 1.3150401242557598e-05,
      "loss": 0.0001,
      "step": 2700
    },
    {
      "epoch": 0.34850823045267487,
      "grad_norm": 0.009915199130773544,
      "learning_rate": 1.312451462593839e-05,
      "loss": 0.0001,
      "step": 2710
    },
    {
      "epoch": 0.3497942386831276,
      "grad_norm": 0.006018963176757097,
      "learning_rate": 1.3098628009319184e-05,
      "loss": 0.0002,
      "step": 2720
    },
    {
      "epoch": 0.35108024691358025,
      "grad_norm": 0.032761815935373306,
      "learning_rate": 1.3072741392699975e-05,
      "loss": 0.0002,
      "step": 2730
    },
    {
      "epoch": 0.3523662551440329,
      "grad_norm": 0.019818885251879692,
      "learning_rate": 1.3046854776080766e-05,
      "loss": 0.0003,
      "step": 2740
    },
    {
      "epoch": 0.3536522633744856,
      "grad_norm": 0.0013882964849472046,
      "learning_rate": 1.302096815946156e-05,
      "loss": 0.0002,
      "step": 2750
    },
    {
      "epoch": 0.3549382716049383,
      "grad_norm": 0.0037138687912374735,
      "learning_rate": 1.2995081542842352e-05,
      "loss": 0.0001,
      "step": 2760
    },
    {
      "epoch": 0.35622427983539096,
      "grad_norm": 0.03463253751397133,
      "learning_rate": 1.2969194926223143e-05,
      "loss": 0.0001,
      "step": 2770
    },
    {
      "epoch": 0.3575102880658436,
      "grad_norm": 0.015865812078118324,
      "learning_rate": 1.2943308309603938e-05,
      "loss": 0.0001,
      "step": 2780
    },
    {
      "epoch": 0.3587962962962963,
      "grad_norm": 0.013896582648158073,
      "learning_rate": 1.2917421692984729e-05,
      "loss": 0.0002,
      "step": 2790
    },
    {
      "epoch": 0.360082304526749,
      "grad_norm": 0.014241690747439861,
      "learning_rate": 1.289153507636552e-05,
      "loss": 0.0002,
      "step": 2800
    },
    {
      "epoch": 0.36136831275720166,
      "grad_norm": 0.11556340008974075,
      "learning_rate": 1.2865648459746311e-05,
      "loss": 0.0002,
      "step": 2810
    },
    {
      "epoch": 0.3626543209876543,
      "grad_norm": 0.003532905364409089,
      "learning_rate": 1.2839761843127106e-05,
      "loss": 0.0003,
      "step": 2820
    },
    {
      "epoch": 0.363940329218107,
      "grad_norm": 0.04147477075457573,
      "learning_rate": 1.2813875226507897e-05,
      "loss": 0.0001,
      "step": 2830
    },
    {
      "epoch": 0.36522633744855965,
      "grad_norm": 0.004739861935377121,
      "learning_rate": 1.2787988609888688e-05,
      "loss": 0.001,
      "step": 2840
    },
    {
      "epoch": 0.36651234567901236,
      "grad_norm": 0.11241577565670013,
      "learning_rate": 1.276210199326948e-05,
      "loss": 0.0002,
      "step": 2850
    },
    {
      "epoch": 0.367798353909465,
      "grad_norm": 0.028302542865276337,
      "learning_rate": 1.2736215376650274e-05,
      "loss": 0.0003,
      "step": 2860
    },
    {
      "epoch": 0.3690843621399177,
      "grad_norm": 0.004340034443885088,
      "learning_rate": 1.2710328760031065e-05,
      "loss": 0.0002,
      "step": 2870
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.042596105486154556,
      "learning_rate": 1.2684442143411856e-05,
      "loss": 0.0001,
      "step": 2880
    },
    {
      "epoch": 0.37165637860082307,
      "grad_norm": 0.00807223655283451,
      "learning_rate": 1.265855552679265e-05,
      "loss": 0.0002,
      "step": 2890
    },
    {
      "epoch": 0.37294238683127573,
      "grad_norm": 0.001974786864593625,
      "learning_rate": 1.2632668910173442e-05,
      "loss": 0.003,
      "step": 2900
    },
    {
      "epoch": 0.3742283950617284,
      "grad_norm": 0.020527340471744537,
      "learning_rate": 1.2606782293554233e-05,
      "loss": 0.0002,
      "step": 2910
    },
    {
      "epoch": 0.37551440329218105,
      "grad_norm": 0.004164820536971092,
      "learning_rate": 1.2580895676935026e-05,
      "loss": 0.0002,
      "step": 2920
    },
    {
      "epoch": 0.37680041152263377,
      "grad_norm": 0.0021591316908597946,
      "learning_rate": 1.2555009060315817e-05,
      "loss": 0.0002,
      "step": 2930
    },
    {
      "epoch": 0.37808641975308643,
      "grad_norm": 0.0030783608090132475,
      "learning_rate": 1.252912244369661e-05,
      "loss": 0.0002,
      "step": 2940
    },
    {
      "epoch": 0.3793724279835391,
      "grad_norm": 0.0017969806212931871,
      "learning_rate": 1.2503235827077403e-05,
      "loss": 0.0004,
      "step": 2950
    },
    {
      "epoch": 0.38065843621399176,
      "grad_norm": 0.019970698282122612,
      "learning_rate": 1.2477349210458194e-05,
      "loss": 0.0002,
      "step": 2960
    },
    {
      "epoch": 0.3819444444444444,
      "grad_norm": 0.0035734795965254307,
      "learning_rate": 1.2451462593838986e-05,
      "loss": 0.0001,
      "step": 2970
    },
    {
      "epoch": 0.38323045267489714,
      "grad_norm": 0.002970809116959572,
      "learning_rate": 1.2425575977219778e-05,
      "loss": 0.0011,
      "step": 2980
    },
    {
      "epoch": 0.3845164609053498,
      "grad_norm": 0.0062741441652178764,
      "learning_rate": 1.2399689360600571e-05,
      "loss": 0.0001,
      "step": 2990
    },
    {
      "epoch": 0.38580246913580246,
      "grad_norm": 0.0013475717278197408,
      "learning_rate": 1.2373802743981363e-05,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 0.3870884773662551,
      "grad_norm": 0.007026765029877424,
      "learning_rate": 1.2347916127362154e-05,
      "loss": 0.0002,
      "step": 3010
    },
    {
      "epoch": 0.38837448559670784,
      "grad_norm": 0.02138850837945938,
      "learning_rate": 1.2322029510742948e-05,
      "loss": 0.0011,
      "step": 3020
    },
    {
      "epoch": 0.3896604938271605,
      "grad_norm": 0.005801910534501076,
      "learning_rate": 1.229614289412374e-05,
      "loss": 0.0002,
      "step": 3030
    },
    {
      "epoch": 0.39094650205761317,
      "grad_norm": 0.0016161476960405707,
      "learning_rate": 1.227025627750453e-05,
      "loss": 0.0001,
      "step": 3040
    },
    {
      "epoch": 0.3922325102880658,
      "grad_norm": 0.04305792599916458,
      "learning_rate": 1.2244369660885322e-05,
      "loss": 0.0002,
      "step": 3050
    },
    {
      "epoch": 0.39351851851851855,
      "grad_norm": 0.0013270771596580744,
      "learning_rate": 1.2218483044266116e-05,
      "loss": 0.0001,
      "step": 3060
    },
    {
      "epoch": 0.3948045267489712,
      "grad_norm": 0.004585277754813433,
      "learning_rate": 1.2192596427646908e-05,
      "loss": 0.0002,
      "step": 3070
    },
    {
      "epoch": 0.39609053497942387,
      "grad_norm": 0.0011700957547873259,
      "learning_rate": 1.2166709811027699e-05,
      "loss": 0.0003,
      "step": 3080
    },
    {
      "epoch": 0.39737654320987653,
      "grad_norm": 0.004790731240063906,
      "learning_rate": 1.214082319440849e-05,
      "loss": 0.0001,
      "step": 3090
    },
    {
      "epoch": 0.3986625514403292,
      "grad_norm": 0.0041654473170638084,
      "learning_rate": 1.2114936577789285e-05,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 0.3999485596707819,
      "grad_norm": 0.05908507481217384,
      "learning_rate": 1.2089049961170076e-05,
      "loss": 0.0001,
      "step": 3110
    },
    {
      "epoch": 0.4012345679012346,
      "grad_norm": 0.0038430667482316494,
      "learning_rate": 1.2063163344550867e-05,
      "loss": 0.0002,
      "step": 3120
    },
    {
      "epoch": 0.40252057613168724,
      "grad_norm": 0.004478666000068188,
      "learning_rate": 1.203727672793166e-05,
      "loss": 0.0001,
      "step": 3130
    },
    {
      "epoch": 0.4038065843621399,
      "grad_norm": 0.018607109785079956,
      "learning_rate": 1.2011390111312453e-05,
      "loss": 0.0002,
      "step": 3140
    },
    {
      "epoch": 0.4050925925925926,
      "grad_norm": 2.65720534324646,
      "learning_rate": 1.1985503494693244e-05,
      "loss": 0.0068,
      "step": 3150
    },
    {
      "epoch": 0.4063786008230453,
      "grad_norm": 0.007778591476380825,
      "learning_rate": 1.1959616878074037e-05,
      "loss": 0.0002,
      "step": 3160
    },
    {
      "epoch": 0.40766460905349794,
      "grad_norm": 0.007081769872456789,
      "learning_rate": 1.1933730261454828e-05,
      "loss": 0.0002,
      "step": 3170
    },
    {
      "epoch": 0.4089506172839506,
      "grad_norm": 0.018165558576583862,
      "learning_rate": 1.1907843644835621e-05,
      "loss": 0.0001,
      "step": 3180
    },
    {
      "epoch": 0.4102366255144033,
      "grad_norm": 0.0025711674243211746,
      "learning_rate": 1.1881957028216414e-05,
      "loss": 0.0002,
      "step": 3190
    },
    {
      "epoch": 0.411522633744856,
      "grad_norm": 0.008673003874719143,
      "learning_rate": 1.1856070411597205e-05,
      "loss": 0.0001,
      "step": 3200
    },
    {
      "epoch": 0.41280864197530864,
      "grad_norm": 0.004619916435331106,
      "learning_rate": 1.1830183794977996e-05,
      "loss": 0.0008,
      "step": 3210
    },
    {
      "epoch": 0.4140946502057613,
      "grad_norm": 0.01887749880552292,
      "learning_rate": 1.180429717835879e-05,
      "loss": 0.0001,
      "step": 3220
    },
    {
      "epoch": 0.41538065843621397,
      "grad_norm": 0.0026155493687838316,
      "learning_rate": 1.1778410561739582e-05,
      "loss": 0.0001,
      "step": 3230
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 0.03773029148578644,
      "learning_rate": 1.1752523945120373e-05,
      "loss": 0.0001,
      "step": 3240
    },
    {
      "epoch": 0.41795267489711935,
      "grad_norm": 0.005376394372433424,
      "learning_rate": 1.1726637328501164e-05,
      "loss": 0.0003,
      "step": 3250
    },
    {
      "epoch": 0.419238683127572,
      "grad_norm": 0.04413533955812454,
      "learning_rate": 1.1700750711881959e-05,
      "loss": 0.0001,
      "step": 3260
    },
    {
      "epoch": 0.42052469135802467,
      "grad_norm": 0.006872081197798252,
      "learning_rate": 1.167486409526275e-05,
      "loss": 0.0001,
      "step": 3270
    },
    {
      "epoch": 0.4218106995884774,
      "grad_norm": 0.0013416475849226117,
      "learning_rate": 1.1648977478643541e-05,
      "loss": 0.0001,
      "step": 3280
    },
    {
      "epoch": 0.42309670781893005,
      "grad_norm": 0.044581182301044464,
      "learning_rate": 1.1623090862024336e-05,
      "loss": 0.0002,
      "step": 3290
    },
    {
      "epoch": 0.4243827160493827,
      "grad_norm": 0.008777022361755371,
      "learning_rate": 1.1597204245405127e-05,
      "loss": 0.0008,
      "step": 3300
    },
    {
      "epoch": 0.4256687242798354,
      "grad_norm": 0.006870721932500601,
      "learning_rate": 1.1571317628785918e-05,
      "loss": 0.0001,
      "step": 3310
    },
    {
      "epoch": 0.4269547325102881,
      "grad_norm": 0.02315070666372776,
      "learning_rate": 1.154543101216671e-05,
      "loss": 0.0002,
      "step": 3320
    },
    {
      "epoch": 0.42824074074074076,
      "grad_norm": 0.009316472336649895,
      "learning_rate": 1.1519544395547504e-05,
      "loss": 0.0001,
      "step": 3330
    },
    {
      "epoch": 0.4295267489711934,
      "grad_norm": 0.01442820392549038,
      "learning_rate": 1.1493657778928295e-05,
      "loss": 0.0001,
      "step": 3340
    },
    {
      "epoch": 0.4308127572016461,
      "grad_norm": 0.0014200543519109488,
      "learning_rate": 1.1467771162309086e-05,
      "loss": 0.0001,
      "step": 3350
    },
    {
      "epoch": 0.43209876543209874,
      "grad_norm": 0.003059349488466978,
      "learning_rate": 1.144188454568988e-05,
      "loss": 0.0001,
      "step": 3360
    },
    {
      "epoch": 0.43338477366255146,
      "grad_norm": 0.004119119606912136,
      "learning_rate": 1.1415997929070672e-05,
      "loss": 0.0002,
      "step": 3370
    },
    {
      "epoch": 0.4346707818930041,
      "grad_norm": 0.003885208163410425,
      "learning_rate": 1.1390111312451463e-05,
      "loss": 0.0001,
      "step": 3380
    },
    {
      "epoch": 0.4359567901234568,
      "grad_norm": 0.0037862372118979692,
      "learning_rate": 1.1364224695832256e-05,
      "loss": 0.0002,
      "step": 3390
    },
    {
      "epoch": 0.43724279835390945,
      "grad_norm": 0.0024381305556744337,
      "learning_rate": 1.1338338079213048e-05,
      "loss": 0.0001,
      "step": 3400
    },
    {
      "epoch": 0.43852880658436216,
      "grad_norm": 0.022797510027885437,
      "learning_rate": 1.131245146259384e-05,
      "loss": 0.0001,
      "step": 3410
    },
    {
      "epoch": 0.4398148148148148,
      "grad_norm": 0.0019880402833223343,
      "learning_rate": 1.1286564845974632e-05,
      "loss": 0.0008,
      "step": 3420
    },
    {
      "epoch": 0.4411008230452675,
      "grad_norm": 0.009416675195097923,
      "learning_rate": 1.1260678229355424e-05,
      "loss": 0.0001,
      "step": 3430
    },
    {
      "epoch": 0.44238683127572015,
      "grad_norm": 0.17607435584068298,
      "learning_rate": 1.1234791612736216e-05,
      "loss": 0.0006,
      "step": 3440
    },
    {
      "epoch": 0.44367283950617287,
      "grad_norm": 0.018977932631969452,
      "learning_rate": 1.1208904996117009e-05,
      "loss": 0.0029,
      "step": 3450
    },
    {
      "epoch": 0.44495884773662553,
      "grad_norm": 0.005082266870886087,
      "learning_rate": 1.1183018379497801e-05,
      "loss": 0.0002,
      "step": 3460
    },
    {
      "epoch": 0.4462448559670782,
      "grad_norm": 0.003054713597521186,
      "learning_rate": 1.1157131762878593e-05,
      "loss": 0.0002,
      "step": 3470
    },
    {
      "epoch": 0.44753086419753085,
      "grad_norm": 0.0032099157106131315,
      "learning_rate": 1.1131245146259384e-05,
      "loss": 0.0001,
      "step": 3480
    },
    {
      "epoch": 0.4488168724279835,
      "grad_norm": 0.05278422310948372,
      "learning_rate": 1.1105358529640178e-05,
      "loss": 0.0002,
      "step": 3490
    },
    {
      "epoch": 0.45010288065843623,
      "grad_norm": 0.00922368559986353,
      "learning_rate": 1.107947191302097e-05,
      "loss": 0.0003,
      "step": 3500
    },
    {
      "epoch": 0.4513888888888889,
      "grad_norm": 0.004235726315528154,
      "learning_rate": 1.105358529640176e-05,
      "loss": 0.0002,
      "step": 3510
    },
    {
      "epoch": 0.45267489711934156,
      "grad_norm": 0.002747223014011979,
      "learning_rate": 1.1027698679782552e-05,
      "loss": 0.0003,
      "step": 3520
    },
    {
      "epoch": 0.4539609053497942,
      "grad_norm": 0.0390220545232296,
      "learning_rate": 1.1001812063163347e-05,
      "loss": 0.0024,
      "step": 3530
    },
    {
      "epoch": 0.45524691358024694,
      "grad_norm": 0.003241554833948612,
      "learning_rate": 1.0975925446544138e-05,
      "loss": 0.0001,
      "step": 3540
    },
    {
      "epoch": 0.4565329218106996,
      "grad_norm": 0.040512777864933014,
      "learning_rate": 1.0950038829924929e-05,
      "loss": 0.0005,
      "step": 3550
    },
    {
      "epoch": 0.45781893004115226,
      "grad_norm": 0.027866961434483528,
      "learning_rate": 1.092415221330572e-05,
      "loss": 0.0005,
      "step": 3560
    },
    {
      "epoch": 0.4591049382716049,
      "grad_norm": 0.003794436575844884,
      "learning_rate": 1.0898265596686515e-05,
      "loss": 0.0001,
      "step": 3570
    },
    {
      "epoch": 0.46039094650205764,
      "grad_norm": 0.0009680523071438074,
      "learning_rate": 1.0872378980067306e-05,
      "loss": 0.0003,
      "step": 3580
    },
    {
      "epoch": 0.4616769547325103,
      "grad_norm": 0.004190468695014715,
      "learning_rate": 1.0846492363448097e-05,
      "loss": 0.0001,
      "step": 3590
    },
    {
      "epoch": 0.46296296296296297,
      "grad_norm": 0.0035843972582370043,
      "learning_rate": 1.082060574682889e-05,
      "loss": 0.0001,
      "step": 3600
    },
    {
      "epoch": 0.4642489711934156,
      "grad_norm": 0.001791327609680593,
      "learning_rate": 1.0794719130209683e-05,
      "loss": 0.0002,
      "step": 3610
    },
    {
      "epoch": 0.4655349794238683,
      "grad_norm": 0.007548035588115454,
      "learning_rate": 1.0768832513590474e-05,
      "loss": 0.0002,
      "step": 3620
    },
    {
      "epoch": 0.466820987654321,
      "grad_norm": 0.006500459276139736,
      "learning_rate": 1.0742945896971267e-05,
      "loss": 0.0001,
      "step": 3630
    },
    {
      "epoch": 0.46810699588477367,
      "grad_norm": 0.001175601384602487,
      "learning_rate": 1.0717059280352058e-05,
      "loss": 0.0001,
      "step": 3640
    },
    {
      "epoch": 0.46939300411522633,
      "grad_norm": 0.0038222370203584433,
      "learning_rate": 1.0691172663732851e-05,
      "loss": 0.0001,
      "step": 3650
    },
    {
      "epoch": 0.470679012345679,
      "grad_norm": 0.0016840915195643902,
      "learning_rate": 1.0665286047113644e-05,
      "loss": 0.0001,
      "step": 3660
    },
    {
      "epoch": 0.4719650205761317,
      "grad_norm": 0.006677842698991299,
      "learning_rate": 1.0639399430494435e-05,
      "loss": 0.0001,
      "step": 3670
    },
    {
      "epoch": 0.4732510288065844,
      "grad_norm": 0.0026607555337250233,
      "learning_rate": 1.0613512813875226e-05,
      "loss": 0.0001,
      "step": 3680
    },
    {
      "epoch": 0.47453703703703703,
      "grad_norm": 0.0034445668570697308,
      "learning_rate": 1.0587626197256021e-05,
      "loss": 0.0003,
      "step": 3690
    },
    {
      "epoch": 0.4758230452674897,
      "grad_norm": 0.014181433245539665,
      "learning_rate": 1.0561739580636812e-05,
      "loss": 0.0002,
      "step": 3700
    },
    {
      "epoch": 0.47710905349794236,
      "grad_norm": 0.003964184783399105,
      "learning_rate": 1.0535852964017603e-05,
      "loss": 0.0001,
      "step": 3710
    },
    {
      "epoch": 0.4783950617283951,
      "grad_norm": 0.005550231318920851,
      "learning_rate": 1.0509966347398394e-05,
      "loss": 0.0001,
      "step": 3720
    },
    {
      "epoch": 0.47968106995884774,
      "grad_norm": 0.008254710584878922,
      "learning_rate": 1.0484079730779189e-05,
      "loss": 0.0001,
      "step": 3730
    },
    {
      "epoch": 0.4809670781893004,
      "grad_norm": 0.0641302540898323,
      "learning_rate": 1.045819311415998e-05,
      "loss": 0.0002,
      "step": 3740
    },
    {
      "epoch": 0.48225308641975306,
      "grad_norm": 0.15722724795341492,
      "learning_rate": 1.0432306497540771e-05,
      "loss": 0.0002,
      "step": 3750
    },
    {
      "epoch": 0.4835390946502058,
      "grad_norm": 0.03840542957186699,
      "learning_rate": 1.0406419880921563e-05,
      "loss": 0.0001,
      "step": 3760
    },
    {
      "epoch": 0.48482510288065844,
      "grad_norm": 0.013328655622899532,
      "learning_rate": 1.0380533264302357e-05,
      "loss": 0.0001,
      "step": 3770
    },
    {
      "epoch": 0.4861111111111111,
      "grad_norm": 0.016422854736447334,
      "learning_rate": 1.0354646647683148e-05,
      "loss": 0.0001,
      "step": 3780
    },
    {
      "epoch": 0.48739711934156377,
      "grad_norm": 0.011485173366963863,
      "learning_rate": 1.032876003106394e-05,
      "loss": 0.0001,
      "step": 3790
    },
    {
      "epoch": 0.4886831275720165,
      "grad_norm": 0.003421095199882984,
      "learning_rate": 1.0302873414444734e-05,
      "loss": 0.0001,
      "step": 3800
    },
    {
      "epoch": 0.48996913580246915,
      "grad_norm": 0.0030348568689078093,
      "learning_rate": 1.0276986797825525e-05,
      "loss": 0.0001,
      "step": 3810
    },
    {
      "epoch": 0.4912551440329218,
      "grad_norm": 0.0023011709563434124,
      "learning_rate": 1.0251100181206317e-05,
      "loss": 0.0002,
      "step": 3820
    },
    {
      "epoch": 0.49254115226337447,
      "grad_norm": 0.0075191594660282135,
      "learning_rate": 1.022521356458711e-05,
      "loss": 0.0001,
      "step": 3830
    },
    {
      "epoch": 0.49382716049382713,
      "grad_norm": 0.00906088761985302,
      "learning_rate": 1.0199326947967902e-05,
      "loss": 0.0001,
      "step": 3840
    },
    {
      "epoch": 0.49511316872427985,
      "grad_norm": 0.0072850557044148445,
      "learning_rate": 1.0173440331348694e-05,
      "loss": 0.0001,
      "step": 3850
    },
    {
      "epoch": 0.4963991769547325,
      "grad_norm": 0.001068995101377368,
      "learning_rate": 1.0147553714729485e-05,
      "loss": 0.0001,
      "step": 3860
    },
    {
      "epoch": 0.4976851851851852,
      "grad_norm": 0.004740534350275993,
      "learning_rate": 1.0121667098110278e-05,
      "loss": 0.0005,
      "step": 3870
    },
    {
      "epoch": 0.49897119341563784,
      "grad_norm": 0.001735779456794262,
      "learning_rate": 1.009578048149107e-05,
      "loss": 0.0001,
      "step": 3880
    },
    {
      "epoch": 0.5002572016460906,
      "grad_norm": 0.0029333156999200583,
      "learning_rate": 1.0069893864871862e-05,
      "loss": 0.0001,
      "step": 3890
    },
    {
      "epoch": 0.5015432098765432,
      "grad_norm": 0.013047750107944012,
      "learning_rate": 1.0044007248252655e-05,
      "loss": 0.0001,
      "step": 3900
    },
    {
      "epoch": 0.5028292181069959,
      "grad_norm": 0.002745984122157097,
      "learning_rate": 1.0018120631633446e-05,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 0.5041152263374485,
      "grad_norm": 0.006791708059608936,
      "learning_rate": 9.992234015014239e-06,
      "loss": 0.0003,
      "step": 3920
    },
    {
      "epoch": 0.5054012345679012,
      "grad_norm": 0.00428038788959384,
      "learning_rate": 9.966347398395032e-06,
      "loss": 0.001,
      "step": 3930
    },
    {
      "epoch": 0.5066872427983539,
      "grad_norm": 0.0020255674608051777,
      "learning_rate": 9.940460781775823e-06,
      "loss": 0.0001,
      "step": 3940
    },
    {
      "epoch": 0.5079732510288066,
      "grad_norm": 0.004565336741507053,
      "learning_rate": 9.914574165156616e-06,
      "loss": 0.0001,
      "step": 3950
    },
    {
      "epoch": 0.5092592592592593,
      "grad_norm": 0.004899796098470688,
      "learning_rate": 9.888687548537407e-06,
      "loss": 0.0001,
      "step": 3960
    },
    {
      "epoch": 0.510545267489712,
      "grad_norm": 0.0015819823602214456,
      "learning_rate": 9.8628009319182e-06,
      "loss": 0.0001,
      "step": 3970
    },
    {
      "epoch": 0.5118312757201646,
      "grad_norm": 0.00922897458076477,
      "learning_rate": 9.836914315298991e-06,
      "loss": 0.0001,
      "step": 3980
    },
    {
      "epoch": 0.5131172839506173,
      "grad_norm": 0.0043044365011155605,
      "learning_rate": 9.811027698679784e-06,
      "loss": 0.0003,
      "step": 3990
    },
    {
      "epoch": 0.51440329218107,
      "grad_norm": 0.004225915763527155,
      "learning_rate": 9.785141082060575e-06,
      "loss": 0.0001,
      "step": 4000
    },
    {
      "epoch": 0.5156893004115226,
      "grad_norm": 0.023909129202365875,
      "learning_rate": 9.759254465441368e-06,
      "loss": 0.0008,
      "step": 4010
    },
    {
      "epoch": 0.5169753086419753,
      "grad_norm": 0.002555280225351453,
      "learning_rate": 9.733367848822159e-06,
      "loss": 0.0002,
      "step": 4020
    },
    {
      "epoch": 0.5182613168724279,
      "grad_norm": 0.002582462737336755,
      "learning_rate": 9.707481232202952e-06,
      "loss": 0.0001,
      "step": 4030
    },
    {
      "epoch": 0.5195473251028807,
      "grad_norm": 0.0025079466868191957,
      "learning_rate": 9.681594615583743e-06,
      "loss": 0.0001,
      "step": 4040
    },
    {
      "epoch": 0.5208333333333334,
      "grad_norm": 0.021751470863819122,
      "learning_rate": 9.655707998964536e-06,
      "loss": 0.0002,
      "step": 4050
    },
    {
      "epoch": 0.522119341563786,
      "grad_norm": 0.022997498512268066,
      "learning_rate": 9.629821382345327e-06,
      "loss": 0.0001,
      "step": 4060
    },
    {
      "epoch": 0.5234053497942387,
      "grad_norm": 0.004662327002733946,
      "learning_rate": 9.60393476572612e-06,
      "loss": 0.0014,
      "step": 4070
    },
    {
      "epoch": 0.5246913580246914,
      "grad_norm": 0.006775532383471727,
      "learning_rate": 9.578048149106911e-06,
      "loss": 0.0002,
      "step": 4080
    },
    {
      "epoch": 0.525977366255144,
      "grad_norm": 0.0016417147126048803,
      "learning_rate": 9.552161532487704e-06,
      "loss": 0.0001,
      "step": 4090
    },
    {
      "epoch": 0.5272633744855967,
      "grad_norm": 0.008640996180474758,
      "learning_rate": 9.526274915868497e-06,
      "loss": 0.0001,
      "step": 4100
    },
    {
      "epoch": 0.5285493827160493,
      "grad_norm": 0.0021184864453971386,
      "learning_rate": 9.500388299249288e-06,
      "loss": 0.0001,
      "step": 4110
    },
    {
      "epoch": 0.529835390946502,
      "grad_norm": 0.0019352282397449017,
      "learning_rate": 9.474501682630081e-06,
      "loss": 0.0001,
      "step": 4120
    },
    {
      "epoch": 0.5311213991769548,
      "grad_norm": 0.0025233381893485785,
      "learning_rate": 9.448615066010874e-06,
      "loss": 0.0001,
      "step": 4130
    },
    {
      "epoch": 0.5324074074074074,
      "grad_norm": 0.0025411536917090416,
      "learning_rate": 9.422728449391665e-06,
      "loss": 0.0001,
      "step": 4140
    },
    {
      "epoch": 0.5336934156378601,
      "grad_norm": 0.0018451986834406853,
      "learning_rate": 9.396841832772458e-06,
      "loss": 0.0001,
      "step": 4150
    },
    {
      "epoch": 0.5349794238683128,
      "grad_norm": 0.001192645519040525,
      "learning_rate": 9.37095521615325e-06,
      "loss": 0.0001,
      "step": 4160
    },
    {
      "epoch": 0.5362654320987654,
      "grad_norm": 0.006312128156423569,
      "learning_rate": 9.345068599534042e-06,
      "loss": 0.0001,
      "step": 4170
    },
    {
      "epoch": 0.5375514403292181,
      "grad_norm": 0.011574684642255306,
      "learning_rate": 9.319181982914833e-06,
      "loss": 0.0001,
      "step": 4180
    },
    {
      "epoch": 0.5388374485596708,
      "grad_norm": 0.0026240830775350332,
      "learning_rate": 9.293295366295626e-06,
      "loss": 0.0001,
      "step": 4190
    },
    {
      "epoch": 0.5401234567901234,
      "grad_norm": 0.03856286779046059,
      "learning_rate": 9.267408749676417e-06,
      "loss": 0.0003,
      "step": 4200
    },
    {
      "epoch": 0.5414094650205762,
      "grad_norm": 0.014449034817516804,
      "learning_rate": 9.24152213305721e-06,
      "loss": 0.0001,
      "step": 4210
    },
    {
      "epoch": 0.5426954732510288,
      "grad_norm": 0.0041498346254229546,
      "learning_rate": 9.215635516438002e-06,
      "loss": 0.0002,
      "step": 4220
    },
    {
      "epoch": 0.5439814814814815,
      "grad_norm": 0.03622683510184288,
      "learning_rate": 9.189748899818794e-06,
      "loss": 0.0001,
      "step": 4230
    },
    {
      "epoch": 0.5452674897119342,
      "grad_norm": 0.00600934773683548,
      "learning_rate": 9.163862283199586e-06,
      "loss": 0.0003,
      "step": 4240
    },
    {
      "epoch": 0.5465534979423868,
      "grad_norm": 0.0015307130524888635,
      "learning_rate": 9.137975666580379e-06,
      "loss": 0.0001,
      "step": 4250
    },
    {
      "epoch": 0.5478395061728395,
      "grad_norm": 0.00272597698494792,
      "learning_rate": 9.11208904996117e-06,
      "loss": 0.0018,
      "step": 4260
    },
    {
      "epoch": 0.5491255144032922,
      "grad_norm": 0.0037988433614373207,
      "learning_rate": 9.086202433341963e-06,
      "loss": 0.0001,
      "step": 4270
    },
    {
      "epoch": 0.5504115226337448,
      "grad_norm": 0.003345542587339878,
      "learning_rate": 9.060315816722756e-06,
      "loss": 0.0001,
      "step": 4280
    },
    {
      "epoch": 0.5516975308641975,
      "grad_norm": 0.00316438777372241,
      "learning_rate": 9.034429200103547e-06,
      "loss": 0.0001,
      "step": 4290
    },
    {
      "epoch": 0.5529835390946503,
      "grad_norm": 0.0025263074785470963,
      "learning_rate": 9.00854258348434e-06,
      "loss": 0.0001,
      "step": 4300
    },
    {
      "epoch": 0.5542695473251029,
      "grad_norm": 0.004750947467982769,
      "learning_rate": 8.98265596686513e-06,
      "loss": 0.0001,
      "step": 4310
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.0060514165088534355,
      "learning_rate": 8.956769350245924e-06,
      "loss": 0.0002,
      "step": 4320
    },
    {
      "epoch": 0.5568415637860082,
      "grad_norm": 0.0033327192068099976,
      "learning_rate": 8.930882733626715e-06,
      "loss": 0.0001,
      "step": 4330
    },
    {
      "epoch": 0.5581275720164609,
      "grad_norm": 0.0023744613863527775,
      "learning_rate": 8.904996117007508e-06,
      "loss": 0.0001,
      "step": 4340
    },
    {
      "epoch": 0.5594135802469136,
      "grad_norm": 0.0013254997320473194,
      "learning_rate": 8.8791095003883e-06,
      "loss": 0.0001,
      "step": 4350
    },
    {
      "epoch": 0.5606995884773662,
      "grad_norm": 0.007698503788560629,
      "learning_rate": 8.853222883769092e-06,
      "loss": 0.0001,
      "step": 4360
    },
    {
      "epoch": 0.5619855967078189,
      "grad_norm": 0.0018942320020869374,
      "learning_rate": 8.827336267149885e-06,
      "loss": 0.0002,
      "step": 4370
    },
    {
      "epoch": 0.5632716049382716,
      "grad_norm": 0.0238112211227417,
      "learning_rate": 8.801449650530678e-06,
      "loss": 0.0001,
      "step": 4380
    },
    {
      "epoch": 0.5645576131687243,
      "grad_norm": 0.1084807813167572,
      "learning_rate": 8.775563033911469e-06,
      "loss": 0.0002,
      "step": 4390
    },
    {
      "epoch": 0.565843621399177,
      "grad_norm": 0.0024254783056676388,
      "learning_rate": 8.749676417292262e-06,
      "loss": 0.0001,
      "step": 4400
    },
    {
      "epoch": 0.5671296296296297,
      "grad_norm": 0.009138009510934353,
      "learning_rate": 8.723789800673053e-06,
      "loss": 0.0001,
      "step": 4410
    },
    {
      "epoch": 0.5684156378600823,
      "grad_norm": 0.003953916020691395,
      "learning_rate": 8.697903184053846e-06,
      "loss": 0.0002,
      "step": 4420
    },
    {
      "epoch": 0.569701646090535,
      "grad_norm": 0.0008875802741385996,
      "learning_rate": 8.672016567434637e-06,
      "loss": 0.0001,
      "step": 4430
    },
    {
      "epoch": 0.5709876543209876,
      "grad_norm": 0.015426911413669586,
      "learning_rate": 8.64612995081543e-06,
      "loss": 0.0005,
      "step": 4440
    },
    {
      "epoch": 0.5722736625514403,
      "grad_norm": 0.004008463118225336,
      "learning_rate": 8.620243334196221e-06,
      "loss": 0.0003,
      "step": 4450
    },
    {
      "epoch": 0.573559670781893,
      "grad_norm": 0.0027499888092279434,
      "learning_rate": 8.594356717577014e-06,
      "loss": 0.0002,
      "step": 4460
    },
    {
      "epoch": 0.5748456790123457,
      "grad_norm": 0.0020664199255406857,
      "learning_rate": 8.568470100957805e-06,
      "loss": 0.0001,
      "step": 4470
    },
    {
      "epoch": 0.5761316872427984,
      "grad_norm": 0.0016352742677554488,
      "learning_rate": 8.542583484338598e-06,
      "loss": 0.0003,
      "step": 4480
    },
    {
      "epoch": 0.5774176954732511,
      "grad_norm": 0.0032449124846607447,
      "learning_rate": 8.51669686771939e-06,
      "loss": 0.0002,
      "step": 4490
    },
    {
      "epoch": 0.5787037037037037,
      "grad_norm": 0.0018622219795361161,
      "learning_rate": 8.490810251100182e-06,
      "loss": 0.0002,
      "step": 4500
    },
    {
      "epoch": 0.5799897119341564,
      "grad_norm": 0.033287640661001205,
      "learning_rate": 8.464923634480973e-06,
      "loss": 0.0001,
      "step": 4510
    },
    {
      "epoch": 0.581275720164609,
      "grad_norm": 0.0015940258745104074,
      "learning_rate": 8.439037017861766e-06,
      "loss": 0.0001,
      "step": 4520
    },
    {
      "epoch": 0.5825617283950617,
      "grad_norm": 0.015372895635664463,
      "learning_rate": 8.413150401242557e-06,
      "loss": 0.0021,
      "step": 4530
    },
    {
      "epoch": 0.5838477366255144,
      "grad_norm": 0.0025875961873680353,
      "learning_rate": 8.38726378462335e-06,
      "loss": 0.0011,
      "step": 4540
    },
    {
      "epoch": 0.585133744855967,
      "grad_norm": 0.16458210349082947,
      "learning_rate": 8.361377168004141e-06,
      "loss": 0.0002,
      "step": 4550
    },
    {
      "epoch": 0.5864197530864198,
      "grad_norm": 0.005536846816539764,
      "learning_rate": 8.335490551384934e-06,
      "loss": 0.0001,
      "step": 4560
    },
    {
      "epoch": 0.5877057613168725,
      "grad_norm": 0.0013323028106242418,
      "learning_rate": 8.309603934765727e-06,
      "loss": 0.0001,
      "step": 4570
    },
    {
      "epoch": 0.5889917695473251,
      "grad_norm": 0.004023298155516386,
      "learning_rate": 8.283717318146518e-06,
      "loss": 0.0001,
      "step": 4580
    },
    {
      "epoch": 0.5902777777777778,
      "grad_norm": 0.004131348337978125,
      "learning_rate": 8.257830701527311e-06,
      "loss": 0.0001,
      "step": 4590
    },
    {
      "epoch": 0.5915637860082305,
      "grad_norm": 0.002468695165589452,
      "learning_rate": 8.231944084908104e-06,
      "loss": 0.0001,
      "step": 4600
    },
    {
      "epoch": 0.5928497942386831,
      "grad_norm": 0.002774169435724616,
      "learning_rate": 8.206057468288895e-06,
      "loss": 0.0001,
      "step": 4610
    },
    {
      "epoch": 0.5941358024691358,
      "grad_norm": 0.0015091742388904095,
      "learning_rate": 8.180170851669688e-06,
      "loss": 0.0001,
      "step": 4620
    },
    {
      "epoch": 0.5954218106995884,
      "grad_norm": 0.022625576704740524,
      "learning_rate": 8.15428423505048e-06,
      "loss": 0.0001,
      "step": 4630
    },
    {
      "epoch": 0.5967078189300411,
      "grad_norm": 0.005071370862424374,
      "learning_rate": 8.128397618431272e-06,
      "loss": 0.0002,
      "step": 4640
    },
    {
      "epoch": 0.5979938271604939,
      "grad_norm": 0.006687543820589781,
      "learning_rate": 8.102511001812064e-06,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 0.5992798353909465,
      "grad_norm": 0.0055353716015815735,
      "learning_rate": 8.076624385192856e-06,
      "loss": 0.0001,
      "step": 4660
    },
    {
      "epoch": 0.6005658436213992,
      "grad_norm": 0.007655265275388956,
      "learning_rate": 8.050737768573648e-06,
      "loss": 0.0001,
      "step": 4670
    },
    {
      "epoch": 0.6018518518518519,
      "grad_norm": 0.009048625826835632,
      "learning_rate": 8.02485115195444e-06,
      "loss": 0.0001,
      "step": 4680
    },
    {
      "epoch": 0.6031378600823045,
      "grad_norm": 0.0035744882188737392,
      "learning_rate": 7.998964535335232e-06,
      "loss": 0.0001,
      "step": 4690
    },
    {
      "epoch": 0.6044238683127572,
      "grad_norm": 0.019169069826602936,
      "learning_rate": 7.973077918716025e-06,
      "loss": 0.0035,
      "step": 4700
    },
    {
      "epoch": 0.6057098765432098,
      "grad_norm": 0.0010858075693249702,
      "learning_rate": 7.947191302096816e-06,
      "loss": 0.0001,
      "step": 4710
    },
    {
      "epoch": 0.6069958847736625,
      "grad_norm": 0.004866370465606451,
      "learning_rate": 7.921304685477609e-06,
      "loss": 0.0001,
      "step": 4720
    },
    {
      "epoch": 0.6082818930041153,
      "grad_norm": 0.0009335764334537089,
      "learning_rate": 7.8954180688584e-06,
      "loss": 0.0002,
      "step": 4730
    },
    {
      "epoch": 0.6095679012345679,
      "grad_norm": 0.0036695890594273806,
      "learning_rate": 7.869531452239193e-06,
      "loss": 0.0001,
      "step": 4740
    },
    {
      "epoch": 0.6108539094650206,
      "grad_norm": 0.0009610226843506098,
      "learning_rate": 7.843644835619984e-06,
      "loss": 0.0002,
      "step": 4750
    },
    {
      "epoch": 0.6121399176954733,
      "grad_norm": 0.0019389786757528782,
      "learning_rate": 7.817758219000777e-06,
      "loss": 0.0001,
      "step": 4760
    },
    {
      "epoch": 0.6134259259259259,
      "grad_norm": 0.013190116733312607,
      "learning_rate": 7.79187160238157e-06,
      "loss": 0.0005,
      "step": 4770
    },
    {
      "epoch": 0.6147119341563786,
      "grad_norm": 0.002405577339231968,
      "learning_rate": 7.765984985762361e-06,
      "loss": 0.0001,
      "step": 4780
    },
    {
      "epoch": 0.6159979423868313,
      "grad_norm": 0.0016547356499359012,
      "learning_rate": 7.740098369143154e-06,
      "loss": 0.0003,
      "step": 4790
    },
    {
      "epoch": 0.6172839506172839,
      "grad_norm": 0.008019113913178444,
      "learning_rate": 7.714211752523945e-06,
      "loss": 0.0002,
      "step": 4800
    },
    {
      "epoch": 0.6185699588477366,
      "grad_norm": 0.0025108843110501766,
      "learning_rate": 7.688325135904738e-06,
      "loss": 0.0001,
      "step": 4810
    },
    {
      "epoch": 0.6198559670781894,
      "grad_norm": 0.0012536990689113736,
      "learning_rate": 7.66243851928553e-06,
      "loss": 0.0001,
      "step": 4820
    },
    {
      "epoch": 0.621141975308642,
      "grad_norm": 3.0949313640594482,
      "learning_rate": 7.636551902666322e-06,
      "loss": 0.0013,
      "step": 4830
    },
    {
      "epoch": 0.6224279835390947,
      "grad_norm": 0.014718999154865742,
      "learning_rate": 7.610665286047114e-06,
      "loss": 0.0001,
      "step": 4840
    },
    {
      "epoch": 0.6237139917695473,
      "grad_norm": 0.0007953541935421526,
      "learning_rate": 7.584778669427907e-06,
      "loss": 0.0001,
      "step": 4850
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.00426604924723506,
      "learning_rate": 7.558892052808698e-06,
      "loss": 0.0002,
      "step": 4860
    },
    {
      "epoch": 0.6262860082304527,
      "grad_norm": 0.0015798392705619335,
      "learning_rate": 7.533005436189491e-06,
      "loss": 0.0001,
      "step": 4870
    },
    {
      "epoch": 0.6275720164609053,
      "grad_norm": 0.004077711142599583,
      "learning_rate": 7.507118819570283e-06,
      "loss": 0.0002,
      "step": 4880
    },
    {
      "epoch": 0.628858024691358,
      "grad_norm": 0.0017253673868253827,
      "learning_rate": 7.481232202951075e-06,
      "loss": 0.0001,
      "step": 4890
    },
    {
      "epoch": 0.6301440329218106,
      "grad_norm": 0.0035500028170645237,
      "learning_rate": 7.455345586331867e-06,
      "loss": 0.0001,
      "step": 4900
    },
    {
      "epoch": 0.6314300411522634,
      "grad_norm": 0.0728374719619751,
      "learning_rate": 7.42945896971266e-06,
      "loss": 0.0004,
      "step": 4910
    },
    {
      "epoch": 0.6327160493827161,
      "grad_norm": 0.007606648840010166,
      "learning_rate": 7.403572353093451e-06,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 0.6340020576131687,
      "grad_norm": 0.003744693472981453,
      "learning_rate": 7.377685736474244e-06,
      "loss": 0.0001,
      "step": 4930
    },
    {
      "epoch": 0.6352880658436214,
      "grad_norm": 0.013704796321690083,
      "learning_rate": 7.351799119855035e-06,
      "loss": 0.0002,
      "step": 4940
    },
    {
      "epoch": 0.6365740740740741,
      "grad_norm": 0.004053870681673288,
      "learning_rate": 7.325912503235828e-06,
      "loss": 0.0001,
      "step": 4950
    },
    {
      "epoch": 0.6378600823045267,
      "grad_norm": 4.499867916107178,
      "learning_rate": 7.300025886616619e-06,
      "loss": 0.0008,
      "step": 4960
    },
    {
      "epoch": 0.6391460905349794,
      "grad_norm": 0.011681994423270226,
      "learning_rate": 7.274139269997412e-06,
      "loss": 0.0002,
      "step": 4970
    },
    {
      "epoch": 0.6404320987654321,
      "grad_norm": 0.085853211581707,
      "learning_rate": 7.248252653378204e-06,
      "loss": 0.0001,
      "step": 4980
    },
    {
      "epoch": 0.6417181069958847,
      "grad_norm": 0.006395160686224699,
      "learning_rate": 7.222366036758996e-06,
      "loss": 0.0001,
      "step": 4990
    },
    {
      "epoch": 0.6430041152263375,
      "grad_norm": 0.005296448711305857,
      "learning_rate": 7.196479420139788e-06,
      "loss": 0.0001,
      "step": 5000
    },
    {
      "epoch": 0.6442901234567902,
      "grad_norm": 0.005537915509194136,
      "learning_rate": 7.17059280352058e-06,
      "loss": 0.0001,
      "step": 5010
    },
    {
      "epoch": 0.6455761316872428,
      "grad_norm": 0.0073884353041648865,
      "learning_rate": 7.144706186901372e-06,
      "loss": 0.0005,
      "step": 5020
    },
    {
      "epoch": 0.6468621399176955,
      "grad_norm": 0.004653883632272482,
      "learning_rate": 7.118819570282165e-06,
      "loss": 0.0001,
      "step": 5030
    },
    {
      "epoch": 0.6481481481481481,
      "grad_norm": 0.0021598150487989187,
      "learning_rate": 7.0929329536629565e-06,
      "loss": 0.0002,
      "step": 5040
    },
    {
      "epoch": 0.6494341563786008,
      "grad_norm": 0.02840140089392662,
      "learning_rate": 7.067046337043749e-06,
      "loss": 0.0001,
      "step": 5050
    },
    {
      "epoch": 0.6507201646090535,
      "grad_norm": 0.6644381284713745,
      "learning_rate": 7.0411597204245406e-06,
      "loss": 0.0002,
      "step": 5060
    },
    {
      "epoch": 0.6520061728395061,
      "grad_norm": 0.0030301043298095465,
      "learning_rate": 7.0152731038053334e-06,
      "loss": 0.0001,
      "step": 5070
    },
    {
      "epoch": 0.6532921810699589,
      "grad_norm": 0.005538966041058302,
      "learning_rate": 6.989386487186125e-06,
      "loss": 0.0004,
      "step": 5080
    },
    {
      "epoch": 0.6545781893004116,
      "grad_norm": 0.0009499698062427342,
      "learning_rate": 6.9634998705669175e-06,
      "loss": 0.0003,
      "step": 5090
    },
    {
      "epoch": 0.6558641975308642,
      "grad_norm": 0.005516155157238245,
      "learning_rate": 6.9376132539477096e-06,
      "loss": 0.0002,
      "step": 5100
    },
    {
      "epoch": 0.6571502057613169,
      "grad_norm": 0.003017079783603549,
      "learning_rate": 6.911726637328502e-06,
      "loss": 0.0002,
      "step": 5110
    },
    {
      "epoch": 0.6584362139917695,
      "grad_norm": 0.002992344554513693,
      "learning_rate": 6.885840020709294e-06,
      "loss": 0.0001,
      "step": 5120
    },
    {
      "epoch": 0.6597222222222222,
      "grad_norm": 0.0019162485841661692,
      "learning_rate": 6.8599534040900865e-06,
      "loss": 0.0001,
      "step": 5130
    },
    {
      "epoch": 0.6610082304526749,
      "grad_norm": 0.005576569586992264,
      "learning_rate": 6.834066787470878e-06,
      "loss": 0.0001,
      "step": 5140
    },
    {
      "epoch": 0.6622942386831275,
      "grad_norm": 0.013640012592077255,
      "learning_rate": 6.808180170851671e-06,
      "loss": 0.0001,
      "step": 5150
    },
    {
      "epoch": 0.6635802469135802,
      "grad_norm": 0.028819715604186058,
      "learning_rate": 6.782293554232462e-06,
      "loss": 0.0002,
      "step": 5160
    },
    {
      "epoch": 0.664866255144033,
      "grad_norm": 0.0030810616444796324,
      "learning_rate": 6.756406937613255e-06,
      "loss": 0.0002,
      "step": 5170
    },
    {
      "epoch": 0.6661522633744856,
      "grad_norm": 0.022461889311671257,
      "learning_rate": 6.730520320994046e-06,
      "loss": 0.0002,
      "step": 5180
    },
    {
      "epoch": 0.6674382716049383,
      "grad_norm": 0.004928259644657373,
      "learning_rate": 6.704633704374839e-06,
      "loss": 0.0001,
      "step": 5190
    },
    {
      "epoch": 0.668724279835391,
      "grad_norm": 0.006776297930628061,
      "learning_rate": 6.678747087755631e-06,
      "loss": 0.0001,
      "step": 5200
    },
    {
      "epoch": 0.6700102880658436,
      "grad_norm": 0.0034874011762440205,
      "learning_rate": 6.652860471136423e-06,
      "loss": 0.0001,
      "step": 5210
    },
    {
      "epoch": 0.6712962962962963,
      "grad_norm": 0.007989301346242428,
      "learning_rate": 6.626973854517215e-06,
      "loss": 0.0001,
      "step": 5220
    },
    {
      "epoch": 0.6725823045267489,
      "grad_norm": 0.01623448170721531,
      "learning_rate": 6.601087237898007e-06,
      "loss": 0.0001,
      "step": 5230
    },
    {
      "epoch": 0.6738683127572016,
      "grad_norm": 0.0024621409829705954,
      "learning_rate": 6.575200621278799e-06,
      "loss": 0.0001,
      "step": 5240
    },
    {
      "epoch": 0.6751543209876543,
      "grad_norm": 0.010299411602318287,
      "learning_rate": 6.549314004659592e-06,
      "loss": 0.0001,
      "step": 5250
    },
    {
      "epoch": 0.676440329218107,
      "grad_norm": 0.0025335042737424374,
      "learning_rate": 6.523427388040383e-06,
      "loss": 0.0001,
      "step": 5260
    },
    {
      "epoch": 0.6777263374485597,
      "grad_norm": 0.001878121285699308,
      "learning_rate": 6.497540771421176e-06,
      "loss": 0.0001,
      "step": 5270
    },
    {
      "epoch": 0.6790123456790124,
      "grad_norm": 0.0021035033278167248,
      "learning_rate": 6.471654154801969e-06,
      "loss": 0.0001,
      "step": 5280
    },
    {
      "epoch": 0.680298353909465,
      "grad_norm": 0.0011496307561174035,
      "learning_rate": 6.44576753818276e-06,
      "loss": 0.0001,
      "step": 5290
    },
    {
      "epoch": 0.6815843621399177,
      "grad_norm": 0.04972586780786514,
      "learning_rate": 6.419880921563553e-06,
      "loss": 0.0002,
      "step": 5300
    },
    {
      "epoch": 0.6828703703703703,
      "grad_norm": 0.0025747851468622684,
      "learning_rate": 6.393994304944344e-06,
      "loss": 0.0001,
      "step": 5310
    },
    {
      "epoch": 0.684156378600823,
      "grad_norm": 0.001532340538688004,
      "learning_rate": 6.368107688325137e-06,
      "loss": 0.0004,
      "step": 5320
    },
    {
      "epoch": 0.6854423868312757,
      "grad_norm": 0.0029973716009408236,
      "learning_rate": 6.342221071705928e-06,
      "loss": 0.0001,
      "step": 5330
    },
    {
      "epoch": 0.6867283950617284,
      "grad_norm": 0.002487617079168558,
      "learning_rate": 6.316334455086721e-06,
      "loss": 0.0001,
      "step": 5340
    },
    {
      "epoch": 0.6880144032921811,
      "grad_norm": 0.004265392664819956,
      "learning_rate": 6.290447838467513e-06,
      "loss": 0.0001,
      "step": 5350
    },
    {
      "epoch": 0.6893004115226338,
      "grad_norm": 0.0009544906788505614,
      "learning_rate": 6.264561221848305e-06,
      "loss": 0.0001,
      "step": 5360
    },
    {
      "epoch": 0.6905864197530864,
      "grad_norm": 0.0012401759158819914,
      "learning_rate": 6.238674605229097e-06,
      "loss": 0.0001,
      "step": 5370
    },
    {
      "epoch": 0.6918724279835391,
      "grad_norm": 2.5582664012908936,
      "learning_rate": 6.212787988609889e-06,
      "loss": 0.0005,
      "step": 5380
    },
    {
      "epoch": 0.6931584362139918,
      "grad_norm": 0.0027354343328624964,
      "learning_rate": 6.186901371990681e-06,
      "loss": 0.0001,
      "step": 5390
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 0.005599164869636297,
      "learning_rate": 6.161014755371474e-06,
      "loss": 0.0001,
      "step": 5400
    },
    {
      "epoch": 0.6957304526748971,
      "grad_norm": 0.005992677994072437,
      "learning_rate": 6.135128138752265e-06,
      "loss": 0.0001,
      "step": 5410
    },
    {
      "epoch": 0.6970164609053497,
      "grad_norm": 0.008221343159675598,
      "learning_rate": 6.109241522133058e-06,
      "loss": 0.0001,
      "step": 5420
    },
    {
      "epoch": 0.6983024691358025,
      "grad_norm": 0.0292135551571846,
      "learning_rate": 6.0833549055138494e-06,
      "loss": 0.0001,
      "step": 5430
    },
    {
      "epoch": 0.6995884773662552,
      "grad_norm": 0.005750433541834354,
      "learning_rate": 6.057468288894642e-06,
      "loss": 0.0001,
      "step": 5440
    },
    {
      "epoch": 0.7008744855967078,
      "grad_norm": 0.0017248913645744324,
      "learning_rate": 6.0315816722754335e-06,
      "loss": 0.0008,
      "step": 5450
    },
    {
      "epoch": 0.7021604938271605,
      "grad_norm": 0.0024589854292571545,
      "learning_rate": 6.005695055656226e-06,
      "loss": 0.0001,
      "step": 5460
    },
    {
      "epoch": 0.7034465020576132,
      "grad_norm": 0.001440791878849268,
      "learning_rate": 5.9798084390370184e-06,
      "loss": 0.0001,
      "step": 5470
    },
    {
      "epoch": 0.7047325102880658,
      "grad_norm": 0.0025605938863009214,
      "learning_rate": 5.9539218224178105e-06,
      "loss": 0.0002,
      "step": 5480
    },
    {
      "epoch": 0.7060185185185185,
      "grad_norm": 0.0006681105587631464,
      "learning_rate": 5.9280352057986025e-06,
      "loss": 0.0001,
      "step": 5490
    },
    {
      "epoch": 0.7073045267489712,
      "grad_norm": 0.08692693710327148,
      "learning_rate": 5.902148589179395e-06,
      "loss": 0.0002,
      "step": 5500
    },
    {
      "epoch": 0.7085905349794238,
      "grad_norm": 0.0031706488225609064,
      "learning_rate": 5.876261972560187e-06,
      "loss": 0.0001,
      "step": 5510
    },
    {
      "epoch": 0.7098765432098766,
      "grad_norm": 0.004039619117975235,
      "learning_rate": 5.8503753559409795e-06,
      "loss": 0.0001,
      "step": 5520
    },
    {
      "epoch": 0.7111625514403292,
      "grad_norm": 0.0054131802171468735,
      "learning_rate": 5.824488739321771e-06,
      "loss": 0.0001,
      "step": 5530
    },
    {
      "epoch": 0.7124485596707819,
      "grad_norm": 0.0019564663525670767,
      "learning_rate": 5.7986021227025636e-06,
      "loss": 0.0001,
      "step": 5540
    },
    {
      "epoch": 0.7137345679012346,
      "grad_norm": 0.002889419673010707,
      "learning_rate": 5.775304167745276e-06,
      "loss": 0.0027,
      "step": 5550
    },
    {
      "epoch": 0.7150205761316872,
      "grad_norm": 0.001959516666829586,
      "learning_rate": 5.749417551126068e-06,
      "loss": 0.0002,
      "step": 5560
    },
    {
      "epoch": 0.7163065843621399,
      "grad_norm": 0.006098353303968906,
      "learning_rate": 5.72353093450686e-06,
      "loss": 0.0002,
      "step": 5570
    },
    {
      "epoch": 0.7175925925925926,
      "grad_norm": 1.7178759574890137,
      "learning_rate": 5.6976443178876524e-06,
      "loss": 0.0003,
      "step": 5580
    },
    {
      "epoch": 0.7188786008230452,
      "grad_norm": 0.0012967167422175407,
      "learning_rate": 5.6717577012684445e-06,
      "loss": 0.0,
      "step": 5590
    },
    {
      "epoch": 0.720164609053498,
      "grad_norm": 0.0010897436877712607,
      "learning_rate": 5.645871084649237e-06,
      "loss": 0.0002,
      "step": 5600
    },
    {
      "epoch": 0.7214506172839507,
      "grad_norm": 0.002236315282061696,
      "learning_rate": 5.6199844680300286e-06,
      "loss": 0.0013,
      "step": 5610
    },
    {
      "epoch": 0.7227366255144033,
      "grad_norm": 0.006879250518977642,
      "learning_rate": 5.5940978514108214e-06,
      "loss": 0.0001,
      "step": 5620
    },
    {
      "epoch": 0.724022633744856,
      "grad_norm": 0.0006845765165053308,
      "learning_rate": 5.568211234791613e-06,
      "loss": 0.0001,
      "step": 5630
    },
    {
      "epoch": 0.7253086419753086,
      "grad_norm": 0.019374879077076912,
      "learning_rate": 5.5423246181724055e-06,
      "loss": 0.0001,
      "step": 5640
    },
    {
      "epoch": 0.7265946502057613,
      "grad_norm": 0.004145989194512367,
      "learning_rate": 5.516438001553197e-06,
      "loss": 0.0001,
      "step": 5650
    },
    {
      "epoch": 0.727880658436214,
      "grad_norm": 0.0018876910908147693,
      "learning_rate": 5.49055138493399e-06,
      "loss": 0.0001,
      "step": 5660
    },
    {
      "epoch": 0.7291666666666666,
      "grad_norm": 0.00243341620080173,
      "learning_rate": 5.464664768314782e-06,
      "loss": 0.0001,
      "step": 5670
    },
    {
      "epoch": 0.7304526748971193,
      "grad_norm": 0.0033051269128918648,
      "learning_rate": 5.438778151695574e-06,
      "loss": 0.0002,
      "step": 5680
    },
    {
      "epoch": 0.7317386831275721,
      "grad_norm": 0.0044785309582948685,
      "learning_rate": 5.412891535076366e-06,
      "loss": 0.0002,
      "step": 5690
    },
    {
      "epoch": 0.7330246913580247,
      "grad_norm": 0.005446622148156166,
      "learning_rate": 5.387004918457159e-06,
      "loss": 0.0001,
      "step": 5700
    },
    {
      "epoch": 0.7343106995884774,
      "grad_norm": 0.002235936466604471,
      "learning_rate": 5.36111830183795e-06,
      "loss": 0.0001,
      "step": 5710
    },
    {
      "epoch": 0.73559670781893,
      "grad_norm": 0.009310039691627026,
      "learning_rate": 5.335231685218743e-06,
      "loss": 0.0001,
      "step": 5720
    },
    {
      "epoch": 0.7368827160493827,
      "grad_norm": 0.0014852730091661215,
      "learning_rate": 5.309345068599534e-06,
      "loss": 0.0001,
      "step": 5730
    },
    {
      "epoch": 0.7381687242798354,
      "grad_norm": 0.006621764972805977,
      "learning_rate": 5.283458451980327e-06,
      "loss": 0.0001,
      "step": 5740
    },
    {
      "epoch": 0.739454732510288,
      "grad_norm": 0.0023152714129537344,
      "learning_rate": 5.257571835361118e-06,
      "loss": 0.0006,
      "step": 5750
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.012187882326543331,
      "learning_rate": 5.231685218741911e-06,
      "loss": 0.0002,
      "step": 5760
    },
    {
      "epoch": 0.7420267489711934,
      "grad_norm": 0.0070885103195905685,
      "learning_rate": 5.205798602122703e-06,
      "loss": 0.0001,
      "step": 5770
    },
    {
      "epoch": 0.7433127572016461,
      "grad_norm": 0.0027371621690690517,
      "learning_rate": 5.179911985503495e-06,
      "loss": 0.0001,
      "step": 5780
    },
    {
      "epoch": 0.7445987654320988,
      "grad_norm": 0.009478329680860043,
      "learning_rate": 5.154025368884287e-06,
      "loss": 0.0001,
      "step": 5790
    },
    {
      "epoch": 0.7458847736625515,
      "grad_norm": 0.004683771636337042,
      "learning_rate": 5.128138752265079e-06,
      "loss": 0.0001,
      "step": 5800
    },
    {
      "epoch": 0.7471707818930041,
      "grad_norm": 0.0023663495667278767,
      "learning_rate": 5.102252135645871e-06,
      "loss": 0.0001,
      "step": 5810
    },
    {
      "epoch": 0.7484567901234568,
      "grad_norm": 0.0011281039332970977,
      "learning_rate": 5.076365519026664e-06,
      "loss": 0.0001,
      "step": 5820
    },
    {
      "epoch": 0.7497427983539094,
      "grad_norm": 0.0036335133481770754,
      "learning_rate": 5.050478902407456e-06,
      "loss": 0.0001,
      "step": 5830
    },
    {
      "epoch": 0.7510288065843621,
      "grad_norm": 0.0024786347057670355,
      "learning_rate": 5.024592285788248e-06,
      "loss": 0.0001,
      "step": 5840
    },
    {
      "epoch": 0.7523148148148148,
      "grad_norm": 0.0016499339835718274,
      "learning_rate": 4.99870566916904e-06,
      "loss": 0.0002,
      "step": 5850
    },
    {
      "epoch": 0.7536008230452675,
      "grad_norm": 0.0018018747214227915,
      "learning_rate": 4.972819052549832e-06,
      "loss": 0.0001,
      "step": 5860
    },
    {
      "epoch": 0.7548868312757202,
      "grad_norm": 0.0008640865562483668,
      "learning_rate": 4.946932435930624e-06,
      "loss": 0.0001,
      "step": 5870
    },
    {
      "epoch": 0.7561728395061729,
      "grad_norm": 0.0008436235366389155,
      "learning_rate": 4.921045819311416e-06,
      "loss": 0.0001,
      "step": 5880
    },
    {
      "epoch": 0.7574588477366255,
      "grad_norm": 0.004792803432792425,
      "learning_rate": 4.895159202692208e-06,
      "loss": 0.0001,
      "step": 5890
    },
    {
      "epoch": 0.7587448559670782,
      "grad_norm": 0.003791837254539132,
      "learning_rate": 4.869272586073e-06,
      "loss": 0.0001,
      "step": 5900
    },
    {
      "epoch": 0.7600308641975309,
      "grad_norm": 0.005707392003387213,
      "learning_rate": 4.843385969453792e-06,
      "loss": 0.0001,
      "step": 5910
    },
    {
      "epoch": 0.7613168724279835,
      "grad_norm": 0.0021628637332469225,
      "learning_rate": 4.817499352834585e-06,
      "loss": 0.0001,
      "step": 5920
    },
    {
      "epoch": 0.7626028806584362,
      "grad_norm": 0.0016021888004615903,
      "learning_rate": 4.791612736215377e-06,
      "loss": 0.0001,
      "step": 5930
    },
    {
      "epoch": 0.7638888888888888,
      "grad_norm": 0.006783057004213333,
      "learning_rate": 4.765726119596169e-06,
      "loss": 0.0001,
      "step": 5940
    },
    {
      "epoch": 0.7651748971193416,
      "grad_norm": 0.002967114793136716,
      "learning_rate": 4.739839502976961e-06,
      "loss": 0.0001,
      "step": 5950
    },
    {
      "epoch": 0.7664609053497943,
      "grad_norm": 0.0020221134182065725,
      "learning_rate": 4.713952886357753e-06,
      "loss": 0.0001,
      "step": 5960
    },
    {
      "epoch": 0.7677469135802469,
      "grad_norm": 0.006718974560499191,
      "learning_rate": 4.688066269738545e-06,
      "loss": 0.0001,
      "step": 5970
    },
    {
      "epoch": 0.7690329218106996,
      "grad_norm": 0.002496840199455619,
      "learning_rate": 4.662179653119337e-06,
      "loss": 0.0001,
      "step": 5980
    },
    {
      "epoch": 0.7703189300411523,
      "grad_norm": 0.005668323952704668,
      "learning_rate": 4.6362930365001295e-06,
      "loss": 0.0001,
      "step": 5990
    },
    {
      "epoch": 0.7716049382716049,
      "grad_norm": 0.003976923879235983,
      "learning_rate": 4.6104064198809215e-06,
      "loss": 0.0001,
      "step": 6000
    },
    {
      "epoch": 0.7728909465020576,
      "grad_norm": 0.0020191585645079613,
      "learning_rate": 4.5845198032617135e-06,
      "loss": 0.0001,
      "step": 6010
    },
    {
      "epoch": 0.7741769547325102,
      "grad_norm": 0.0009678936912678182,
      "learning_rate": 4.558633186642506e-06,
      "loss": 0.0001,
      "step": 6020
    },
    {
      "epoch": 0.7754629629629629,
      "grad_norm": 0.00930264126509428,
      "learning_rate": 4.5327465700232985e-06,
      "loss": 0.0017,
      "step": 6030
    },
    {
      "epoch": 0.7767489711934157,
      "grad_norm": 0.004309632815420628,
      "learning_rate": 4.5068599534040905e-06,
      "loss": 0.0001,
      "step": 6040
    },
    {
      "epoch": 0.7780349794238683,
      "grad_norm": 0.003268216038122773,
      "learning_rate": 4.4809733367848825e-06,
      "loss": 0.0001,
      "step": 6050
    },
    {
      "epoch": 0.779320987654321,
      "grad_norm": 0.0018638026667758822,
      "learning_rate": 4.455086720165675e-06,
      "loss": 0.0001,
      "step": 6060
    },
    {
      "epoch": 0.7806069958847737,
      "grad_norm": 0.0013310402864590287,
      "learning_rate": 4.429200103546467e-06,
      "loss": 0.0001,
      "step": 6070
    },
    {
      "epoch": 0.7818930041152263,
      "grad_norm": 0.005635813809931278,
      "learning_rate": 4.4033134869272595e-06,
      "loss": 0.0001,
      "step": 6080
    },
    {
      "epoch": 0.783179012345679,
      "grad_norm": 0.00407576747238636,
      "learning_rate": 4.3774268703080516e-06,
      "loss": 0.0001,
      "step": 6090
    },
    {
      "epoch": 0.7844650205761317,
      "grad_norm": 0.0026738829910755157,
      "learning_rate": 4.351540253688844e-06,
      "loss": 0.0001,
      "step": 6100
    },
    {
      "epoch": 0.7857510288065843,
      "grad_norm": 0.007700005080550909,
      "learning_rate": 4.325653637069636e-06,
      "loss": 0.0039,
      "step": 6110
    },
    {
      "epoch": 0.7870370370370371,
      "grad_norm": 0.0017073083436116576,
      "learning_rate": 4.299767020450428e-06,
      "loss": 0.0001,
      "step": 6120
    },
    {
      "epoch": 0.7883230452674898,
      "grad_norm": 0.0011570630595088005,
      "learning_rate": 4.27388040383122e-06,
      "loss": 0.0002,
      "step": 6130
    },
    {
      "epoch": 0.7896090534979424,
      "grad_norm": 0.0034899653401225805,
      "learning_rate": 4.247993787212012e-06,
      "loss": 0.0001,
      "step": 6140
    },
    {
      "epoch": 0.7908950617283951,
      "grad_norm": 0.009586712345480919,
      "learning_rate": 4.222107170592804e-06,
      "loss": 0.0001,
      "step": 6150
    },
    {
      "epoch": 0.7921810699588477,
      "grad_norm": 0.00334401847794652,
      "learning_rate": 4.196220553973596e-06,
      "loss": 0.0001,
      "step": 6160
    },
    {
      "epoch": 0.7934670781893004,
      "grad_norm": 0.008318040519952774,
      "learning_rate": 4.170333937354388e-06,
      "loss": 0.0001,
      "step": 6170
    },
    {
      "epoch": 0.7947530864197531,
      "grad_norm": 0.001992603996768594,
      "learning_rate": 4.144447320735181e-06,
      "loss": 0.0001,
      "step": 6180
    },
    {
      "epoch": 0.7960390946502057,
      "grad_norm": 0.0061052110977470875,
      "learning_rate": 4.118560704115973e-06,
      "loss": 0.0001,
      "step": 6190
    },
    {
      "epoch": 0.7973251028806584,
      "grad_norm": 0.003990577068179846,
      "learning_rate": 4.092674087496765e-06,
      "loss": 0.0001,
      "step": 6200
    },
    {
      "epoch": 0.7986111111111112,
      "grad_norm": 0.009150988422334194,
      "learning_rate": 4.066787470877557e-06,
      "loss": 0.0001,
      "step": 6210
    },
    {
      "epoch": 0.7998971193415638,
      "grad_norm": 0.0029879496432840824,
      "learning_rate": 4.040900854258349e-06,
      "loss": 0.0001,
      "step": 6220
    },
    {
      "epoch": 0.8011831275720165,
      "grad_norm": 0.03295820578932762,
      "learning_rate": 4.015014237639141e-06,
      "loss": 0.0001,
      "step": 6230
    },
    {
      "epoch": 0.8024691358024691,
      "grad_norm": 0.004485324490815401,
      "learning_rate": 3.989127621019933e-06,
      "loss": 0.0001,
      "step": 6240
    },
    {
      "epoch": 0.8037551440329218,
      "grad_norm": 0.0008365808171220124,
      "learning_rate": 3.963241004400725e-06,
      "loss": 0.0001,
      "step": 6250
    },
    {
      "epoch": 0.8050411522633745,
      "grad_norm": 0.0026881021913141012,
      "learning_rate": 3.937354387781517e-06,
      "loss": 0.0001,
      "step": 6260
    },
    {
      "epoch": 0.8063271604938271,
      "grad_norm": 0.08337099105119705,
      "learning_rate": 3.911467771162309e-06,
      "loss": 0.0002,
      "step": 6270
    },
    {
      "epoch": 0.8076131687242798,
      "grad_norm": 0.004019717685878277,
      "learning_rate": 3.885581154543102e-06,
      "loss": 0.0001,
      "step": 6280
    },
    {
      "epoch": 0.8088991769547325,
      "grad_norm": 0.0022616058122366667,
      "learning_rate": 3.859694537923894e-06,
      "loss": 0.0002,
      "step": 6290
    },
    {
      "epoch": 0.8101851851851852,
      "grad_norm": 0.0034262000117450953,
      "learning_rate": 3.833807921304686e-06,
      "loss": 0.0001,
      "step": 6300
    },
    {
      "epoch": 0.8114711934156379,
      "grad_norm": 0.002254670951515436,
      "learning_rate": 3.807921304685478e-06,
      "loss": 0.0001,
      "step": 6310
    },
    {
      "epoch": 0.8127572016460906,
      "grad_norm": 0.0025688488967716694,
      "learning_rate": 3.78203468806627e-06,
      "loss": 0.0001,
      "step": 6320
    },
    {
      "epoch": 0.8140432098765432,
      "grad_norm": 0.018148697912693024,
      "learning_rate": 3.756148071447062e-06,
      "loss": 0.0001,
      "step": 6330
    },
    {
      "epoch": 0.8153292181069959,
      "grad_norm": 0.0021473942324519157,
      "learning_rate": 3.7302614548278542e-06,
      "loss": 0.0003,
      "step": 6340
    },
    {
      "epoch": 0.8166152263374485,
      "grad_norm": 0.0014695929130539298,
      "learning_rate": 3.7043748382086463e-06,
      "loss": 0.0001,
      "step": 6350
    },
    {
      "epoch": 0.8179012345679012,
      "grad_norm": 0.0020644841715693474,
      "learning_rate": 3.6784882215894383e-06,
      "loss": 0.0001,
      "step": 6360
    },
    {
      "epoch": 0.8191872427983539,
      "grad_norm": 0.001386662246659398,
      "learning_rate": 3.652601604970231e-06,
      "loss": 0.0001,
      "step": 6370
    },
    {
      "epoch": 0.8204732510288066,
      "grad_norm": 0.007944884710013866,
      "learning_rate": 3.626714988351023e-06,
      "loss": 0.0001,
      "step": 6380
    },
    {
      "epoch": 0.8217592592592593,
      "grad_norm": 0.0010859272442758083,
      "learning_rate": 3.600828371731815e-06,
      "loss": 0.0001,
      "step": 6390
    },
    {
      "epoch": 0.823045267489712,
      "grad_norm": 0.010937873274087906,
      "learning_rate": 3.574941755112607e-06,
      "loss": 0.0001,
      "step": 6400
    },
    {
      "epoch": 0.8243312757201646,
      "grad_norm": 0.0019087487598881125,
      "learning_rate": 3.549055138493399e-06,
      "loss": 0.0001,
      "step": 6410
    },
    {
      "epoch": 0.8256172839506173,
      "grad_norm": 0.0016518960474058986,
      "learning_rate": 3.5231685218741914e-06,
      "loss": 0.0001,
      "step": 6420
    },
    {
      "epoch": 0.82690329218107,
      "grad_norm": 0.0227675661444664,
      "learning_rate": 3.4972819052549835e-06,
      "loss": 0.0001,
      "step": 6430
    },
    {
      "epoch": 0.8281893004115226,
      "grad_norm": 0.0013630572939291596,
      "learning_rate": 3.4713952886357755e-06,
      "loss": 0.0001,
      "step": 6440
    },
    {
      "epoch": 0.8294753086419753,
      "grad_norm": 0.003362728515639901,
      "learning_rate": 3.4455086720165675e-06,
      "loss": 0.0001,
      "step": 6450
    },
    {
      "epoch": 0.8307613168724279,
      "grad_norm": 0.002384941093623638,
      "learning_rate": 3.4196220553973596e-06,
      "loss": 0.0001,
      "step": 6460
    },
    {
      "epoch": 0.8320473251028807,
      "grad_norm": 0.0033134666737169027,
      "learning_rate": 3.3937354387781516e-06,
      "loss": 0.0001,
      "step": 6470
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.007808230351656675,
      "learning_rate": 3.367848822158944e-06,
      "loss": 0.0001,
      "step": 6480
    },
    {
      "epoch": 0.834619341563786,
      "grad_norm": 0.0026437905617058277,
      "learning_rate": 3.341962205539736e-06,
      "loss": 0.0001,
      "step": 6490
    },
    {
      "epoch": 0.8359053497942387,
      "grad_norm": 0.00742620974779129,
      "learning_rate": 3.316075588920528e-06,
      "loss": 0.0003,
      "step": 6500
    },
    {
      "epoch": 0.8371913580246914,
      "grad_norm": 0.0018457573605701327,
      "learning_rate": 3.29018897230132e-06,
      "loss": 0.0001,
      "step": 6510
    },
    {
      "epoch": 0.838477366255144,
      "grad_norm": 0.0018475463148206472,
      "learning_rate": 3.2643023556821122e-06,
      "loss": 0.0003,
      "step": 6520
    },
    {
      "epoch": 0.8397633744855967,
      "grad_norm": 0.0014850758016109467,
      "learning_rate": 3.2384157390629047e-06,
      "loss": 0.0001,
      "step": 6530
    },
    {
      "epoch": 0.8410493827160493,
      "grad_norm": 0.002166560385376215,
      "learning_rate": 3.2125291224436967e-06,
      "loss": 0.0001,
      "step": 6540
    },
    {
      "epoch": 0.842335390946502,
      "grad_norm": 0.0013405639911070466,
      "learning_rate": 3.1866425058244888e-06,
      "loss": 0.0001,
      "step": 6550
    },
    {
      "epoch": 0.8436213991769548,
      "grad_norm": 0.0010464373044669628,
      "learning_rate": 3.160755889205281e-06,
      "loss": 0.0001,
      "step": 6560
    },
    {
      "epoch": 0.8449074074074074,
      "grad_norm": 0.0010208480525761843,
      "learning_rate": 3.134869272586073e-06,
      "loss": 0.0001,
      "step": 6570
    },
    {
      "epoch": 0.8461934156378601,
      "grad_norm": 0.009899551048874855,
      "learning_rate": 3.1089826559668657e-06,
      "loss": 0.0001,
      "step": 6580
    },
    {
      "epoch": 0.8474794238683128,
      "grad_norm": 0.006115611642599106,
      "learning_rate": 3.083096039347658e-06,
      "loss": 0.0001,
      "step": 6590
    },
    {
      "epoch": 0.8487654320987654,
      "grad_norm": 0.003531817812472582,
      "learning_rate": 3.05720942272845e-06,
      "loss": 0.0001,
      "step": 6600
    },
    {
      "epoch": 0.8500514403292181,
      "grad_norm": 0.0018379612592980266,
      "learning_rate": 3.031322806109242e-06,
      "loss": 0.0001,
      "step": 6610
    },
    {
      "epoch": 0.8513374485596708,
      "grad_norm": 0.0019477917812764645,
      "learning_rate": 3.0054361894900343e-06,
      "loss": 0.0001,
      "step": 6620
    },
    {
      "epoch": 0.8526234567901234,
      "grad_norm": 0.17019309103488922,
      "learning_rate": 2.9795495728708264e-06,
      "loss": 0.0002,
      "step": 6630
    },
    {
      "epoch": 0.8539094650205762,
      "grad_norm": 0.002387451473623514,
      "learning_rate": 2.9536629562516184e-06,
      "loss": 0.0001,
      "step": 6640
    },
    {
      "epoch": 0.8551954732510288,
      "grad_norm": 0.0008348588016815484,
      "learning_rate": 2.9277763396324105e-06,
      "loss": 0.0001,
      "step": 6650
    },
    {
      "epoch": 0.8564814814814815,
      "grad_norm": 0.0020913209300488234,
      "learning_rate": 2.9018897230132025e-06,
      "loss": 0.0,
      "step": 6660
    },
    {
      "epoch": 0.8577674897119342,
      "grad_norm": 0.009105749428272247,
      "learning_rate": 2.8760031063939945e-06,
      "loss": 0.0001,
      "step": 6670
    },
    {
      "epoch": 0.8590534979423868,
      "grad_norm": 0.006906955502927303,
      "learning_rate": 2.850116489774787e-06,
      "loss": 0.0003,
      "step": 6680
    },
    {
      "epoch": 0.8603395061728395,
      "grad_norm": 0.0026630922220647335,
      "learning_rate": 2.824229873155579e-06,
      "loss": 0.0066,
      "step": 6690
    },
    {
      "epoch": 0.8616255144032922,
      "grad_norm": 0.0018625525990501046,
      "learning_rate": 2.798343256536371e-06,
      "loss": 0.0001,
      "step": 6700
    },
    {
      "epoch": 0.8629115226337448,
      "grad_norm": 0.0014608592027798295,
      "learning_rate": 2.772456639917163e-06,
      "loss": 0.0001,
      "step": 6710
    },
    {
      "epoch": 0.8641975308641975,
      "grad_norm": 0.0011855842312797904,
      "learning_rate": 2.746570023297955e-06,
      "loss": 0.0001,
      "step": 6720
    },
    {
      "epoch": 0.8654835390946503,
      "grad_norm": 0.0025238844100385904,
      "learning_rate": 2.7206834066787476e-06,
      "loss": 0.0001,
      "step": 6730
    },
    {
      "epoch": 0.8667695473251029,
      "grad_norm": 0.006742027588188648,
      "learning_rate": 2.6947967900595397e-06,
      "loss": 0.0021,
      "step": 6740
    },
    {
      "epoch": 0.8680555555555556,
      "grad_norm": 0.0014183939201757312,
      "learning_rate": 2.6689101734403317e-06,
      "loss": 0.0001,
      "step": 6750
    },
    {
      "epoch": 0.8693415637860082,
      "grad_norm": 0.001124102622270584,
      "learning_rate": 2.6430235568211237e-06,
      "loss": 0.0001,
      "step": 6760
    },
    {
      "epoch": 0.8706275720164609,
      "grad_norm": 0.00956263393163681,
      "learning_rate": 2.6171369402019158e-06,
      "loss": 0.0001,
      "step": 6770
    },
    {
      "epoch": 0.8719135802469136,
      "grad_norm": 0.003493101103231311,
      "learning_rate": 2.591250323582708e-06,
      "loss": 0.0002,
      "step": 6780
    },
    {
      "epoch": 0.8731995884773662,
      "grad_norm": 0.01961158961057663,
      "learning_rate": 2.5653637069635003e-06,
      "loss": 0.0001,
      "step": 6790
    },
    {
      "epoch": 0.8744855967078189,
      "grad_norm": 0.00638039642944932,
      "learning_rate": 2.5394770903442923e-06,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 0.8757716049382716,
      "grad_norm": 0.0014742551138624549,
      "learning_rate": 2.5135904737250844e-06,
      "loss": 0.0001,
      "step": 6810
    },
    {
      "epoch": 0.8770576131687243,
      "grad_norm": 0.0009474300313740969,
      "learning_rate": 2.4877038571058764e-06,
      "loss": 0.0001,
      "step": 6820
    },
    {
      "epoch": 0.878343621399177,
      "grad_norm": 0.0040219672955572605,
      "learning_rate": 2.4618172404866684e-06,
      "loss": 0.0001,
      "step": 6830
    },
    {
      "epoch": 0.8796296296296297,
      "grad_norm": 0.012442986480891705,
      "learning_rate": 2.435930623867461e-06,
      "loss": 0.0001,
      "step": 6840
    },
    {
      "epoch": 0.8809156378600823,
      "grad_norm": 0.0010765137849375606,
      "learning_rate": 2.410044007248253e-06,
      "loss": 0.0001,
      "step": 6850
    },
    {
      "epoch": 0.882201646090535,
      "grad_norm": 0.0008113933727145195,
      "learning_rate": 2.384157390629045e-06,
      "loss": 0.0001,
      "step": 6860
    },
    {
      "epoch": 0.8834876543209876,
      "grad_norm": 0.0008651356911286712,
      "learning_rate": 2.358270774009837e-06,
      "loss": 0.0001,
      "step": 6870
    },
    {
      "epoch": 0.8847736625514403,
      "grad_norm": 0.0032008145935833454,
      "learning_rate": 2.332384157390629e-06,
      "loss": 0.0001,
      "step": 6880
    },
    {
      "epoch": 0.886059670781893,
      "grad_norm": 0.001598079688847065,
      "learning_rate": 2.306497540771421e-06,
      "loss": 0.0,
      "step": 6890
    },
    {
      "epoch": 0.8873456790123457,
      "grad_norm": 0.0028093024156987667,
      "learning_rate": 2.2806109241522136e-06,
      "loss": 0.0001,
      "step": 6900
    },
    {
      "epoch": 0.8886316872427984,
      "grad_norm": 0.0008759461343288422,
      "learning_rate": 2.2547243075330056e-06,
      "loss": 0.0009,
      "step": 6910
    },
    {
      "epoch": 0.8899176954732511,
      "grad_norm": 0.001994126243516803,
      "learning_rate": 2.2288376909137976e-06,
      "loss": 0.0001,
      "step": 6920
    },
    {
      "epoch": 0.8912037037037037,
      "grad_norm": 0.009079212322831154,
      "learning_rate": 2.2029510742945897e-06,
      "loss": 0.0001,
      "step": 6930
    },
    {
      "epoch": 0.8924897119341564,
      "grad_norm": 0.04887304827570915,
      "learning_rate": 2.1770644576753817e-06,
      "loss": 0.0001,
      "step": 6940
    },
    {
      "epoch": 0.893775720164609,
      "grad_norm": 0.0007414416177198291,
      "learning_rate": 2.151177841056174e-06,
      "loss": 0.0001,
      "step": 6950
    },
    {
      "epoch": 0.8950617283950617,
      "grad_norm": 0.014524801634252071,
      "learning_rate": 2.1252912244369662e-06,
      "loss": 0.0001,
      "step": 6960
    },
    {
      "epoch": 0.8963477366255144,
      "grad_norm": 0.002759402384981513,
      "learning_rate": 2.0994046078177587e-06,
      "loss": 0.0001,
      "step": 6970
    },
    {
      "epoch": 0.897633744855967,
      "grad_norm": 0.0034666077699512243,
      "learning_rate": 2.0735179911985507e-06,
      "loss": 0.0001,
      "step": 6980
    },
    {
      "epoch": 0.8989197530864198,
      "grad_norm": 0.004562650341540575,
      "learning_rate": 2.0476313745793428e-06,
      "loss": 0.0001,
      "step": 6990
    },
    {
      "epoch": 0.9002057613168725,
      "grad_norm": 0.26345857977867126,
      "learning_rate": 2.021744757960135e-06,
      "loss": 0.0001,
      "step": 7000
    },
    {
      "epoch": 0.9014917695473251,
      "grad_norm": 0.011431130580604076,
      "learning_rate": 1.995858141340927e-06,
      "loss": 0.0002,
      "step": 7010
    },
    {
      "epoch": 0.9027777777777778,
      "grad_norm": 0.002659969497472048,
      "learning_rate": 1.969971524721719e-06,
      "loss": 0.0001,
      "step": 7020
    },
    {
      "epoch": 0.9040637860082305,
      "grad_norm": 0.0018710159929469228,
      "learning_rate": 1.9440849081025114e-06,
      "loss": 0.0001,
      "step": 7030
    },
    {
      "epoch": 0.9053497942386831,
      "grad_norm": 0.003944565542042255,
      "learning_rate": 1.9181982914833034e-06,
      "loss": 0.0001,
      "step": 7040
    },
    {
      "epoch": 0.9066358024691358,
      "grad_norm": 0.0014964473666623235,
      "learning_rate": 1.8923116748640954e-06,
      "loss": 0.0001,
      "step": 7050
    },
    {
      "epoch": 0.9079218106995884,
      "grad_norm": 0.0008506452431902289,
      "learning_rate": 1.8664250582448875e-06,
      "loss": 0.0001,
      "step": 7060
    },
    {
      "epoch": 0.9092078189300411,
      "grad_norm": 0.01223718747496605,
      "learning_rate": 1.8405384416256797e-06,
      "loss": 0.0001,
      "step": 7070
    },
    {
      "epoch": 0.9104938271604939,
      "grad_norm": 0.0019942736253142357,
      "learning_rate": 1.8146518250064718e-06,
      "loss": 0.0001,
      "step": 7080
    },
    {
      "epoch": 0.9117798353909465,
      "grad_norm": 0.007574773859232664,
      "learning_rate": 1.788765208387264e-06,
      "loss": 0.0001,
      "step": 7090
    },
    {
      "epoch": 0.9130658436213992,
      "grad_norm": 0.0020829709246754646,
      "learning_rate": 1.762878591768056e-06,
      "loss": 0.0001,
      "step": 7100
    },
    {
      "epoch": 0.9143518518518519,
      "grad_norm": 0.0213822890073061,
      "learning_rate": 1.736991975148848e-06,
      "loss": 0.0001,
      "step": 7110
    },
    {
      "epoch": 0.9156378600823045,
      "grad_norm": 0.0027355807833373547,
      "learning_rate": 1.7111053585296404e-06,
      "loss": 0.0001,
      "step": 7120
    },
    {
      "epoch": 0.9169238683127572,
      "grad_norm": 0.0013070553541183472,
      "learning_rate": 1.6852187419104324e-06,
      "loss": 0.0002,
      "step": 7130
    },
    {
      "epoch": 0.9182098765432098,
      "grad_norm": 0.00497082294896245,
      "learning_rate": 1.6593321252912244e-06,
      "loss": 0.0001,
      "step": 7140
    },
    {
      "epoch": 0.9194958847736625,
      "grad_norm": 0.0009285129490308464,
      "learning_rate": 1.6334455086720167e-06,
      "loss": 0.0001,
      "step": 7150
    },
    {
      "epoch": 0.9207818930041153,
      "grad_norm": 0.012607517652213573,
      "learning_rate": 1.6075588920528087e-06,
      "loss": 0.0001,
      "step": 7160
    },
    {
      "epoch": 0.9220679012345679,
      "grad_norm": 0.0018715906189754605,
      "learning_rate": 1.5816722754336008e-06,
      "loss": 0.0002,
      "step": 7170
    },
    {
      "epoch": 0.9233539094650206,
      "grad_norm": 0.0020598394330590963,
      "learning_rate": 1.555785658814393e-06,
      "loss": 0.0001,
      "step": 7180
    },
    {
      "epoch": 0.9246399176954733,
      "grad_norm": 0.001023476361297071,
      "learning_rate": 1.529899042195185e-06,
      "loss": 0.0,
      "step": 7190
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.0016463572392240167,
      "learning_rate": 1.5040124255759773e-06,
      "loss": 0.0001,
      "step": 7200
    },
    {
      "epoch": 0.9272119341563786,
      "grad_norm": 0.004491779021918774,
      "learning_rate": 1.4781258089567696e-06,
      "loss": 0.0001,
      "step": 7210
    },
    {
      "epoch": 0.9284979423868313,
      "grad_norm": 0.0008420973899774253,
      "learning_rate": 1.4522391923375618e-06,
      "loss": 0.0001,
      "step": 7220
    },
    {
      "epoch": 0.9297839506172839,
      "grad_norm": 0.0012134849093854427,
      "learning_rate": 1.4263525757183539e-06,
      "loss": 0.0001,
      "step": 7230
    },
    {
      "epoch": 0.9310699588477366,
      "grad_norm": 0.0013357439311221242,
      "learning_rate": 1.4004659590991459e-06,
      "loss": 0.0001,
      "step": 7240
    },
    {
      "epoch": 0.9323559670781894,
      "grad_norm": 0.0030748110730201006,
      "learning_rate": 1.3745793424799381e-06,
      "loss": 0.0004,
      "step": 7250
    },
    {
      "epoch": 0.933641975308642,
      "grad_norm": 0.004567206837236881,
      "learning_rate": 1.3486927258607302e-06,
      "loss": 0.0001,
      "step": 7260
    },
    {
      "epoch": 0.9349279835390947,
      "grad_norm": 0.0011773293372243643,
      "learning_rate": 1.3228061092415222e-06,
      "loss": 0.0001,
      "step": 7270
    },
    {
      "epoch": 0.9362139917695473,
      "grad_norm": 0.018711280077695847,
      "learning_rate": 1.2969194926223145e-06,
      "loss": 0.0002,
      "step": 7280
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.02963871695101261,
      "learning_rate": 1.2710328760031065e-06,
      "loss": 0.0001,
      "step": 7290
    },
    {
      "epoch": 0.9387860082304527,
      "grad_norm": 0.004777487833052874,
      "learning_rate": 1.2451462593838986e-06,
      "loss": 0.0001,
      "step": 7300
    },
    {
      "epoch": 0.9400720164609053,
      "grad_norm": 0.0019831168465316296,
      "learning_rate": 1.2192596427646908e-06,
      "loss": 0.0001,
      "step": 7310
    },
    {
      "epoch": 0.941358024691358,
      "grad_norm": 0.00319300452247262,
      "learning_rate": 1.1933730261454828e-06,
      "loss": 0.0009,
      "step": 7320
    },
    {
      "epoch": 0.9426440329218106,
      "grad_norm": 0.005329872015863657,
      "learning_rate": 1.167486409526275e-06,
      "loss": 0.0001,
      "step": 7330
    },
    {
      "epoch": 0.9439300411522634,
      "grad_norm": 0.0014817349147051573,
      "learning_rate": 1.1415997929070671e-06,
      "loss": 0.0001,
      "step": 7340
    },
    {
      "epoch": 0.9452160493827161,
      "grad_norm": 0.001595684909261763,
      "learning_rate": 1.1157131762878592e-06,
      "loss": 0.0006,
      "step": 7350
    },
    {
      "epoch": 0.9465020576131687,
      "grad_norm": 0.002836626023054123,
      "learning_rate": 1.0898265596686514e-06,
      "loss": 0.0001,
      "step": 7360
    },
    {
      "epoch": 0.9477880658436214,
      "grad_norm": 0.00642017275094986,
      "learning_rate": 1.0639399430494435e-06,
      "loss": 0.0003,
      "step": 7370
    },
    {
      "epoch": 0.9490740740740741,
      "grad_norm": 0.001294533722102642,
      "learning_rate": 1.0380533264302355e-06,
      "loss": 0.0002,
      "step": 7380
    },
    {
      "epoch": 0.9503600823045267,
      "grad_norm": 0.18024682998657227,
      "learning_rate": 1.0121667098110278e-06,
      "loss": 0.0002,
      "step": 7390
    },
    {
      "epoch": 0.9516460905349794,
      "grad_norm": 0.10878123342990875,
      "learning_rate": 9.8628009319182e-07,
      "loss": 0.0001,
      "step": 7400
    },
    {
      "epoch": 0.9529320987654321,
      "grad_norm": 0.004731209482997656,
      "learning_rate": 9.60393476572612e-07,
      "loss": 0.0001,
      "step": 7410
    },
    {
      "epoch": 0.9542181069958847,
      "grad_norm": 0.02456054836511612,
      "learning_rate": 9.345068599534042e-07,
      "loss": 0.0001,
      "step": 7420
    },
    {
      "epoch": 0.9555041152263375,
      "grad_norm": 0.007255394011735916,
      "learning_rate": 9.086202433341963e-07,
      "loss": 0.0001,
      "step": 7430
    },
    {
      "epoch": 0.9567901234567902,
      "grad_norm": 0.010355602949857712,
      "learning_rate": 8.827336267149884e-07,
      "loss": 0.0001,
      "step": 7440
    },
    {
      "epoch": 0.9580761316872428,
      "grad_norm": 0.0016274407971650362,
      "learning_rate": 8.568470100957805e-07,
      "loss": 0.0002,
      "step": 7450
    },
    {
      "epoch": 0.9593621399176955,
      "grad_norm": 0.005948258563876152,
      "learning_rate": 8.309603934765727e-07,
      "loss": 0.0001,
      "step": 7460
    },
    {
      "epoch": 0.9606481481481481,
      "grad_norm": 0.0017902817344292998,
      "learning_rate": 8.050737768573648e-07,
      "loss": 0.0001,
      "step": 7470
    },
    {
      "epoch": 0.9619341563786008,
      "grad_norm": 0.002995510818436742,
      "learning_rate": 7.791871602381569e-07,
      "loss": 0.0001,
      "step": 7480
    },
    {
      "epoch": 0.9632201646090535,
      "grad_norm": 0.0012815238442271948,
      "learning_rate": 7.53300543618949e-07,
      "loss": 0.0001,
      "step": 7490
    },
    {
      "epoch": 0.9645061728395061,
      "grad_norm": 0.0043452526442706585,
      "learning_rate": 7.274139269997412e-07,
      "loss": 0.0001,
      "step": 7500
    },
    {
      "epoch": 0.9657921810699589,
      "grad_norm": 0.016228528693318367,
      "learning_rate": 7.015273103805333e-07,
      "loss": 0.0001,
      "step": 7510
    },
    {
      "epoch": 0.9670781893004116,
      "grad_norm": 0.0009945766068995,
      "learning_rate": 6.756406937613256e-07,
      "loss": 0.0001,
      "step": 7520
    },
    {
      "epoch": 0.9683641975308642,
      "grad_norm": 0.0010808302322402596,
      "learning_rate": 6.497540771421176e-07,
      "loss": 0.0001,
      "step": 7530
    },
    {
      "epoch": 0.9696502057613169,
      "grad_norm": 0.008010335266590118,
      "learning_rate": 6.238674605229096e-07,
      "loss": 0.0001,
      "step": 7540
    },
    {
      "epoch": 0.9709362139917695,
      "grad_norm": 0.0031478474847972393,
      "learning_rate": 5.979808439037019e-07,
      "loss": 0.0001,
      "step": 7550
    },
    {
      "epoch": 0.9722222222222222,
      "grad_norm": 0.002188713988289237,
      "learning_rate": 5.72094227284494e-07,
      "loss": 0.0001,
      "step": 7560
    },
    {
      "epoch": 0.9735082304526749,
      "grad_norm": 0.0012754281051456928,
      "learning_rate": 5.462076106652861e-07,
      "loss": 0.0002,
      "step": 7570
    },
    {
      "epoch": 0.9747942386831275,
      "grad_norm": 0.0016153176547959447,
      "learning_rate": 5.203209940460782e-07,
      "loss": 0.0008,
      "step": 7580
    },
    {
      "epoch": 0.9760802469135802,
      "grad_norm": 0.001255243201740086,
      "learning_rate": 4.944343774268704e-07,
      "loss": 0.0001,
      "step": 7590
    },
    {
      "epoch": 0.977366255144033,
      "grad_norm": 0.0030847592279314995,
      "learning_rate": 4.6854776080766246e-07,
      "loss": 0.0002,
      "step": 7600
    },
    {
      "epoch": 0.9786522633744856,
      "grad_norm": 0.010967894457280636,
      "learning_rate": 4.4266114418845455e-07,
      "loss": 0.0001,
      "step": 7610
    },
    {
      "epoch": 0.9799382716049383,
      "grad_norm": 0.0563119612634182,
      "learning_rate": 4.1677452756924675e-07,
      "loss": 0.0001,
      "step": 7620
    },
    {
      "epoch": 0.981224279835391,
      "grad_norm": 0.006170048378407955,
      "learning_rate": 3.908879109500389e-07,
      "loss": 0.0013,
      "step": 7630
    },
    {
      "epoch": 0.9825102880658436,
      "grad_norm": 0.0013857601443305612,
      "learning_rate": 3.65001294330831e-07,
      "loss": 0.0001,
      "step": 7640
    },
    {
      "epoch": 0.9837962962962963,
      "grad_norm": 0.0010179076343774796,
      "learning_rate": 3.3911467771162313e-07,
      "loss": 0.0001,
      "step": 7650
    },
    {
      "epoch": 0.9850823045267489,
      "grad_norm": 0.00433717854321003,
      "learning_rate": 3.132280610924152e-07,
      "loss": 0.001,
      "step": 7660
    },
    {
      "epoch": 0.9863683127572016,
      "grad_norm": 0.002983903745189309,
      "learning_rate": 2.8734144447320737e-07,
      "loss": 0.0002,
      "step": 7670
    },
    {
      "epoch": 0.9876543209876543,
      "grad_norm": 0.0033613729756325483,
      "learning_rate": 2.614548278539995e-07,
      "loss": 0.0001,
      "step": 7680
    },
    {
      "epoch": 0.988940329218107,
      "grad_norm": 0.0029237314593046904,
      "learning_rate": 2.355682112347916e-07,
      "loss": 0.0005,
      "step": 7690
    },
    {
      "epoch": 0.9902263374485597,
      "grad_norm": 0.0021175832953304052,
      "learning_rate": 2.0968159461558376e-07,
      "loss": 0.0001,
      "step": 7700
    },
    {
      "epoch": 0.9915123456790124,
      "grad_norm": 0.005607726983726025,
      "learning_rate": 1.8379497799637588e-07,
      "loss": 0.0001,
      "step": 7710
    },
    {
      "epoch": 0.992798353909465,
      "grad_norm": 0.03920157253742218,
      "learning_rate": 1.57908361377168e-07,
      "loss": 0.0003,
      "step": 7720
    },
    {
      "epoch": 0.9940843621399177,
      "grad_norm": 0.00119919388089329,
      "learning_rate": 1.3202174475796014e-07,
      "loss": 0.0001,
      "step": 7730
    },
    {
      "epoch": 0.9953703703703703,
      "grad_norm": 0.006984671112149954,
      "learning_rate": 1.0613512813875227e-07,
      "loss": 0.0001,
      "step": 7740
    },
    {
      "epoch": 0.996656378600823,
      "grad_norm": 0.004477635491639376,
      "learning_rate": 8.02485115195444e-08,
      "loss": 0.0001,
      "step": 7750
    },
    {
      "epoch": 0.9979423868312757,
      "grad_norm": 0.004155075643211603,
      "learning_rate": 5.436189490033653e-08,
      "loss": 0.0001,
      "step": 7760
    },
    {
      "epoch": 0.9992283950617284,
      "grad_norm": 0.001148692797869444,
      "learning_rate": 2.8475278281128658e-08,
      "loss": 0.0001,
      "step": 7770
    }
  ],
  "logging_steps": 10,
  "max_steps": 7776,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.050423370737254e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
